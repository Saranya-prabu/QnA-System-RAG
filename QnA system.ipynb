{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cad5d58c87d748b0848b5658b4e45d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b73915335b734fd09ddab0774afb734c",
              "IPY_MODEL_641b5629049442ec8787bba0e300b835",
              "IPY_MODEL_aa25d38878c145a6bd42624366816c31"
            ],
            "layout": "IPY_MODEL_e0c46794e5a742ba992f4fda0bd69a59"
          }
        },
        "b73915335b734fd09ddab0774afb734c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a3074244e734860a027f6310e02e996",
            "placeholder": "​",
            "style": "IPY_MODEL_5031d539c76d489b923ed706a97d474d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "641b5629049442ec8787bba0e300b835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08e079c0e1544167a1555667b0052cb5",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0719941790c4ac4bba2fcec8578dd38",
            "value": 25
          }
        },
        "aa25d38878c145a6bd42624366816c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_564d7075146e4619bf427e94826f648d",
            "placeholder": "​",
            "style": "IPY_MODEL_30a946297fa042fd855f1999a15042a9",
            "value": " 25.0/25.0 [00:00&lt;00:00, 769B/s]"
          }
        },
        "e0c46794e5a742ba992f4fda0bd69a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a3074244e734860a027f6310e02e996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5031d539c76d489b923ed706a97d474d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08e079c0e1544167a1555667b0052cb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0719941790c4ac4bba2fcec8578dd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "564d7075146e4619bf427e94826f648d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30a946297fa042fd855f1999a15042a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9b68bd575c24bb5905cf727fcb2420a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23492f0dfb864ce98b2b16e20a9a48b3",
              "IPY_MODEL_bd564582e58144fd8b062e7649e686c8",
              "IPY_MODEL_ee79a9799eec4c6084cfcad4dcdf530a"
            ],
            "layout": "IPY_MODEL_1b7953c1c51044149b088bc2f752a824"
          }
        },
        "23492f0dfb864ce98b2b16e20a9a48b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91b5f8f95b3b40f8ba5cd0d2c6adbdcb",
            "placeholder": "​",
            "style": "IPY_MODEL_c5b95e7df7ca443bb13031dddbd5722f",
            "value": "config.json: 100%"
          }
        },
        "bd564582e58144fd8b062e7649e686c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4251df036e8b4c048d96cd57d91a229c",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97c0f07d3e2f4343aa99791cecbcbcd8",
            "value": 482
          }
        },
        "ee79a9799eec4c6084cfcad4dcdf530a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29cb587b14e64b70a405fa7240c8725f",
            "placeholder": "​",
            "style": "IPY_MODEL_bf339de80678418dbc8bb3188fd0cf9f",
            "value": " 482/482 [00:00&lt;00:00, 9.88kB/s]"
          }
        },
        "1b7953c1c51044149b088bc2f752a824": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91b5f8f95b3b40f8ba5cd0d2c6adbdcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5b95e7df7ca443bb13031dddbd5722f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4251df036e8b4c048d96cd57d91a229c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c0f07d3e2f4343aa99791cecbcbcd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29cb587b14e64b70a405fa7240c8725f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf339de80678418dbc8bb3188fd0cf9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91ad4c2471574acfb1535626310570ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ec09c74a1b94ecbbc0cad63f896fe81",
              "IPY_MODEL_d2948c3d64d840f9af73f58f7b552834",
              "IPY_MODEL_33ed13480ff743e0a2cca32850eb6429"
            ],
            "layout": "IPY_MODEL_86aaf305e3844bbd8657f08c8a64cd8f"
          }
        },
        "1ec09c74a1b94ecbbc0cad63f896fe81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb4926941b804812980f6ce2b547271b",
            "placeholder": "​",
            "style": "IPY_MODEL_360c53b4723349508d64688d17fdba09",
            "value": "vocab.json: 100%"
          }
        },
        "d2948c3d64d840f9af73f58f7b552834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f99c8bb8d1ea4adb89e25a0b4d03a3cb",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8d5a4b8a2da4d21b2c6a65aefa4d33e",
            "value": 898823
          }
        },
        "33ed13480ff743e0a2cca32850eb6429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f8491abfbe1409b9a7979d99a204663",
            "placeholder": "​",
            "style": "IPY_MODEL_2aea6cc090b740d5b905f8a1a49fe9c0",
            "value": " 899k/899k [00:00&lt;00:00, 7.84MB/s]"
          }
        },
        "86aaf305e3844bbd8657f08c8a64cd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb4926941b804812980f6ce2b547271b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "360c53b4723349508d64688d17fdba09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f99c8bb8d1ea4adb89e25a0b4d03a3cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8d5a4b8a2da4d21b2c6a65aefa4d33e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f8491abfbe1409b9a7979d99a204663": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aea6cc090b740d5b905f8a1a49fe9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fed63b0d4558487bac5af7b83a0a5076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62d6e8c297dc4624a8e17ca2b7cc37d1",
              "IPY_MODEL_9c5218b952864193a36612c60ed30035",
              "IPY_MODEL_997befeb031b4d28bf872a9b305593b5"
            ],
            "layout": "IPY_MODEL_be81ebe8aab7425c8d4bcdd9c418abf5"
          }
        },
        "62d6e8c297dc4624a8e17ca2b7cc37d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ff4f46d179a45b4a3a5174122e5fbab",
            "placeholder": "​",
            "style": "IPY_MODEL_a5e84d8393e24b9ab8e2d9e3dc6bd3a8",
            "value": "merges.txt: 100%"
          }
        },
        "9c5218b952864193a36612c60ed30035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe17fc17ec134213aab5cf4e058f5a4f",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a628f4e295f45629c46bc117d5c3035",
            "value": 456318
          }
        },
        "997befeb031b4d28bf872a9b305593b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e9cfb7d477840ef993773d2796ad632",
            "placeholder": "​",
            "style": "IPY_MODEL_aacb4b7ac6cd4e9ba6d6ac4b06cdca2c",
            "value": " 456k/456k [00:00&lt;00:00, 16.3MB/s]"
          }
        },
        "be81ebe8aab7425c8d4bcdd9c418abf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ff4f46d179a45b4a3a5174122e5fbab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5e84d8393e24b9ab8e2d9e3dc6bd3a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe17fc17ec134213aab5cf4e058f5a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a628f4e295f45629c46bc117d5c3035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e9cfb7d477840ef993773d2796ad632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aacb4b7ac6cd4e9ba6d6ac4b06cdca2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b7720e105bd4d56a4c7ffd7af658bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad16a9fd9c424896894d35a7d678e88f",
              "IPY_MODEL_13a7ca69e7fe4aecaf2e52360db1e3f0",
              "IPY_MODEL_197c7c91d4e743d3a9f824d88e20f1e3"
            ],
            "layout": "IPY_MODEL_289eb2eb0ee64ec698dd7548689f10ec"
          }
        },
        "ad16a9fd9c424896894d35a7d678e88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e688a6af7ef4f18ad1925cab69c6995",
            "placeholder": "​",
            "style": "IPY_MODEL_a8efb70fdd374269a1c870c08c4475c8",
            "value": "tokenizer.json: 100%"
          }
        },
        "13a7ca69e7fe4aecaf2e52360db1e3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e571f850ad48b1ac3f06fbd8133aca",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e04a8ed393b54987bc266ba770495bcc",
            "value": 1355863
          }
        },
        "197c7c91d4e743d3a9f824d88e20f1e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56bbafcfbab9476f8759965e0a7be7aa",
            "placeholder": "​",
            "style": "IPY_MODEL_4e6d98db092a49779cec3c9a31c7777b",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 31.1MB/s]"
          }
        },
        "289eb2eb0ee64ec698dd7548689f10ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e688a6af7ef4f18ad1925cab69c6995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8efb70fdd374269a1c870c08c4475c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5e571f850ad48b1ac3f06fbd8133aca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e04a8ed393b54987bc266ba770495bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56bbafcfbab9476f8759965e0a7be7aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e6d98db092a49779cec3c9a31c7777b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ad192520a484682a1414c80b4273ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b214c64bd56d47e891d0205947d5e5f1",
              "IPY_MODEL_5dd0dfebf54d439fa63f8bedda4bf173",
              "IPY_MODEL_31f8b03e56404164af35f3a2b3ab5b23"
            ],
            "layout": "IPY_MODEL_bb7f512e1e3946a2964ca7775018f3c4"
          }
        },
        "b214c64bd56d47e891d0205947d5e5f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cadd6fe35b04e19919ed7e7c2d39020",
            "placeholder": "​",
            "style": "IPY_MODEL_6743e1e673664fc69138347a0e297b45",
            "value": "model.safetensors: 100%"
          }
        },
        "5dd0dfebf54d439fa63f8bedda4bf173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7c518be5ce84db6874d18142d38b59f",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f055714a57ac4e5f9fc6daf594a0670d",
            "value": 1421700479
          }
        },
        "31f8b03e56404164af35f3a2b3ab5b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d85fb069880641f691e2412af6e1dea2",
            "placeholder": "​",
            "style": "IPY_MODEL_6286bd927ce541a6a67e8f13bedf8340",
            "value": " 1.42G/1.42G [00:14&lt;00:00, 72.2MB/s]"
          }
        },
        "bb7f512e1e3946a2964ca7775018f3c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cadd6fe35b04e19919ed7e7c2d39020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6743e1e673664fc69138347a0e297b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7c518be5ce84db6874d18142d38b59f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f055714a57ac4e5f9fc6daf594a0670d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d85fb069880641f691e2412af6e1dea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6286bd927ce541a6a67e8f13bedf8340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7fae6a6bfc54d988d6f00b3e6b9128d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19c4d17968d947febb22ce20f9e6f4fd",
              "IPY_MODEL_ca4ce67359b042c0958fb85e07d8535b",
              "IPY_MODEL_120b7ce9f9ea4090a58f20b2396a0247"
            ],
            "layout": "IPY_MODEL_8cf8bd642fda4d3cb13c26b2df00386c"
          }
        },
        "19c4d17968d947febb22ce20f9e6f4fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5170262932d240009cdf47e6dfaf3ad7",
            "placeholder": "​",
            "style": "IPY_MODEL_09f8b91a45ca45188b985cd02109c83c",
            "value": "100%"
          }
        },
        "ca4ce67359b042c0958fb85e07d8535b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92027cc3652944ccb93a3a1aa5b115ff",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bfe989f8d2047d3869bee01542cd598",
            "value": 1
          }
        },
        "120b7ce9f9ea4090a58f20b2396a0247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d683edc6a054f7b87ec8706f2f301bd",
            "placeholder": "​",
            "style": "IPY_MODEL_94c1e12f2e464625abe49b41171aec1e",
            "value": " 1/1 [00:07&lt;00:00,  7.21s/it]"
          }
        },
        "8cf8bd642fda4d3cb13c26b2df00386c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5170262932d240009cdf47e6dfaf3ad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09f8b91a45ca45188b985cd02109c83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92027cc3652944ccb93a3a1aa5b115ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bfe989f8d2047d3869bee01542cd598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d683edc6a054f7b87ec8706f2f301bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94c1e12f2e464625abe49b41171aec1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d7316c19e164bf9b6c0411ddf40a784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fae9612233c4ba593eb3565ab86176b",
              "IPY_MODEL_ddc7265a3da74ae6bbe45a9025e8d701",
              "IPY_MODEL_4ee0e515d37e44c899a1ad2b3ebc406d"
            ],
            "layout": "IPY_MODEL_6dfed727521842f9ae35172a0188e950"
          }
        },
        "0fae9612233c4ba593eb3565ab86176b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20245caa3faa424caa7914da53a9ff40",
            "placeholder": "​",
            "style": "IPY_MODEL_c63524c30ebd44cd8a24345bff0d4cf8",
            "value": "100%"
          }
        },
        "ddc7265a3da74ae6bbe45a9025e8d701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_165f5ea0935249bd9abe42f97fd05255",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c618c81def749f18d90f53ce93adb56",
            "value": 2
          }
        },
        "4ee0e515d37e44c899a1ad2b3ebc406d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e71e872bf0c748f79a456bf5596db792",
            "placeholder": "​",
            "style": "IPY_MODEL_0f7b87407c734c3e9affb8eb29443f9f",
            "value": " 2/2 [00:00&lt;00:00,  9.75it/s]"
          }
        },
        "6dfed727521842f9ae35172a0188e950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20245caa3faa424caa7914da53a9ff40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c63524c30ebd44cd8a24345bff0d4cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "165f5ea0935249bd9abe42f97fd05255": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c618c81def749f18d90f53ce93adb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e71e872bf0c748f79a456bf5596db792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f7b87407c734c3e9affb8eb29443f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **BERT based QnA**"
      ],
      "metadata": {
        "id": "9biCvNnYzQdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Text from PDFs"
      ],
      "metadata": {
        "id": "PstmsSPThKhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbu3olJgzlJJ",
        "outputId": "5c513da3-09f9-495a-a99c-2ba1f08fc01a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six python-docx pandas transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhIqqvdj6SKG",
        "outputId": "beea9111-a015-4fdf-bff5-39e98fefd9b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (20240706)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (42.0.8)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from docx import Document\n",
        "from pdfminer.high_level import extract_text, extract_pages\n",
        "from pdfminer.layout import LTTextContainer\n",
        "from transformers import pipeline\n",
        "\n",
        "# Function to extract text and links from a PDF file\n",
        "def extract_text_and_links_from_pdf(pdf_path):\n",
        "    text_data = []\n",
        "    links = []\n",
        "\n",
        "    # Extract text\n",
        "    for page_layout in extract_pages(pdf_path):\n",
        "        for element in page_layout:\n",
        "            if isinstance(element, LTTextContainer):\n",
        "                text_data.append(element.get_text())\n",
        "\n",
        "    # Extract links\n",
        "    def extract_links_from_pdf(pdf_path):\n",
        "        links = []\n",
        "        with open(pdf_path, 'rb') as f:\n",
        "            parser = PDFParser(f)\n",
        "            doc = PDFDocument(parser)\n",
        "            for page in PDFPage.create_pages(doc):\n",
        "                if page.annots:\n",
        "                    for annot in page.annots:\n",
        "                        uri = annot.get('URI', None)\n",
        "                        if uri:\n",
        "                            links.append(uri)\n",
        "        return links\n",
        "\n",
        "    links = extract_links_from_pdf(pdf_path)\n",
        "    return \"\\n\".join(text_data), links\n",
        "\n",
        "# Function to extract text and links from a DOCX file\n",
        "def extract_text_and_links_from_docx(docx_path):\n",
        "    text_data = []\n",
        "    links = []\n",
        "\n",
        "    try:\n",
        "        doc = Document(docx_path)\n",
        "        for para in doc.paragraphs:\n",
        "            text_data.append(para.text)\n",
        "            # DOCX does not have direct hyperlink attribute, so extract links manually\n",
        "            for run in para.runs:\n",
        "                if 'hyperlink' in run._element.xml:\n",
        "                    link = re.search(r'href=\"(.*?)\"', run._element.xml)\n",
        "                    if link:\n",
        "                        links.append(link.group(1))\n",
        "        return \"\\n\".join(text_data), links\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from {docx_path}: {e}\")\n",
        "        return \"\", []\n",
        "\n",
        "# Function to extract text from an Excel file\n",
        "def extract_text_from_excel(excel_path):\n",
        "    try:\n",
        "        xls = pd.ExcelFile(excel_path)\n",
        "        full_text = []\n",
        "        for sheet_name in xls.sheet_names:\n",
        "            df = pd.read_excel(xls, sheet_name=sheet_name)\n",
        "            full_text.append(df.to_string())\n",
        "        return \"\\n\".join(full_text)\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from {excel_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Function to clean and preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\n+', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Function to initialize the QnA model\n",
        "def initialize_qna_model():\n",
        "    return pipeline(\"question-answering\", model=\"deepset/bert-base-cased-squad2\")\n",
        "\n",
        "# Function to answer a user question using the QnA model\n",
        "def answer_question(qna_model, question, context):\n",
        "    result = qna_model(question=question, context=context)\n",
        "    return result['answer']\n",
        "\n",
        "# Main function to process files and answer questions\n",
        "def main(file_folder, question):\n",
        "    qna_model = initialize_qna_model()\n",
        "    all_text = \"\"\n",
        "    all_links = []\n",
        "\n",
        "    for filename in os.listdir(file_folder):\n",
        "        file_path = os.path.join(file_folder, filename)\n",
        "        print(f\"Processing file: {file_path}\")\n",
        "\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            text, links = extract_text_and_links_from_pdf(file_path)\n",
        "        elif filename.lower().endswith('.docx'):\n",
        "            text, links = extract_text_and_links_from_docx(file_path)\n",
        "        elif filename.lower().endswith('.xlsx') or filename.lower().endswith('.xls'):\n",
        "            text = extract_text_from_excel(file_path)\n",
        "            links = []\n",
        "        else:\n",
        "            #print(f\"Skipping unsupported file format: {filename}\")\n",
        "            continue\n",
        "\n",
        "        if not text:\n",
        "            print(f\"Failed to extract text from {file_path}\")\n",
        "            continue\n",
        "\n",
        "        text = preprocess_text(text)\n",
        "        all_text += text + \" \"\n",
        "        all_links.extend(links)\n",
        "\n",
        "    answer = answer_question(qna_model, question, all_text)\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {answer}\")\n",
        "    print(\"Extracted Links:\", all_links)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage: Provide a folder containing various file types and ask a question\n",
        "    file_folder = '/content/drive/My Drive/Proplens/'\n",
        "    question = \"What are the main features of the product?\"\n",
        "    main(file_folder, question)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g2PpnROEMjJ",
        "outputId": "b3331b54-aec0-4bae-9811-f5aaca6cd312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: /content/drive/My Drive/Proplens/facade-catalogue-and-specifications.pdf\n",
            "Processing file: /content/drive/My Drive/Proplens/Inventory sheet.xlsx\n",
            "Processing file: /content/drive/My Drive/Proplens/Project links.docx\n",
            "Processing file: /content/drive/My Drive/Proplens/Sales SOP and policies.docx\n",
            "Processing file: /content/drive/My Drive/Proplens/Tembusu grand 1 Bed + Study unit plan.png\n",
            "Processing file: /content/drive/My Drive/Proplens/Tembusu grand 2 Bed +study unit plan.png\n",
            "Processing file: /content/drive/My Drive/Proplens/Tembusu grand 2 bed unit plan.png\n",
            "Processing file: /content/drive/My Drive/Proplens/Tembusu grand 3 bed unit plan.png\n",
            "Processing file: /content/drive/My Drive/Proplens/Tembusu grand 4 Bed unit plan.png\n",
            "Processing file: /content/drive/My Drive/Proplens/Tembusu grand image.jpeg\n",
            "Processing file: /content/drive/My Drive/Proplens/Tembusu grand Location map.png\n",
            "Processing file: /content/drive/My Drive/Proplens/Tembusu grand Site plan.png\n",
            "Processing file: /content/drive/My Drive/Proplens/TEMBUSU GRAND_MAIN BROCHURE.pdf\n",
            "Processing file: /content/drive/My Drive/Proplens/pdf\n",
            "Processing file: /content/drive/My Drive/Proplens/Checklist for purchase of property under construction from developers.pdf\n",
            "Processing file: /content/drive/My Drive/Proplens/faiss_index_hp (1)\n",
            "Processing file: /content/drive/My Drive/Proplens/faiss_index_hp\n",
            "Processing file: /content/drive/My Drive/Proplens/index.faiss\n",
            "Processing file: /content/drive/My Drive/Proplens/index.pkl\n",
            "Question: What are the main features of the product?\n",
            "Answer: variations in colour and vein pattern\n",
            "Extracted Links: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation for SQUAD dataset"
      ],
      "metadata": {
        "id": "kXU8miNCO4aO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Lc_OXVDN1yy",
        "outputId": "543b4382-82a6-4e04-c928-178b3d97215e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Function to initialize the QnA model\n",
        "def initialize_qna_model():\n",
        "    return pipeline(\"question-answering\", model=\"deepset/bert-base-cased-squad2\")\n",
        "\n",
        "# Function to assess performance and latency on a benchmark dataset\n",
        "def assess_performance_and_latency():\n",
        "    # Define the benchmark dataset\n",
        "    dataset_name = \"squad\"  # Use a standard benchmark dataset like SQuAD\n",
        "    num_samples = 100  # Number of samples to test\n",
        "\n",
        "    # Load the benchmark dataset\n",
        "    dataset = load_dataset(dataset_name)\n",
        "\n",
        "    # Extract a subset of the validation data\n",
        "    validation_data = dataset['validation']\n",
        "    sample_data = validation_data.select(range(num_samples))\n",
        "\n",
        "    # Prepare data for evaluation\n",
        "    contexts = [item['context'] for item in sample_data]\n",
        "    questions = [item['question'] for item in sample_data]\n",
        "    answers = [item['answers']['text'][0] for item in sample_data]\n",
        "\n",
        "    qna_model = initialize_qna_model()\n",
        "\n",
        "    predictions = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for context, question in zip(contexts, questions):\n",
        "        result = qna_model(question=question, context=context)\n",
        "        predictions.append(result['answer'])\n",
        "\n",
        "    end_time = time.time()\n",
        "    latency = end_time - start_time\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    accuracy = np.mean([a == p for a, p in zip(answers, predictions)])\n",
        "    f1 = f1_score(answers, predictions, average='weighted')\n",
        "\n",
        "    print(f\"Latency: {latency:.2f} seconds\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    assess_performance_and_latency()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYaDcUmkOZGu",
        "outputId": "c1569414-4c18-4422-d467-5722e5c17cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latency: 58.09 seconds\n",
            "Accuracy: 0.66\n",
            "F1 Score: 0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FASTAPI APP"
      ],
      "metadata": {
        "id": "i3F9GPhLz4Ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn pyngrok datasets transformers nest_asyncio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD27gZOFz6A6",
        "outputId": "38aacad8-5438-40e9-d165-6f5aadaddee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.111.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.30.3)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.37.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.27.0)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.1.4)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.0.9)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.2.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi) (2.6.1)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi) (3.7)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi) (0.12.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi) (1.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile api.py\n",
        "import time\n",
        "import numpy as np\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Function to initialize the QnA model\n",
        "def initialize_qna_model():\n",
        "    return pipeline(\"question-answering\", model=\"deepset/bert-base-cased-squad2\")\n",
        "\n",
        "# Load the SQuAD dataset\n",
        "dataset_name = \"squad\"\n",
        "dataset = load_dataset(dataset_name)\n",
        "validation_data = dataset['validation']\n",
        "\n",
        "# Extract a subset of the validation data for demo purposes\n",
        "num_samples = 100\n",
        "sample_data = validation_data.select(range(num_samples))\n",
        "contexts = [item['context'] for item in sample_data]\n",
        "questions = [item['question'] for item in sample_data]\n",
        "answers = [item['answers']['text'][0] for item in sample_data]\n",
        "\n",
        "qna_model = initialize_qna_model()\n",
        "\n",
        "class QuestionRequest(BaseModel):\n",
        "    question: str\n",
        "\n",
        "@app.post(\"/answer/\")\n",
        "async def get_answer(request: QuestionRequest):\n",
        "    question = request.question\n",
        "    context = \" \".join(contexts)  # Join all contexts for this example\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        result = qna_model(question=question, context=context)\n",
        "        answer = result['answer']\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing request: {e}\")\n",
        "\n",
        "    latency = time.time() - start_time\n",
        "    return {\"answer\": answer, \"latency\": latency}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv8P0dZMz7Qb",
        "outputId": "4ceff41c-f30c-40c7-b3ca-045459fde84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting api.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup python3 -m uvicorn api:app --host 0.0.0.0 --port 8000 > output.log 2>&1 &\n"
      ],
      "metadata": {
        "id": "UiPWxJPh0Dh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install necessary libraries\n",
        "!pip install fastapi uvicorn pyngrok nest_asyncio\n",
        "\n",
        "# Step 2: Set up ngrok authtoken (replace 'YOUR_AUTHTOKEN_HERE' with your actual authtoken)\n",
        "!ngrok authtoken 2jPTIbWSfS7g4Vu0dllTblPJxNv_4apQJqVsKySceNCJ1uQHL\n",
        "\n",
        "# Step 3: Import necessary modules\n",
        "from pyngrok import ngrok\n",
        "from fastapi import FastAPI\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "\n",
        "# Step 4: Patch the event loop\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Step 5: Create a FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"Hello\": \"World\"}\n",
        "\n",
        "# Step 6: Set up a tunnel to the FastAPI server\n",
        "port = 8001  # Use a different port\n",
        "public_url = ngrok.connect(port)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# Step 7: Start the FastAPI server\n",
        "try:\n",
        "    uvicorn.run(app, host='0.0.0.0', port=port)\n",
        "except Exception as e:\n",
        "    print(f\"Error starting server: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaBAl0vg2VM_",
        "outputId": "bfa1bf34-ad9c-441a-c0c7-343b9aa7122e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.111.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.30.3)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.37.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.27.0)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.1.4)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.0.9)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.2.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi) (2.6.1)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi) (3.7)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi) (0.12.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.20.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (12.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi) (1.2.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (0.1.2)\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Public URL: NgrokTunnel: \"https://b437-34-145-195-49.ngrok-free.app\" -> \"http://localhost:8001\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [29173]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [29173]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2jPTIbWSfS7g4Vu0dllTblPJxNv_4apQJqVsKySceNCJ1uQHL  # Replace with your actual ngrok authtoken\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VsAqpC83e3i",
        "outputId": "29b56092-df83-4b49-f567-d42bcc11a642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "from transformers import pipeline\n",
        "import time\n",
        "\n",
        "# Patch the event loop\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Initialize the QnA model\n",
        "def initialize_qna_model():\n",
        "    return pipeline(\"question-answering\", model=\"deepset/bert-base-cased-squad2\")\n",
        "\n",
        "qna_model = initialize_qna_model()\n",
        "\n",
        "# Create a FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Define request and response models\n",
        "class QnARequest(BaseModel):\n",
        "    context: str\n",
        "    question: str\n",
        "\n",
        "class QnAResponse(BaseModel):\n",
        "    answer: str\n",
        "    latency: float\n",
        "\n",
        "# Define the QnA endpoint\n",
        "@app.post(\"/qna\", response_model=QnAResponse)\n",
        "async def get_answer(request: QnARequest):\n",
        "    start_time = time.time()\n",
        "    result = qna_model(question=request.question, context=request.context)\n",
        "    latency = time.time() - start_time\n",
        "    return QnAResponse(answer=result['answer'], latency=latency)\n",
        "\n",
        "# Set up a tunnel to the FastAPI server\n",
        "port = 8000  # Use port 8000\n",
        "public_url = ngrok.connect(port)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# Start the FastAPI server\n",
        "uvicorn.run(app, host='0.0.0.0', port=port)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8KNQBvB3oic",
        "outputId": "65276c85-0cd3-446d-fea0-273351d4db6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:     Started server process [87395]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://5fb3-34-145-195-49.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "INFO:     2402:e280:3d6e:1a10:3845:7748:fefd:ec84:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     2402:e280:3d6e:1a10:3845:7748:fefd:ec84:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     2402:e280:3d6e:1a10:3845:7748:fefd:ec84:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     2402:e280:3d6e:1a10:3845:7748:fefd:ec84:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [87395]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RAG based QnA**"
      ],
      "metadata": {
        "id": "FlXYJf6r_HZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing Required Libraries\n",
        "%pip install python-docx\n",
        "%pip install python-pptx\n",
        "%pip install PyPDF2\n",
        "%pip install langchain\n",
        "%pip install langchain_community\n",
        "%pip install langchain_google_genai\n",
        "%pip install langchain_text_splitters\n",
        "%pip install sentence-transformers\n",
        "%pip install faiss-cpu\n",
        "%pip install cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SWHTyT2m_TKZ",
        "outputId": "9cf02ee2-b756-43dd-e2ee-4840f83fea0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (4.9.4)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (9.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.0 python-pptx-0.6.23\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.10-py3-none-any.whl (990 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.0/990.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.22 (from langchain)\n",
            "  Downloading langchain_core-0.2.22-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.5/373.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.93-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.22->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.22->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.22->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.10 langchain-core-0.2.22 langchain-text-splitters-0.2.2 langsmith-0.1.93 orjson-3.10.6\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.9-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.10)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.22 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.22)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.93)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.22->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.22->langchain_community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.22->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.9 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-1.0.7-py3-none-any.whl (36 kB)\n",
            "Collecting google-generativeai<0.8.0,>=0.7.0 (from langchain_google_genai)\n",
            "  Downloading google_generativeai-0.7.2-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/164.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.2.22)\n",
            "Collecting google-ai-generativelanguage==0.6.6 (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.6-py3-none-any.whl (718 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.16.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (0.1.93)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (8.5.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.20.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.63.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (2024.7.4)\n",
            "Installing collected packages: google-ai-generativelanguage, google-generativeai, langchain_google_genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.4\n",
            "    Uninstalling google-ai-generativelanguage-0.6.4:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.4\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.5.4\n",
            "    Uninstalling google-generativeai-0.5.4:\n",
            "      Successfully uninstalled google-generativeai-0.5.4\n",
            "Successfully installed google-ai-generativelanguage-0.6.6 google-generativeai-0.7.2 langchain_google_genai-1.0.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "3ee5fce28bef495ea1c38c159bed11b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_text_splitters in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain_text_splitters) (0.2.22)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (0.1.93)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (8.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (3.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (2024.7.4)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-3.0.1\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0.post1\n",
            "Collecting cohere\n",
            "  Downloading cohere-5.6.1-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.5/178.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2.0.0,>=1.34.0 (from cohere)\n",
            "  Downloading boto3-1.34.145-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.27.0)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.19.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Collecting botocore<1.35.0,>=1.34.145 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading botocore-1.34.145-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.0.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.23.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.145->boto3<2.0.0,>=1.34.0->cohere) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.145->boto3<2.0.0,>=1.34.0->cohere) (1.16.0)\n",
            "Installing collected packages: types-requests, parameterized, jmespath, httpx-sse, fastavro, botocore, s3transfer, boto3, cohere\n",
            "Successfully installed boto3-1.34.145 botocore-1.34.145 cohere-5.6.1 fastavro-1.9.5 httpx-sse-0.4.0 jmespath-1.0.1 parameterized-0.9.0 s3transfer-0.10.2 types-requests-2.32.0.20240712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# necessary Imports\n",
        "from docx import Document\n",
        "from PyPDF2 import PdfReader\n",
        "from pptx import Presentation\n",
        "from langchain_community.llms import Cohere\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.prompts  import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder"
      ],
      "metadata": {
        "id": "SGZw_epzJI2D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dSJT9OxJKuC",
        "outputId": "4b58bb87-8c04-46b8-a2c3-9689949a06b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "from docx import Document\n",
        "import openpyxl\n",
        "\n",
        "# Define the folder path\n",
        "folder_path = '/content/drive/My Drive/Proplens/'\n",
        "\n",
        "# Initialize empty strings to store the text\n",
        "pdf_text = \"\"\n",
        "doc_text = \"\"\n",
        "excel_text = \"\"\n",
        "file_list = []  # List to keep track of processed files\n",
        "\n",
        "# Function to read PDF files\n",
        "def read_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with open(file_path, 'rb') as pdf_file:\n",
        "        pdf_reader = PdfReader(pdf_file)\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + '\\n'\n",
        "    return text\n",
        "\n",
        "# Function to read DOCX files\n",
        "def read_docx(file_path):\n",
        "    text = \"\"\n",
        "    doc_file = Document(file_path)\n",
        "    for paragraph in doc_file.paragraphs:\n",
        "        text += paragraph.text + '\\n'\n",
        "    return text\n",
        "\n",
        "# Function to read Excel files\n",
        "def read_excel(file_path):\n",
        "    text = \"\"\n",
        "    wb = openpyxl.load_workbook(file_path)\n",
        "    sheet = wb.active\n",
        "    for row in sheet.iter_rows(values_only=True):\n",
        "        text += \"\\t\".join(map(str, row)) + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# Process all files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "    if filename.endswith('.pdf'):\n",
        "        pdf_text += read_pdf(file_path)\n",
        "        file_list.append(filename)\n",
        "    elif filename.endswith('.docx'):\n",
        "        doc_text += read_docx(file_path)\n",
        "        file_list.append(filename)\n",
        "    elif filename.endswith('.xlsx'):\n",
        "        excel_text += read_excel(file_path)\n",
        "        file_list.append(filename)\n",
        "\n",
        "# Combine all text\n",
        "all_text = pdf_text + '\\n' + doc_text + '\\n' + excel_text\n",
        "\n",
        "# Output the length of the combined text and list of processed files\n",
        "print(\"Length of combined text:\", len(all_text))\n",
        "print(\"Files processed:\")\n",
        "for file in file_list:\n",
        "    print(file)\n",
        "\n",
        "# Optional: Save the combined text to a file\n",
        "with open('/content/drive/My Drive/Proplens/combined_text.txt', 'w') as file:\n",
        "    file.write(all_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4dsVDjiY3GZ",
        "outputId": "f46b2be6-0036-4766-b313-3c8df0907547"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of combined text: 164744\n",
            "Files processed:\n",
            "facade-catalogue-and-specifications.pdf\n",
            "Inventory sheet.xlsx\n",
            "Project links.docx\n",
            "Sales SOP and policies.docx\n",
            "TEMBUSU GRAND_MAIN BROCHURE.pdf\n",
            "Checklist for purchase of property under construction from developers.pdf\n",
            "gov.sg _ Property Tax on Residential Property.pdf\n",
            "Sales schemes.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the text into chunks for embeddings creation\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size = 1000,\n",
        "        chunk_overlap = 200, # This is helpul to handle the data loss while chunking.\n",
        "        length_function = len,\n",
        "        separators=['\\n', '\\n\\n', ' ', '']\n",
        "    )\n",
        "\n",
        "chunks = text_splitter.split_text(text = all_text)\n"
      ],
      "metadata": {
        "id": "ozvq784bYq3D"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)\n",
        "\n",
        "# Initializing embeddings model\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Indexing the data using FAISS\n",
        "vectorstore = FAISS.from_texts(chunks, embedding = embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7u2KM7QKZDN4",
        "outputId": "2d7040e0-9a81-49fe-a868-37feb53b6ffa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating retriever\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
        "\n",
        "prompt_template = \"\"\"Answer the question as precise as possible using the provided context. If the answer is\n",
        "                not contained in the context, say \"answer not available in context\" \\n\\n\n",
        "                Context: \\n {context}?\\n\n",
        "                Question: \\n {question} \\n\n",
        "                Answer:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template=prompt_template)"
      ],
      "metadata": {
        "id": "HkfaVNrPamCo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3TrlM8Evt-fm"
      },
      "outputs": [],
      "source": [
        "# function to create a single string of relevant documents given by Faiss.\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# RAG Chain\n",
        "\n",
        "def generate_answer(question):\n",
        "    cohere_llm = Cohere(model=\"command\", temperature=0.1, cohere_api_key = os.getenv('J3ryImGgctIBh5Lbb06reA2PrmNCy98L2FrbegkV'))\n",
        "\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | cohere_llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    return rag_chain.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure API key is set in the environment\n",
        "os.environ['COHERE_API_KEY'] = 'J3ryImGgctIBh5Lbb06reA2PrmNCy98L2FrbegkV'"
      ],
      "metadata": {
        "id": "6YkZ1J-Gd4H_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "ans = generate_answer(\"Describe nature scenes at tembusu grand?\")\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJIsWWQhbLrO",
        "outputId": "5d2727fc-9b28-4b50-84be-fe030e2ad9ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `Cohere` was deprecated in LangChain 0.1.14 and will be removed in 0.3.0. An updated version of the class exists in the langchain-cohere package and should be used instead. To use it run `pip install -U langchain-cohere` and import as `from langchain_cohere import Cohere`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tembusu Grand is a modern development that features a unique stamp of quiet and understated elegance. Its towering architecture is inspired by the Tembusu heritage tree, featuring colors, textures, and an iconic crown design that mirrors the tree's sculptural form. The development is nestled within a lush, evergreen landscape featuring thematic gardens and cascading water features. \n",
            "\n",
            "The Essence of Katong Living artist's impression highlights the Tembusu Grand's thematic gardens and cascading water features. The statement of modern architecture with punctuations of nature includes a yoga studio, tennis court, and gymnasium overlooking a lap pool, social spaces like the Leisure Lawn and Co-Working Lounge, and the Arrival Courtyard with lush greenery and water features. The Pets Corner provides opportunities for outdoor fun, while the Scent and Herbs Gardens offer spaces to relax and unwind. \n",
            "\n",
            "The Tembusu Club features an Entertainment Room and Private Dining space, while the Kids' Playroom includes a Playhouse. The residential services team provides seamless assistance with daily needs such as parcel collection, arranging for laundry and transport bookings, and special occasions like catering for parties and restaurant reservations. \n",
            "\n",
            "Finally, smart-home technologies offer remote control via the Smart Home app, enhancing the sense of modern luxury. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance evaluation for SQUAD dataset"
      ],
      "metadata": {
        "id": "Ml9ar86QhEn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(question, retriever, prompt):\n",
        "    cohere_llm = Cohere(model=\"command\", temperature=0.1, cohere_api_key=os.getenv('COHERE_API_KEY'))\n",
        "\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | cohere_llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    result = rag_chain.invoke(question)\n",
        "\n",
        "    # Ensure result is in the expected format\n",
        "    if isinstance(result, dict) and 'answer' in result:\n",
        "        return result\n",
        "    else:\n",
        "        # Handle unexpected format\n",
        "        return {'answer': result}  # Or raise an exception if that's preferred\n"
      ],
      "metadata": {
        "id": "UxqKqz6fhJtz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(dataset, generate_answer_func, retriever, prompt):\n",
        "    start_time = time.time()\n",
        "\n",
        "    predictions = []\n",
        "    true_answers = []\n",
        "\n",
        "    for example in dataset['validation']:\n",
        "        question = example['question']\n",
        "        context = example['context']\n",
        "        true_answer = example['answers']['text'][0]\n",
        "\n",
        "        # Get prediction from the model\n",
        "        try:\n",
        "            logging.info(f\"Processing question: {question}\")\n",
        "            result = generate_answer_func(question, retriever, prompt)\n",
        "            predicted_answer = result.get('answer', '')\n",
        "            predictions.append(predicted_answer)\n",
        "            true_answers.append(true_answer)\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error processing question: {e}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate Latency\n",
        "    latency = end_time - start_time\n",
        "\n",
        "    # Calculate Accuracy and F1 Score\n",
        "    def compute_exact_match(pred, true):\n",
        "        return int(pred.strip().lower() == true.strip().lower())\n",
        "\n",
        "    accuracy = np.mean([compute_exact_match(pred, true) for pred, true in zip(predictions, true_answers)])\n",
        "\n",
        "    def compute_f1(pred, true):\n",
        "        pred_tokens = set(pred.split())\n",
        "        true_tokens = set(true.split())\n",
        "        intersection = pred_tokens.intersection(true_tokens)\n",
        "        if len(pred_tokens) == 0 or len(true_tokens) == 0:\n",
        "            return 0.0\n",
        "        precision = len(intersection) / len(pred_tokens)\n",
        "        recall = len(intersection) / len(true_tokens)\n",
        "        if precision + recall == 0:\n",
        "            return 0.0\n",
        "        return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    f1 = np.mean([compute_f1(pred, true) for pred, true in zip(predictions, true_answers)])\n",
        "\n",
        "    return latency, accuracy, f1\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    import os\n",
        "\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "    # Ensure API key is set in the environment\n",
        "    os.environ['COHERE_API_KEY'] = 'J3ryImGgctIBh5Lbb06reA2PrmNCy98L2FrbegkV'\n",
        "\n",
        "    # Load the dataset\n",
        "    dataset = load_dataset(\"squad\")\n",
        "\n",
        "    # Setup your vectorstore and prompt template\n",
        "    # For example:\n",
        "    # vectorstore = FAISS.from_texts(chunks, embedding=embeddings)\n",
        "    # retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
        "\n",
        "    prompt_template = \"\"\"Answer the question as precise as possible using the provided context. If the answer is\n",
        "                not contained in the context, say \"answer not available in context\" \\n\\n\n",
        "                Context: \\n {context}?\\n\n",
        "                Question: \\n {question} \\n\n",
        "                Answer:\"\"\"\n",
        "\n",
        "    prompt = PromptTemplate.from_template(template=prompt_template)\n",
        "\n",
        "    # Call the evaluate_model function\n",
        "    try:\n",
        "        latency, accuracy, f1 = evaluate_model(dataset, generate_answer, retriever, prompt)\n",
        "        print(f\"Latency: {latency:.2f} seconds\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "        print(f\"F1 Score: {f1:.2f}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error evaluating model: {e}\")\n"
      ],
      "metadata": {
        "id": "jMaQO8sHif1t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "outputId": "d87683f9-f554-474a-fde7-44c66b78ddd5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: data=None message=\"You are using a Trial key, which is limited to 40 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\".\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c454d7d60e07>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Call the evaluate_model function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mlatency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Latency: {latency:.2f} seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy: {accuracy:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-c454d7d60e07>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(dataset, generate_answer_func, retriever, prompt)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing question: {question}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_answer_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mpredicted_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'answer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_answer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-08c4d837596f>\u001b[0m in \u001b[0;36mgenerate_answer\u001b[0;34m(question, retriever, prompt)\u001b[0m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Ensure result is in the expected format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2871\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2872\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2873\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2874\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         return (\n\u001b[0;32m--> 346\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    347\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    702\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    880\u001b[0m                 )\n\u001b[1;32m    881\u001b[0m             ]\n\u001b[0;32m--> 882\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    883\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             output = (\n\u001b[0;32m--> 727\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    728\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m             text = (\n\u001b[0;32m-> 1431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/cohere.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \"\"\"\n\u001b[1;32m    235\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invocation_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         response = completion_with_retry(\n\u001b[0m\u001b[1;32m    237\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/cohere.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoSleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_for_next_attempt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdo\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/nap.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmocked\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "\n",
        "def evaluate_model(retriever, generate_answer_function, dataset_name='squad', num_samples=100):\n",
        "    # Load the benchmark dataset\n",
        "    print(\"Loading dataset...\")\n",
        "    dataset = load_dataset(dataset_name)\n",
        "\n",
        "    # Extract a subset of the validation data\n",
        "    validation_data = dataset['validation']\n",
        "    sample_data = validation_data.select(range(num_samples))\n",
        "\n",
        "    contexts = [item['context'] for item in sample_data]\n",
        "    questions = [item['question'] for item in sample_data]\n",
        "    true_answers = [item['answers']['text'][0] for item in sample_data]\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, (context, question) in enumerate(zip(contexts, questions)):\n",
        "        print(f\"Processing question {i+1}/{num_samples}\")\n",
        "        # Retrieve relevant documents for the question\n",
        "        search_results = retriever.get_relevant_documents(question)\n",
        "\n",
        "        if not search_results:\n",
        "            print(f\"No search results for question: {question}\")\n",
        "            continue\n",
        "\n",
        "        relevant_docs = search_results\n",
        "        formatted_context = \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
        "\n",
        "        # Generate an answer\n",
        "        result = generate_answer_function(question, formatted_context)\n",
        "\n",
        "        if not result:\n",
        "            print(f\"No answer generated for question: {question}\")\n",
        "            predictions.append(\"No answer generated\")\n",
        "        else:\n",
        "            predictions.append(result)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate Latency\n",
        "    latency = end_time - start_time\n",
        "\n",
        "    # Calculate Accuracy and F1 Score\n",
        "    def compute_exact_match(pred, true):\n",
        "        return int(pred.strip().lower() == true.strip().lower())\n",
        "\n",
        "    accuracy = np.mean([compute_exact_match(pred, true) for pred, true in zip(predictions, true_answers)])\n",
        "\n",
        "    def compute_f1(pred, true):\n",
        "        pred_tokens = set(pred.split())\n",
        "        true_tokens = set(true.split())\n",
        "        intersection = pred_tokens.intersection(true_tokens)\n",
        "        if len(pred_tokens) == 0 or len(true_tokens) == 0:\n",
        "            return 0.0\n",
        "        precision = len(intersection) / len(pred_tokens)\n",
        "        recall = len(intersection) / len(true_tokens)\n",
        "        if precision + recall == 0:\n",
        "            return 0.0\n",
        "        return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    f1 = np.mean([compute_f1(pred, true) for pred, true in zip(predictions, true_answers)])\n",
        "\n",
        "    print(f\"Latency: {latency:.2f} seconds\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define your `generate_answer` function with context parameter\n",
        "    def generate_answer_with_context(question, context):\n",
        "        # Mock implementation for demonstration purposes\n",
        "        return \"Generated answer\"\n",
        "\n",
        "    # Evaluate the model\n",
        "    evaluate_model(retriever, generate_answer_with_context)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PglOPU1d1B85",
        "outputId": "5712016d-faba-415a-f50d-ac9422403954"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Processing question 1/100\n",
            "Processing question 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing question 3/100\n",
            "Processing question 4/100\n",
            "Processing question 5/100\n",
            "Processing question 6/100\n",
            "Processing question 7/100\n",
            "Processing question 8/100\n",
            "Processing question 9/100\n",
            "Processing question 10/100\n",
            "Processing question 11/100\n",
            "Processing question 12/100\n",
            "Processing question 13/100\n",
            "Processing question 14/100\n",
            "Processing question 15/100\n",
            "Processing question 16/100\n",
            "Processing question 17/100\n",
            "Processing question 18/100\n",
            "Processing question 19/100\n",
            "Processing question 20/100\n",
            "Processing question 21/100\n",
            "Processing question 22/100\n",
            "Processing question 23/100\n",
            "Processing question 24/100\n",
            "Processing question 25/100\n",
            "Processing question 26/100\n",
            "Processing question 27/100\n",
            "Processing question 28/100\n",
            "Processing question 29/100\n",
            "Processing question 30/100\n",
            "Processing question 31/100\n",
            "Processing question 32/100\n",
            "Processing question 33/100\n",
            "Processing question 34/100\n",
            "Processing question 35/100\n",
            "Processing question 36/100\n",
            "Processing question 37/100\n",
            "Processing question 38/100\n",
            "Processing question 39/100\n",
            "Processing question 40/100\n",
            "Processing question 41/100\n",
            "Processing question 42/100\n",
            "Processing question 43/100\n",
            "Processing question 44/100\n",
            "Processing question 45/100\n",
            "Processing question 46/100\n",
            "Processing question 47/100\n",
            "Processing question 48/100\n",
            "Processing question 49/100\n",
            "Processing question 50/100\n",
            "Processing question 51/100\n",
            "Processing question 52/100\n",
            "Processing question 53/100\n",
            "Processing question 54/100\n",
            "Processing question 55/100\n",
            "Processing question 56/100\n",
            "Processing question 57/100\n",
            "Processing question 58/100\n",
            "Processing question 59/100\n",
            "Processing question 60/100\n",
            "Processing question 61/100\n",
            "Processing question 62/100\n",
            "Processing question 63/100\n",
            "Processing question 64/100\n",
            "Processing question 65/100\n",
            "Processing question 66/100\n",
            "Processing question 67/100\n",
            "Processing question 68/100\n",
            "Processing question 69/100\n",
            "Processing question 70/100\n",
            "Processing question 71/100\n",
            "Processing question 72/100\n",
            "Processing question 73/100\n",
            "Processing question 74/100\n",
            "Processing question 75/100\n",
            "Processing question 76/100\n",
            "Processing question 77/100\n",
            "Processing question 78/100\n",
            "Processing question 79/100\n",
            "Processing question 80/100\n",
            "Processing question 81/100\n",
            "Processing question 82/100\n",
            "Processing question 83/100\n",
            "Processing question 84/100\n",
            "Processing question 85/100\n",
            "Processing question 86/100\n",
            "Processing question 87/100\n",
            "Processing question 88/100\n",
            "Processing question 89/100\n",
            "Processing question 90/100\n",
            "Processing question 91/100\n",
            "Processing question 92/100\n",
            "Processing question 93/100\n",
            "Processing question 94/100\n",
            "Processing question 95/100\n",
            "Processing question 96/100\n",
            "Processing question 97/100\n",
            "Processing question 98/100\n",
            "Processing question 99/100\n",
            "Processing question 100/100\n",
            "Latency: 4.28 seconds\n",
            "Accuracy: 0.00\n",
            "F1 Score: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Define the generate_answer_with_context function\n",
        "def generate_answer_with_context(question, context):\n",
        "    cohere_llm = Cohere(model=\"command\", temperature=0.1, cohere_api_key=os.getenv('J3ryImGgctIBh5Lbb06reA2PrmNCy98L2FrbegkV'))\n",
        "\n",
        "    # Define the prompt template\n",
        "    prompt_template = f\"\"\"\n",
        "    Context: {context}\n",
        "    Question: {question}\n",
        "    Answer:\"\"\"\n",
        "\n",
        "    # Generate a response\n",
        "    response = cohere_llm.generate([prompt_template])\n",
        "\n",
        "    # Check the response format\n",
        "    print(\"Response:\", response)\n",
        "\n",
        "    # Extract the text from the response\n",
        "    if isinstance(response, list) and len(response) > 0 and 'text' in response[0]:\n",
        "        return response[0]['text'].strip()\n",
        "    else:\n",
        "        return \"No answer generated\"\n",
        "\n",
        "# Define the evaluate_model function\n",
        "def evaluate_model(retriever, generate_answer_function, dataset_name='squad', num_samples=100):\n",
        "    # Load the benchmark dataset\n",
        "    print(\"Loading dataset...\")\n",
        "    dataset = load_dataset(dataset_name)\n",
        "\n",
        "    # Extract a subset of the validation data\n",
        "    validation_data = dataset['validation']\n",
        "    sample_data = validation_data.select(range(num_samples))\n",
        "\n",
        "    contexts = [item['context'] for item in sample_data]\n",
        "    questions = [item['question'] for item in sample_data]\n",
        "    true_answers = [item['answers']['text'][0] for item in sample_data]\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, (context, question) in enumerate(zip(contexts, questions), start=1):\n",
        "        print(f\"Processing question {i}/{num_samples}\")\n",
        "        # Retrieve relevant documents for the question\n",
        "        search_results = retriever.invoke(question)\n",
        "\n",
        "        # If search results are a list, use it directly\n",
        "        relevant_docs = search_results\n",
        "        formatted_context = format_docs(relevant_docs)\n",
        "\n",
        "        # Generate an answer\n",
        "        result = generate_answer_function(question, formatted_context)\n",
        "        predictions.append(result)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate Latency\n",
        "    latency = end_time - start_time\n",
        "\n",
        "    # Calculate Accuracy and F1 Score\n",
        "    def compute_exact_match(pred, true):\n",
        "        return int(pred.strip().lower() == true.strip().lower())\n",
        "\n",
        "    accuracy = np.mean([compute_exact_match(pred, true) for pred, true in zip(predictions, true_answers)])\n",
        "\n",
        "    def compute_f1(pred, true):\n",
        "        pred_tokens = set(pred.split())\n",
        "        true_tokens = set(true.split())\n",
        "        intersection = pred_tokens.intersection(true_tokens)\n",
        "        if len(pred_tokens) == 0 or len(true_tokens) == 0:\n",
        "            return 0.0\n",
        "        precision = len(intersection) / len(pred_tokens)\n",
        "        recall = len(intersection) / len(true_tokens)\n",
        "        if precision + recall == 0:\n",
        "            return 0.0\n",
        "        return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    f1 = np.mean([compute_f1(pred, true) for pred, true in zip(predictions, true_answers)])\n",
        "\n",
        "    print(f\"Latency: {latency:.2f} seconds\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define your `generate_answer` function with context parameter\n",
        "    def generate_answer_with_context(question, context):\n",
        "        cohere_llm = Cohere(model=\"command\", temperature=0.1, cohere_api_key=os.getenv('zqr9XSBYfGM0p2CvhySt971mIWHELJaMK85x6SLO'))\n",
        "\n",
        "        prompt_template = f\"\"\"\n",
        "        Context: {context}\n",
        "        Question: {question}\n",
        "        Answer:\"\"\"\n",
        "\n",
        "        response = cohere_llm.generate([prompt_template])\n",
        "        print(\"Response:\", response)\n",
        "\n",
        "        if isinstance(response, list) and len(response) > 0 and 'text' in response[0]:\n",
        "            return response[0]['text'].strip()\n",
        "        else:\n",
        "            return \"No answer generated\"\n",
        "\n",
        "    # Evaluate the model\n",
        "    evaluate_model(retriever, generate_answer_with_context)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2ZGSQ3M3x6a",
        "outputId": "cc2aa11d-ae74-465b-ac87-3d9119236266"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Processing question 1/100\n",
            "Response: generations=[[Generation(text=' The answer is The Denver Broncos represented the AFC at Super Bowl 50')]] llm_output=None run=[RunInfo(run_id=UUID('c1ea10a2-7145-4302-8d8b-d5bac67f6de7'))]\n",
            "Processing question 2/100\n",
            "Response: generations=[[Generation(text=' Carolina Panthers')]] llm_output=None run=[RunInfo(run_id=UUID('761facbc-de76-46be-abfd-c7f0cfe5c6a4'))]\n",
            "Processing question 3/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl is an annual American football game that determines the league champion. The 50th Super Bowl was played in 2016, and was won by the Denver Broncos, who defeated the Carolina Panthers by a score of 24–10. The game was played on February 7, 2016, at Levi's Stadium in Santa Clara, California, and was televised on CBS. \")]] llm_output=None run=[RunInfo(run_id=UUID('c75d242b-146f-4cfc-9a84-4ca6c6c9d220'))]\n",
            "Processing question 4/100\n",
            "Response: generations=[[Generation(text=' The Denver Broncos won Super Bowl 50, defeating the Carolina Panthers by a score of 24-10. This win gave the Broncos their third Super Bowl victory and first since 1998. ')]] llm_output=None run=[RunInfo(run_id=UUID('50c730d2-e194-420f-bb9c-824ba1b5e377'))]\n",
            "Processing question 5/100\n",
            "Response: generations=[[Generation(text=\" The color was blue, according to NFL reporter Brian Sexton, although the league didn't confirm that color until two years later, in 2022. \")]] llm_output=None run=[RunInfo(run_id=UUID('880fc393-bb9a-49ca-b9f7-4641052bee51'))]\n",
            "Processing question 6/100\n",
            "Response: generations=[[Generation(text=' The theme of Super Bowl 50 was \"Golden Anniversary\" and the Pepsi Halftime Show featured a performance by Coldplay, who opened with a rendition of \"Yellow\" and was accompanied by singer Beyonce. The show also featured stunning visuals and an impressive light show, making it a memorable performance for the 50th Super Bowl. ')]] llm_output=None run=[RunInfo(run_id=UUID('3c474ae0-a9cc-4e71-a8cc-1a311e38c2f2'))]\n",
            "Processing question 7/100\n",
            "Response: generations=[[Generation(text=' The game was played on Sunday, as referred to by the abbreviation \"Sun\" in the schedule. ')]] llm_output=None run=[RunInfo(run_id=UUID('6411d03a-a38b-4427-b732-30881ace72ca'))]\n",
            "Processing question 8/100\n",
            "Response: generations=[[Generation(text=' Tembusu Grand')]] llm_output=None run=[RunInfo(run_id=UUID('f5eab6a8-8317-475d-9783-761012dae38b'))]\n",
            "Processing question 9/100\n",
            "Response: generations=[[Generation(text=' The theme of Super Bowl 50 was \"Golden Anniversary\" and the Pepsi Halftime Show featured a performance by Coldplay, who opened with a rendition of \"Yellow\" and was accompanied by singer Beyonce. The show also featured stunning visuals and an impressive light show, making it a memorable performance for the 50th Super Bowl. ')]] llm_output=None run=[RunInfo(run_id=UUID('08774a3a-635b-41d5-b083-033cbd2100b9'))]\n",
            "Processing question 10/100\n",
            "Response: generations=[[Generation(text=' Air-conditioning system. ')]] llm_output=None run=[RunInfo(run_id=UUID('9a0ef9e2-dbf1-4bdf-88b9-40553c79826f'))]\n",
            "Processing question 11/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl is always played on a Sunday except for two years when it was played on a Monday (Super Bowl I and Super Bowl IV). So the answer is Sunday.  It is traditionally held on the first Sunday of February, but this date can be changed depending on when New Year's Day falls.  For example, in 2021 it was played on February 7th, and in 2022 it was played on February 13th.  The 2023 Super Bowl will be played on Sunday February 12th.  The Super Bowl is the biggest annual sporting event in the United States, with over 100 million viewers tuning in to watch the game live on television each year.  The game is played between the champions of the National Football League (NFL) and the American Football Conference (AFC), and the winners are awarded the Vince Lombardi Trophy.  The Super Bowl is also famous for its halftime show, which features some of the biggest names in music performing live on stage.  The Super Bowl is one of the most watched sporting events in the world, and is a major event on the American calendar.  It is also a major day for sports betting and many people enjoy placing bets on which team will win the game.  The Super Bowl is a major advertising event, with many\")]] llm_output=None run=[RunInfo(run_id=UUID('901b0551-6cb6-4384-af00-3de4585b6d6c'))]\n",
            "Processing question 12/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers lost the Super Bowl 50 to the Denver Broncos and therefore did not win. ')]] llm_output=None run=[RunInfo(run_id=UUID('910d12df-bd90-49ad-914f-7bac8008245d'))]\n",
            "Processing question 13/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 took place in the Levi's Stadium located in Santa Clara, California. It was the first Super Bowl to take place in the San Francisco Bay Area since Super XIX in 1985. The game was played between the Denver Broncos and the Carolina Panthers with the Broncos winning 24-10. \")]] llm_output=None run=[RunInfo(run_id=UUID('70242fca-13ec-455a-9c74-6f1e10c269c0'))]\n",
            "Processing question 14/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 took place in Santa Clara, California, US. It was the first Super Bowl to be played on the West Coast in 15 years. The game was played on February 7, 2016, at Levi's Stadium in Santa Clara, with the Denver Broncos defeating the Carolina Panthers by a score of 24–10. \")]] llm_output=None run=[RunInfo(run_id=UUID('6b62a5f3-382a-4654-8fac-c923b3cce720'))]\n",
            "Processing question 15/100\n",
            "Response: generations=[[Generation(text=' Answer: \\nThe Roman numeral for 50 is L. So if we used Roman numerals, Super Bowl 50 would have been called Super Bowl L. ')]] llm_output=None run=[RunInfo(run_id=UUID('a15afe50-a3bd-4da7-a049-77638ca256cd'))]\n",
            "Processing question 16/100\n",
            "Response: generations=[[Generation(text=' The 2015 NFL season')]] llm_output=None run=[RunInfo(run_id=UUID('a7474d5d-46aa-4108-b7b9-40c7406836f2'))]\n",
            "Processing question 17/100\n",
            "Response: generations=[[Generation(text=' The Denver Broncos secured a Super Bowl title for the third time in 1998.  Although they have won several Super Bowl titles since, 1998 remains a memorable year for the team.  This was also the last Super Bowl win for the Broncos before the upcoming 2022-2023 season. ')]] llm_output=None run=[RunInfo(run_id=UUID('db92a853-5bd1-485d-bc12-ead1ec4a6b43'))]\n",
            "Processing question 18/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 took place in Santa Clara, California, US. It was the first Super Bowl to be played on the West Coast in 15 years. The game was played on February 7, 2016, at Levi's Stadium with the Denver Broncos defeating the Carolina Panthers by a score of 24–10. \")]] llm_output=None run=[RunInfo(run_id=UUID('1af8e386-b3e1-4838-bb58-a681b901f953'))]\n",
            "Processing question 19/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl is an annual American football game that determines the league champion. The specific stadium where Super Bowl 50 was held is the Levi's Stadium, located in Santa Clara, California. It was the venue for Super Bowl 50, which took place on February 7, 2016, and was contested by the Denver Broncos and the Carolina Panthers.\")]] llm_output=None run=[RunInfo(run_id=UUID('ddeaa8cd-1f5d-4e62-8eb6-7259f0874295'))]\n",
            "Processing question 20/100\n",
            "Response: generations=[[Generation(text=' The final score of Super Bowl 50 was Denver Broncos - 24, Carolina Panthers - 10. ')]] llm_output=None run=[RunInfo(run_id=UUID('330401f3-7052-41a6-95ad-e8a633481ec9'))]\n",
            "Processing question 21/100\n",
            "Response: generations=[[Generation(text=' The answer is Super Bowl 50 took place on February 7, 2016. ')]] llm_output=None run=[RunInfo(run_id=UUID('bdc91598-d8d3-40ba-a399-946fd0fc35c6'))]\n",
            "Processing question 22/100\n",
            "Response: generations=[[Generation(text=' Super Bowl 50 was played on February 7, 2016 and was won by the Denver Broncos against the Carolina Panthers with a score of 24-10. ')]] llm_output=None run=[RunInfo(run_id=UUID('25cfa6cd-099f-44e9-8a79-58de03f2e835'))]\n",
            "Processing question 23/100\n",
            "Response: generations=[[Generation(text=' New England Patriots')]] llm_output=None run=[RunInfo(run_id=UUID('80556b46-8abd-411e-890d-908666b0c08d'))]\n",
            "Processing question 24/100\n",
            "Response: generations=[[Generation(text=' Answer: BLK 92')]] llm_output=None run=[RunInfo(run_id=UUID('147dcc65-2263-41e8-a986-e3fe3305a3fd'))]\n",
            "Processing question 25/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers lost the Super Bowl 50 to the Denver Broncos and therefore did not win. ')]] llm_output=None run=[RunInfo(run_id=UUID('26fa185b-063f-46f6-9e8d-d42dde58a071'))]\n",
            "Processing question 26/100\n",
            "Response: generations=[[Generation(text=' 2015')]] llm_output=None run=[RunInfo(run_id=UUID('5e0db925-17d3-47cc-8ca5-d1a3c45eb5cb'))]\n",
            "Processing question 27/100\n",
            "Response: generations=[[Generation(text=' The answer is the Denver Broncos. The Super Bowl is an annual American football game that determines the league champion. The 50th Super Bowl was played on February 7, 2016, and the Denver Broncos defeated the Carolina Panthers 24–10. ')]] llm_output=None run=[RunInfo(run_id=UUID('3317bfe1-9b06-481b-b707-9bff75da8e6f'))]\n",
            "Processing question 28/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 was held in Santa Clara, California, at the Levi's Stadium which is located in the San Francisco Bay Area on February 7, 2016. It was the first Super Bowl to be played in the Bay Area since Super Bowl XIX, which was held in 1985 at Stanford Stadium. The game was played between the Denver Broncos and the Carolina Panthers, with the Broncos winning 24–10. \")]] llm_output=None run=[RunInfo(run_id=UUID('6b544619-5083-4e89-bc19-88800555dd4e'))]\n",
            "Processing question 29/100\n",
            "Response: generations=[[Generation(text=' Super Bowl')]] llm_output=None run=[RunInfo(run_id=UUID('b4adfb2d-c329-486d-a60f-808a1d0aef82'))]\n",
            "Processing question 30/100\n",
            "Response: generations=[[Generation(text=\" The New England Patriots won the AFC playoff game during the 2015 NFL season.  They ended up winning the Super Bowl that year, defeating the Seattle Seahawks, 28-24.  They were led by star quarterback Tom Brady, and head coach Bill Belichick.  This was the Patriots' fourth Super Bowl victory.  They have since gone on to win three additional Super Bowls, most recently in 2019.  They are one of the most dominant and successful teams in NFL history.  Their victory over the Seahawks was a thrilling back-and-forth affair, with the Patriots coming back from a 10-point deficit late in the fourth quarter to win the game.  It was a classic Super Bowl that is still remembered and discussed today.  The Patriots' victory was the culmination of a dominant run through the playoffs, in which they won their division and conference titles.  They were led by a stellar defense, and the brilliance of Tom Brady, who was named the Super Bowl MVP.  The Patriots' victory over the Seahawks was the beginning of a dynasty for the franchise, as they would go on to win three additional Super Bowls over the next five years.  It was a thrilling time to be a Patriots fan, and the team is still one of the most popular\")]] llm_output=None run=[RunInfo(run_id=UUID('6dbd99b7-8645-40c6-84e7-4f87666a15e5'))]\n",
            "Processing question 31/100\n",
            "Response: generations=[[Generation(text=\" The Most Valuable Player award, which was introduced in 1993, has been won by several Carolina Panthers players over the years. The players are as follows:\\n\\n1. Steve Smith Sr. (2005)\\n2. Julius Peppers (2006)\\n3. DeAngelo Williams (2008)\\n4. Cam Newton (2015)\\n5. Luke Kuechly (2015)\\n6. Jonathan Stewart (2017)\\n7. Christian McCaffrey (2019)\\n8. Teddy Bridgewater (2021)\\n\\nThe award is typically given to the player who had the greatest impact on the team's success during the season. \")]] llm_output=None run=[RunInfo(run_id=UUID('775187ef-3eb6-4eec-b12f-eb31e860f421'))]\n",
            "Processing question 32/100\n",
            "Response: generations=[[Generation(text=' The Denver Broncos have made eight appearances in the Super Bowl.  They won the Super Bowl in 1997, 1998, 1999, and 2015.  Their four Super Bowl wins are a tied record for the NFL.  Their appearances in the Super Bowl were in 1977, 1986, 1989, 1997, 1998, 1999, 2013, and 2015.  Their win-loss record in the Super Bowl is 4-4.  Their four appearances in the 1990s were the most for any NFL team in that decade.  The team has been consistent contenders in recent years and is widely expected to make their ninth Super Bowl appearance soon.  They have a very strong offense and defense this season, as well as an experienced and well-coached roster, which makes them one of the top contenders going into the upcoming NFL season.  They play in the AFC West Division of the NFL, which is widely considered one of the most competitive divisions in all of football.  The team has a very passionate and loyal fanbase, who eagerly await their return to the Super Bowl.  They have a reputation for having one of the best home fields in the NFL, as well as one of the most intimidating environments for opposing teams, which is a big advantage for them in the playoffs.  They')]] llm_output=None run=[RunInfo(run_id=UUID('8ac47931-9a3e-492f-a8b8-14c61ee0c948'))]\n",
            "Processing question 33/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers were established in 1993 and joined the NFL as the 29th franchise in the NFL. They are the only active NFL franchise to be based in Charlotte, North Carolina and their current logo, a blue panther face, was adopted in 2012. ')]] llm_output=None run=[RunInfo(run_id=UUID('d97269ed-04bb-4bd8-980a-00e1ce9b683f'))]\n",
            "Processing question 34/100\n",
            "Response: generations=[[Generation(text=' Eunos Bus Interchange')]] llm_output=None run=[RunInfo(run_id=UUID('29d80b9b-9a21-4f55-b38d-6e30b7388230'))]\n",
            "Processing question 35/100\n",
            "Response: generations=[[Generation(text=' The answer is not specified in the provided information. ')]] llm_output=None run=[RunInfo(run_id=UUID('9dad6a45-4ae0-40d5-b1a3-3db0ae8168b3'))]\n",
            "Processing question 36/100\n",
            "Response: generations=[[Generation(text=' The Panthers beat the Arizona Cardinals in the NFC Championship Game to advance to Super Bowl 50')]] llm_output=None run=[RunInfo(run_id=UUID('2760c7b1-31d4-4a87-a070-d354e36e493a'))]\n",
            "Processing question 37/100\n",
            "Response: generations=[[Generation(text=' The Colts lost to the Broncos in the AFC Championship game in 2013')]] llm_output=None run=[RunInfo(run_id=UUID('0f64eff3-69de-4d86-864f-86fda0052359'))]\n",
            "Processing question 38/100\n",
            "Response: generations=[[Generation(text=' The defending Super Bowl champions were the Baltimore Colts, who defeated the New York Jets in Super Bowl III. The Colts were the first NFL team to win a Super Bowl. ')]] llm_output=None run=[RunInfo(run_id=UUID('1cc37f50-21b2-4287-96a5-a8a876ff656a'))]\n",
            "Processing question 39/100\n",
            "Response: generations=[[Generation(text=' The answer is New England Patriots, Pittsburgh Steelers, Dallas Cowboys, and San Francisco 49ers have all been to the Super Bowl 8 times. ')]] llm_output=None run=[RunInfo(run_id=UUID('3a01304f-9abd-4c16-8cc9-62dcc0fa63fe'))]\n",
            "Processing question 40/100\n",
            "Response: generations=[[Generation(text=\" Tom Brady was the NFL MVP for the 2007-2008 NFL season.  He was the quarterback for the New England Patriots and received the MVP award after that season's Super Bowl.  He was the first unanimous MVP in NFL history and remains the only quarterback to have won the MVP award in back-to-back seasons.  Brady is considered one of the greatest quarterbacks of all time, and during his career, he won seven Super Bowls, six Super Bowl MVP awards, three regular season MVP awards, and was selected to the Pro Bowl 15 times.  He retired from the NFL in 2022, after 23 seasons with the Patriots.  Would you like to know more about Tom Brady's career? \")]] llm_output=None run=[RunInfo(run_id=UUID('81ecb475-d993-49c5-9e57-3adc4e0f0cd9'))]\n",
            "Processing question 41/100\n",
            "Response: generations=[[Generation(text=' 3 BHK + Study unit in any one of the following blocks \\nBLK 92, BLK 94, BLK 96, BLK 98 \\nthen you are eligible for an extra commission kicker of 0.005\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\n\\nThe relevant information to answer the question is the list of blocks where 3 BHK + Study units can be found, and the number of deals and the commission rate that applies to them.\\n\\nTherefore, the answer is 2 to 4.')]] llm_output=None run=[RunInfo(run_id=UUID('62a5741f-155e-4115-8f48-35df5be132a4'))]\n",
            "Processing question 42/100\n",
            "Response: generations=[[Generation(text=' Cam Newton')]] llm_output=None run=[RunInfo(run_id=UUID('a31553e5-3741-413f-8f62-493aee97993c'))]\n",
            "Processing question 43/100\n",
            "Response: generations=[[Generation(text=' The Denver Broncos played 16 games during the 2015 regular season, winning 12 and losing 4. ')]] llm_output=None run=[RunInfo(run_id=UUID('c8d93ee6-ecc8-4576-9244-963256384ce1'))]\n",
            "Processing question 44/100\n",
            "Response: generations=[[Generation(text=' The only team to have played in the Super Bowl eight times is the Pittsburgh Steelers.  They won the Super Bowl in 1974, 1975, 1978, 1979, 1980, 2006, 2009, and 2010, which equals eight appearances throughout the years.  They also hold the record for most Super Bowl victories with six.  Although the Dallas Cowboys have also appeared in the Super Bowl eight times, they have only won it five times, which is still an impressive record.  The Cowboys appeared in the Super Bowl in 1970, 1971, 1973, 1978, 1979, 1981, 1992, and 1995 but fell short of winning all eight times.  Overall, the Steelers have the most Super Bowl appearances and the most Super Bowl victories out of any team that has played in the Super Bowl.  Although the Cowboys have the second-most Super Bowl appearances, they are still behind the Steelers in terms of victories.  The Cowboys have five Super Bowl victories, which is still an extremely impressive record and ranks them as one of the most successful teams in NFL history.  Overall, the Steelers and the Cowboys are the only two teams with eight Super Bowl appearances, but the Steelers have the most Super Bowl victories out of the two teams.  This is an impressive record that is unlikely to be beaten')]] llm_output=None run=[RunInfo(run_id=UUID('3e65023e-353a-44c6-b332-97ce17f9dec2'))]\n",
            "Processing question 45/100\n",
            "Response: generations=[[Generation(text=' New England Patriots')]] llm_output=None run=[RunInfo(run_id=UUID('0c9c104d-8f05-415a-a259-41cad15de931'))]\n",
            "Processing question 46/100\n",
            "Response: generations=[[Generation(text=' Cam Newton')]] llm_output=None run=[RunInfo(run_id=UUID('61cd9f51-01c7-4b30-8b29-84578ac35a5b'))]\n",
            "Processing question 47/100\n",
            "Response: generations=[[Generation(text=' The answer is the Dallas Cowboys based on the information provided in the table. ')]] llm_output=None run=[RunInfo(run_id=UUID('2926b7a5-f4ab-4739-9f81-02829b8858c2'))]\n",
            "Processing question 48/100\n",
            "Response: generations=[[Generation(text=' The Panthers have been in the Super Bowl twice. They lost in 2004 and were defeated in 2016, against the New England Patriots and the Denver Broncos, respectively. ')]] llm_output=None run=[RunInfo(run_id=UUID('dbffb657-b432-46ea-bae6-cf1aa4ffc5ef'))]\n",
            "Processing question 49/100\n",
            "Response: generations=[[Generation(text=' The San Diego Chargers')]] llm_output=None run=[RunInfo(run_id=UUID('6565ba42-3f02-4488-9d44-5c6eee8238bf'))]\n",
            "Processing question 50/100\n",
            "Response: generations=[[Generation(text=\" The Most Valuable Player for the 2015 NFL season was Cam Newton, who played for the Carolina Panthers as a quarterback.  He was awarded the prestigious MVP award for his outstanding performance, leadership, and athleticism on the field that year.  He was also named the NFL Offensive Player of the Year, which is awarded to the player deemed to have had the most significant impact on their team's offensive performance.  Additionally, he was named the NFL passer rating leader, with a rating of 99.4, and was selected to the Pro Bowl, which is an annual all-star game featuring the best players from the National Football League.  He led the Panthers to a 15-1 record and an appearance in the Super Bowl, where they lost to the Denver Broncos.  Overall, he had an exceptional season and was widely recognized as one of the best players in the NFL.  His performance, leadership, and athleticism made him a dominant force in the league and earned him the MVP award.  He was also named the NFL Offensive Player of the Year and was selected to the Pro Bowl, further cementing his status as one of the top players in the league.  He led the Panthers to a successful season and came close to winning the Super Bowl, ultimately falling just\")]] llm_output=None run=[RunInfo(run_id=UUID('272877ba-6365-41fc-8ca4-e25be02eba6a'))]\n",
            "Processing question 51/100\n",
            "Response: generations=[[Generation(text=' The New England Patriots')]] llm_output=None run=[RunInfo(run_id=UUID('c3e1e95c-c043-49a6-9c0b-3de044f7c431'))]\n",
            "Processing question 52/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers beat the Arizona Cardinals 49-15 in the 2015 NFC Championship game. The Panthers went on to lose to the Denver Broncos in Super Bowl 50. ')]] llm_output=None run=[RunInfo(run_id=UUID('d03d01a3-6a1d-46bd-8d41-adc73bc6cc0c'))]\n",
            "Processing question 53/100\n",
            "Response: generations=[[Generation(text=' Tom Brady was the 2015 NFL MVP. He is an American football quarterback for the New England Patriots of the National Football League (NFL). He has won a record seven Super Bowls for the Patriots and has been named NFL MVP three times. ')]] llm_output=None run=[RunInfo(run_id=UUID('97698817-8c24-4201-8dab-31bb43a4f047'))]\n",
            "Processing question 54/100\n",
            "Response: generations=[[Generation(text=' The panthers beat the saints to become the NFC champs')]] llm_output=None run=[RunInfo(run_id=UUID('074c325e-3317-4ebf-9422-4bcd38fa59c5'))]\n",
            "Processing question 55/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers formed in 1993.')]] llm_output=None run=[RunInfo(run_id=UUID('5f6ffe64-5fca-45aa-bc9e-e693c29a205e'))]\n",
            "Processing question 56/100\n",
            "Response: generations=[[Generation(text=' Cam Newton')]] llm_output=None run=[RunInfo(run_id=UUID('6c89696c-94a0-4af5-8c34-9272192b5b84'))]\n",
            "Processing question 57/100\n",
            "Response: generations=[[Generation(text=' Von Miller forced 2 fumbles during Super Bowl 50.  He was also named the Super Bowl 50 MVP, becoming the first player in NFL history to win the Super Bowl MVP award with a sack, a forced fumble, a fumble recovery, and an interception.  Miller had 2.5 sacks, five tackles, 2 forced fumbles, and one fumble recovery in the game.  This performance tied him for the most sacks in a Super Bowl with Michael Strahan, who achieved the same statistic in Super Bowl 46.  Von Miller is currently a defensive captain for the Buffalo Bills.  He has the most total sacks in the NFL since 2011, with 115.5 sacks.  He has also made 5 Pro Bowls and 6 All-Pro teams.  Von Miller is widely regarded as one of the best defensive players in the NFL, if not the best, and is under contract with the Buffalo Bills through the 2023-24 NFL season.  He has made at least 10 sacks in every NFL season from 2011 to 2021, and is currently ranked 7th all-time in total sacks in NFL history.  Von Miller has also won a Super Bowl in every NFL stadium, a feat which no other player in NFL history has been able to achieve.  He is currently the')]] llm_output=None run=[RunInfo(run_id=UUID('8090a83e-afd7-4f1d-8135-d888dc8320e8'))]\n",
            "Processing question 58/100\n",
            "Response: generations=[[Generation(text=' The New York Rangers hockey team scored the most points in the regular season, but they lost the scoring lead to the Pittsburgh Penguins during the playoffs. ')]] llm_output=None run=[RunInfo(run_id=UUID('28050857-5233-4c70-96d9-430cf0410dba'))]\n",
            "Processing question 59/100\n",
            "Response: generations=[[Generation(text=' Von Miller was the Denver linebacker named Super Bowl MVP, who played for the Denver Broncos and was crucial in their victory at Super Bowl 50.  He was named MVP of the game and also won the Butkus Award, an award given to the best linebackers in college football during his time at Texas A&M.  He was drafted by the Denver Broncos in the 2011 NFL Draft, and has since won many other accolades and honors for his outstanding play in the NFL.  He is currently one of the captains of the Broncos and continues to play a key role in their success.  He is known for his impressive speed and ability to get to the quarterback, as well as his leadership on and off the field.  He is considered one of the best linebackers in the NFL and has been named to the Pro Bowl multiple times.  He is also a vocal leader on the team and has been known to speak out on social issues.  He is a popular player among fans and has a large following on social media.  He is known for his charitable work and has been involved in many community service projects.  He is a role model for many young athletes and is considered a leader on and off the field.  He is also a very successful businessman and has many')]] llm_output=None run=[RunInfo(run_id=UUID('eff98fde-96f6-4529-8a29-82b4e5334119'))]\n",
            "Processing question 60/100\n",
            "Response: generations=[[Generation(text=' Von Miller made 2 solo tackles at Super Bowl 50.  He also made 1 assist, 1 sack, and 1 forced fumble during the game.  Von Miller was named the Super Bowl 50 MVP.  He also won a car, a trip, and a diamond ring worth $123,000.  The game took place on February 7, 2016 at Levi\\'s Stadium in Santa Clara, California.  The final score was Denver Broncos 24, Carolina Panthers 10.  The game was watched by an estimated average audience of 111.31 million television viewers.  This made it the most-watched Super Bowl in \"average audience\" television history.  The game was also streamed by an estimated average audience of 1.4 million concurrent viewers, which was the highest ever for a Super Bowl and the largest ever for any NFL game.  The game was officiated by Bill Vinovich, who was assisted by Wayne Mackie, Kent Payne, Tom Hill, Jim Howey, Gary Cavaletto, and Keith Ferguson.  The game was also attended by several celebrities such as Beyonce, who performed the halftime show, and Justin Timberlake, who performed during the halftime show as well.  Other celebrities who attended the game included George Clooney, Cindy Crawford, and Kobe Bryant.')]] llm_output=None run=[RunInfo(run_id=UUID('a106f7a4-78f9-414c-980f-15568ba2e3e9'))]\n",
            "Processing question 61/100\n",
            "Response: generations=[[Generation(text=' Tom Brady')]] llm_output=None run=[RunInfo(run_id=UUID('dd3b9d2c-0970-4946-97f4-43e18efe84cc'))]\n",
            "Processing question 62/100\n",
            "Response: generations=[[Generation(text=\" Cam Newton was sacked four times during the game.  It was a high-pressure game, with the opposing team's defense being particularly effective, resulting in an upset victory and advancing to the Super Bowl.  It is worth noting that Cam Newton is a renowned and highly accomplished quarterback with a strong track record of success in the NFL.  However, despite his skills and experience, he was unable to effectively overcome the opposing defense and avoid the sacks during the particular game in question.  It is also important to consider the context and dynamics of the game, as well as the strategies employed by both teams, which can influence the number of sacks a quarterback may experience in any given game.  Overall, this game was a notable example of a strong defensive performance and serves as a reminder of the importance of a robust offensive strategy and effective protection of the quarterback in football.  It will be interesting to see how Cam Newton and the team respond to this game and continue their season in the upcoming weeks and tournaments.  Aside from this game, Cam Newton has had a successful career and has made numerous noteworthy contributions to the sport of American football.  Despite this setback, he is still regarded as one of the top players in the league and continues to be a dominant force on the field.\")]] llm_output=None run=[RunInfo(run_id=UUID('6d8d97c4-c0a7-4991-a975-e8fc8dd42832'))]\n",
            "Processing question 63/100\n",
            "Response: generations=[[Generation(text=' Tom Brady')]] llm_output=None run=[RunInfo(run_id=UUID('5ddbb46b-d493-40aa-a623-b7f69e8cbb9f'))]\n",
            "Processing question 64/100\n",
            "Response: generations=[[Generation(text=' Cam Newton had 39 turnovers in 2015.  This was the highest total among all quarterbacks that year.  Hopefully he can lower his turnovers in the upcoming season.  His high turnover numbers are a large reason why the Panthers missed the playoffs last year.  Lower turnovers and the Panthers should be in the playoff hunt again this season.  Hopefully, Cam can lower his thrown interceptions as well.  He had a career-high 35 interceptions last year.  This was also the highest total in the league.  He needs to limit the interceptions to help the Panthers win more games.  They were 3-8 in games where he threw for multiple interceptions.  If he can limit his turnovers, the Panthers should be able to win more games and get back into the playoff hunt.  They have a very tough schedule this year.  They will need Cam to play better and limit his turnovers if they want to have a winning season.  He is one of the best players in the league and is capable of having a great season.  His turnovers have been very high the past few seasons.  He needs to limit them this year to help the Panthers win more games.  They have a lot of talent on their team and should be able to make some noise in the playoffs')]] llm_output=None run=[RunInfo(run_id=UUID('8bc1154c-31cc-4557-989f-740a9633d210'))]\n",
            "Processing question 65/100\n",
            "Response: generations=[[Generation(text=' 4')]] llm_output=None run=[RunInfo(run_id=UUID('7e9a1c3b-28ce-46e8-915b-a117ae6c91d7'))]\n",
            "Processing question 66/100\n",
            "Response: generations=[[Generation(text=' The MVP award for Super Bowl 50 was given to Denver Broncos quarterback Peyton Manning.  He was able to lead his team to a 24-10 victory over the Carolina Panthers, winning their third Super Bowl championship. Manning threw for 141 yards and scored the only touchdown for the team, earning him the Super Bowl MVP title. ')]] llm_output=None run=[RunInfo(run_id=UUID('4d91c4e3-5f85-43e1-a7a7-698759779a2a'))]\n",
            "Processing question 67/100\n",
            "Response: generations=[[Generation(text=' Linebacker')]] llm_output=None run=[RunInfo(run_id=UUID('c0b68b50-e2c6-4c6c-a3a5-772b61bf5f25'))]\n",
            "Processing question 68/100\n",
            "Response: generations=[[Generation(text=' 18')]] llm_output=None run=[RunInfo(run_id=UUID('56a1a89c-d6a2-4f3b-a2a8-cf7f4ccbf602'))]\n",
            "Processing question 69/100\n",
            "Response: generations=[[Generation(text=' Von Miller did not have any forced fumbles during the Super Bowl 50 game, which is formally known as the \"Peyton Manning Bowl.\"')]] llm_output=None run=[RunInfo(run_id=UUID('68571644-0428-413b-822b-e457a32819c8'))]\n",
            "Processing question 70/100\n",
            "Response: generations=[[Generation(text=' Tom Brady')]] llm_output=None run=[RunInfo(run_id=UUID('54501d8c-a531-4ecc-b43e-4435e814d122'))]\n",
            "Processing question 71/100\n",
            "Response: generations=[[Generation(text=' Von Miller got 2 tackles during the game. ')]] llm_output=None run=[RunInfo(run_id=UUID('e02f8660-ed08-4b13-bb37-9dcb39f53351'))]\n",
            "Processing question 72/100\n",
            "Response: generations=[[Generation(text=' Cam Newton was sacked 6 times during Super Bowl 50.  He was also responsible for 4 turnovers during the game.  The Carolina Panthers fell short to the Denver Broncos by a score of 24-10.')]] llm_output=None run=[RunInfo(run_id=UUID('fc88fff8-faaa-48ee-a7c7-5b1c51356117'))]\n",
            "Processing question 73/100\n",
            "Response: generations=[[Generation(text=' The answer is The Denver defense forced Newton into turnovers three times, with two fumbles and one interception. ')]] llm_output=None run=[RunInfo(run_id=UUID('0f3f7d79-aa81-46ec-8615-ab16acfe07c9'))]\n",
            "Processing question 74/100\n",
            "Response: generations=[[Generation(text=' I am unable to provide an answer to the question you asked because the provided information does not contain any information on Newton Turnovers or sports related points however I can provide you with information on the provided example of a commission structure in the sales industry if you would like? ')]] llm_output=None run=[RunInfo(run_id=UUID('9ec4f4ec-a39d-4fe8-a870-a24b85fdc1b9'))]\n",
            "Processing question 75/100\n",
            "Response: generations=[[Generation(text=' The answer is Peyton Manning, who was the MVP of Super Bowl 50. He was the quarterback for the Denver Broncos, who defeated the Carolina Panthers 24-10. ')]] llm_output=None run=[RunInfo(run_id=UUID('b9dd39e7-be40-4874-b473-bbe0b3517ebb'))]\n",
            "Processing question 76/100\n",
            "Response: generations=[[Generation(text=' Linebacker')]] llm_output=None run=[RunInfo(run_id=UUID('fad9e9ea-b8e5-4a1a-9997-d767dbfb316b'))]\n",
            "Processing question 77/100\n",
            "Response: generations=[[Generation(text=' four times')]] llm_output=None run=[RunInfo(run_id=UUID('3a4bd62e-7359-4404-b33c-9399ca94e6e2'))]\n",
            "Processing question 78/100\n",
            "Response: generations=[[Generation(text=' The answer is The Broncos caused turnovers three times in the game, with two forced fumbles and one interception. ')]] llm_output=None run=[RunInfo(run_id=UUID('e4a1f317-06eb-4c0f-a254-04b5d500a7b7'))]\n",
            "Processing question 79/100\n",
            "Response: generations=[[Generation(text=' None')]] llm_output=None run=[RunInfo(run_id=UUID('b6b3330b-f56d-40ad-9708-72951598ad09'))]\n",
            "Processing question 80/100\n",
            "Response: generations=[[Generation(text=' Von Miller achieved 2.0 tackles by himself during the game. ')]] llm_output=None run=[RunInfo(run_id=UUID('da8a1ba5-5c29-4418-8b6e-7016575eec8d'))]\n",
            "Processing question 81/100\n",
            "Response: generations=[[Generation(text=' CBS Sports')]] llm_output=None run=[RunInfo(run_id=UUID('9ddd73a9-5169-4abf-a4ce-5fb8c7259e0f'))]\n",
            "Processing question 82/100\n",
            "Response: generations=[[Generation(text=' The average cost for a 30 second commercial during Super Bowl 50 was around $50 million. This number is highly variable and dependent on many factors, such as the demand for advertising time, the time of day, and the number of people watching. It is also important to note that this number is only an average and does not reflect the actual cost for any specific commercial. ')]] llm_output=None run=[RunInfo(run_id=UUID('cce8bd67-ae73-42e4-bd5f-d65ad953dd88'))]\n",
            "Processing question 83/100\n",
            "Response: generations=[[Generation(text=' The answer cannot be determined from the provided information. ')]] llm_output=None run=[RunInfo(run_id=UUID('a3ba0812-e947-4f55-8c78-fa3ea05c16d4'))]\n",
            "Processing question 84/100\n",
            "Response: generations=[[Generation(text=' Chris Martin, Bruno Mars, and Beyonce')]] llm_output=None run=[RunInfo(run_id=UUID('e09bf236-4ffd-44b1-963c-e4b69bb26354'))]\n",
            "Processing question 85/100\n",
            "Response: generations=[[Generation(text=' Beyonce was the headline performer at the Super Bowl XLVII halftime show in 2013. Her performance was held in the Mercedes-Benz Superdome in New Orleans, Louisiana, and was seen by a record audience of over 110 million viewers. It was the culmination of a series of spectacular halftime shows that she had been putting on since 2013. ')]] llm_output=None run=[RunInfo(run_id=UUID('08427fab-5dee-4e21-acf5-2059c9ca4f08'))]\n",
            "Processing question 86/100\n",
            "Response: generations=[[Generation(text=' CBS Sports')]] llm_output=None run=[RunInfo(run_id=UUID('5d86ae41-3059-4715-bc49-8d82554610d9'))]\n",
            "Processing question 87/100\n",
            "Response: generations=[[Generation(text=' None')]] llm_output=None run=[RunInfo(run_id=UUID('9256be8e-4551-4818-a1f5-1e9a82af9473'))]\n",
            "Processing question 88/100\n",
            "Response: generations=[[Generation(text=' Beyonce')]] llm_output=None run=[RunInfo(run_id=UUID('a09c850f-254d-4e06-ba77-b50958091f65'))]\n",
            "Processing question 89/100\n",
            "Response: generations=[[Generation(text=' Bruno Mars')]] llm_output=None run=[RunInfo(run_id=UUID('87c88193-fe27-481f-b0af-653e1aee582f'))]\n",
            "Processing question 90/100\n",
            "Response: generations=[[Generation(text=' There was no mention of a performer at a halftime show in the provided text, which appears to be a specification list for a condominium building. If you intend to inquire about a different topic, please provide additional context or details so that I can better assist you. ')]] llm_output=None run=[RunInfo(run_id=UUID('0784e368-b0f9-459c-aa02-8def8dbe0c38'))]\n",
            "Processing question 91/100\n",
            "Response: generations=[[Generation(text=' CBS')]] llm_output=None run=[RunInfo(run_id=UUID('541deb9d-997e-4b92-8796-ccbf213b7067'))]\n",
            "Processing question 92/100\n",
            "Response: generations=[[Generation(text='\\n\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\n\\nHelp Text: \\nThe provided text refers to a residential property development that offers smart intercom features for visitors, as well as energy-efficient design and features for the buildings in the')]] llm_output=None run=[RunInfo(run_id=UUID('0bc4a31e-ec8c-444d-8153-b284ab1e8d9e'))]\n",
            "Processing question 93/100\n",
            "Response: generations=[[Generation(text=' Chris Martin')]] llm_output=None run=[RunInfo(run_id=UUID('24dbcfd8-2f98-4cc8-bbd2-4f5a6085a5fd'))]\n",
            "Processing question 94/100\n",
            "Response: generations=[[Generation(text=' 20')]] llm_output=None run=[RunInfo(run_id=UUID('da57c8d7-ffc9-4986-b248-c1bf699f6329'))]\n",
            "Processing question 95/100\n",
            "Response: generations=[[Generation(text=' Tanjong Katong MRT Station')]] llm_output=None run=[RunInfo(run_id=UUID('6cb8616b-98b8-4ada-a0a0-4e43a6980e32'))]\n",
            "Processing question 96/100\n",
            "Response: generations=[[Generation(text=' The answer is unfortunately not explicitly provided in the text. ')]] llm_output=None run=[RunInfo(run_id=UUID('51dc46d7-0a0e-4e73-96de-ff9934835b4e'))]\n",
            "Processing question 97/100\n",
            "Response: generations=[[Generation(text=' Coldplay')]] llm_output=None run=[RunInfo(run_id=UUID('a11f1504-dec0-42bc-addf-51d8a3857144'))]\n",
            "Processing question 98/100\n",
            "Response: generations=[[Generation(text=' Dr. Dre and Anderson Paak were the artists that performed with Coldplay during the 2022 Super Bowl half-time show. ')]] llm_output=None run=[RunInfo(run_id=UUID('180c5ada-d619-4cfb-875c-670f10ff3bb9'))]\n",
            "Processing question 99/100\n",
            "Response: generations=[[Generation(text=' The Super Bowl is broadcasted on NBC, CBS, and Fox. ')]] llm_output=None run=[RunInfo(run_id=UUID('e2a2d4ec-bc9a-4154-b421-7452305e8be5'))]\n",
            "Processing question 100/100\n",
            "Response: generations=[[Generation(text=' The halftime show was headlined by Coldplay, with guest performers including Beyonce, Bruno Mars, and Mark Ronson, and the Youth Orchestra Los Angeles. ')]] llm_output=None run=[RunInfo(run_id=UUID('95092089-aaa7-42a8-98ba-bbd3ac9b18af'))]\n",
            "Latency: 312.71 seconds\n",
            "Accuracy: 0.00\n",
            "F1 Score: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qLajvjO5f0W",
        "outputId": "2eae0b46-a109-4351-cd37-022f5d7861a5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "from rouge import Rouge\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model_extended(retriever, generate_answer_function, dataset_name='squad', num_samples=100):\n",
        "    # Load the benchmark dataset\n",
        "    print(\"Loading dataset...\")\n",
        "    dataset = load_dataset(dataset_name)\n",
        "\n",
        "    # Extract a subset of the validation data\n",
        "    validation_data = dataset['validation']\n",
        "    sample_data = validation_data.select(range(num_samples))\n",
        "\n",
        "    contexts = [item['context'] for item in sample_data]\n",
        "    questions = [item['question'] for item in sample_data]\n",
        "    true_answers = [item['answers']['text'][0] for item in sample_data]\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, (context, question) in enumerate(zip(contexts, questions), start=1):\n",
        "        print(f\"Processing question {i}/{num_samples}\")\n",
        "        # Retrieve relevant documents for the question\n",
        "        search_results = retriever.invoke(question)\n",
        "        relevant_docs = search_results\n",
        "        formatted_context = format_docs(relevant_docs)\n",
        "\n",
        "        # Generate an answer\n",
        "        result = generate_answer_function(question, formatted_context)\n",
        "        predictions.append(result)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate Latency\n",
        "    latency = end_time - start_time\n",
        "\n",
        "    # Calculate Precision and Recall\n",
        "    def compute_precision_recall(pred, true):\n",
        "        pred_tokens = set(pred.split())\n",
        "        true_tokens = set(true.split())\n",
        "        intersection = pred_tokens.intersection(true_tokens)\n",
        "        precision = len(intersection) / len(pred_tokens) if pred_tokens else 0\n",
        "        recall = len(intersection) / len(true_tokens) if true_tokens else 0\n",
        "        return precision, recall\n",
        "\n",
        "    precisions, recalls = zip(*[compute_precision_recall(pred, true) for pred, true in zip(predictions, true_answers)])\n",
        "    avg_precision = np.mean(precisions)\n",
        "    avg_recall = np.mean(recalls)\n",
        "\n",
        "    # Calculate ROUGE Scores\n",
        "    rouge = Rouge()\n",
        "    rouge_scores = rouge.get_scores(predictions, true_answers, avg=True)\n",
        "\n",
        "    # Calculate BLEU Scores\n",
        "    bleu_scores = [sentence_bleu([true.split()], pred.split()) for pred, true in zip(predictions, true_answers)]\n",
        "    avg_bleu = np.mean(bleu_scores)\n",
        "\n",
        "    # Exact Match\n",
        "    def compute_exact_match(pred, true):\n",
        "        return int(pred.strip().lower() == true.strip().lower())\n",
        "\n",
        "    accuracy = np.mean([compute_exact_match(pred, true) for pred, true in zip(predictions, true_answers)])\n",
        "\n",
        "    print(f\"Latency: {latency:.2f} seconds\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Precision: {avg_precision:.2f}\")\n",
        "    print(f\"Recall: {avg_recall:.2f}\")\n",
        "    print(f\"ROUGE Scores: {rouge_scores}\")\n",
        "    print(f\"Average BLEU Score: {avg_bleu:.2f}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define your `generate_answer` function with context parameter\n",
        "    def generate_answer_with_context(question, context):\n",
        "        cohere_llm = Cohere(model=\"command\", temperature=0.1, cohere_api_key=os.getenv('zqr9XSBYfGM0p2CvhySt971mIWHELJaMK85x6SLO'))\n",
        "\n",
        "        prompt_template = f\"\"\"\n",
        "        Context: {context}\n",
        "        Question: {question}\n",
        "        Answer:\"\"\"\n",
        "\n",
        "        response = cohere_llm.generate([prompt_template])\n",
        "        print(\"Response:\", response)\n",
        "\n",
        "        if isinstance(response, list) and len(response) > 0 and 'text' in response[0]:\n",
        "            return response[0]['text'].strip()\n",
        "        else:\n",
        "            return \"No answer generated\"\n",
        "\n",
        "    # Evaluate the model\n",
        "    evaluate_model_extended(retriever, generate_answer_with_context)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKYRSmHl48_r",
        "outputId": "fbb842ae-1529-4d98-aa31-4a1735e2de0f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Processing question 1/100\n",
            "Response: generations=[[Generation(text=' The answer is The Denver Broncos represented the AFC at Super Bowl 50')]] llm_output=None run=[RunInfo(run_id=UUID('129f0ae3-fe7b-472c-874a-f0bf4d603ea4'))]\n",
            "Processing question 2/100\n",
            "Response: generations=[[Generation(text=' Carolina Panthers')]] llm_output=None run=[RunInfo(run_id=UUID('a33425f1-f8e1-45a0-b603-462c74402ea0'))]\n",
            "Processing question 3/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl is an annual American football game that determines the league champion. The 50th Super Bowl was played in 2016, and was won by the Denver Broncos, who defeated the Carolina Panthers by a score of 24–10. The game was played on February 7, 2016 at Levi's Stadium in Santa Clara, California. \")]] llm_output=None run=[RunInfo(run_id=UUID('c095c833-8019-40ec-9e11-71076a0a04d2'))]\n",
            "Processing question 4/100\n",
            "Response: generations=[[Generation(text=' The Denver Broncos won Super Bowl 50, defeating the Carolina Panthers by a score of 24-10. This win gave the Broncos their third Super Bowl victory and first since 1998. ')]] llm_output=None run=[RunInfo(run_id=UUID('257160e3-3232-4ae5-9bb9-c632e10535c6'))]\n",
            "Processing question 5/100\n",
            "Response: generations=[[Generation(text=\" The color was blue, according to NFL reporter Brian Sexton, although the league didn't confirm that color until two years later, in 2022. \")]] llm_output=None run=[RunInfo(run_id=UUID('0a57f011-cb1b-4976-870b-ddfacaf4b714'))]\n",
            "Processing question 6/100\n",
            "Response: generations=[[Generation(text=' The theme of Super Bowl 50 was \"Golden Anniversary\" and the Pepsi Halftime Show featured a performance by Coldplay, who opened with a rendition of \"Yellow\" and was accompanied by singer Beyonce. The show also featured spectacular lighting and an array of fireworks, creating an impressive visual experience for the audience.')]] llm_output=None run=[RunInfo(run_id=UUID('a00efe91-df66-4fb6-8bef-fd9aedb6cf4d'))]\n",
            "Processing question 7/100\n",
            "Response: generations=[[Generation(text=' The game was played on Sunday, as referred to by the abbreviation \"Sun\" in the third column of the table.  Please let me know if you would like me to clarify any part of the provided information. ')]] llm_output=None run=[RunInfo(run_id=UUID('33e4745f-70a5-422a-8de4-2db59cee21e4'))]\n",
            "Processing question 8/100\n",
            "Response: generations=[[Generation(text=' Tembusu Grand')]] llm_output=None run=[RunInfo(run_id=UUID('a366bdd3-36dd-4c7c-883a-6bab5144e772'))]\n",
            "Processing question 9/100\n",
            "Response: generations=[[Generation(text=' The theme of Super Bowl 50 was \"Golden Anniversary\" and the Pepsi Halftime Show featured a performance by Coldplay, who opened with a rendition of \"Yellow\" and was accompanied by singer Beyonce. The show also featured stunning visuals and an impressive light show, making it a memorable performance for the 50th Super Bowl. ')]] llm_output=None run=[RunInfo(run_id=UUID('863cf5bb-a761-4d66-b7fb-59a7c36f0fb7'))]\n",
            "Processing question 10/100\n",
            "Response: generations=[[Generation(text=' Air-conditioning system. ')]] llm_output=None run=[RunInfo(run_id=UUID('079a459e-1d00-4ade-87b1-e5ffaaeabe87'))]\n",
            "Processing question 11/100\n",
            "Response: generations=[[Generation(text=' The Super Bowl is always played on a Sunday except for two years when it was played on a Monday (the game went into overtime). The specific date varies from year to year.  For example, Super Bowl I was played on January 15, 1967, Super Bowl II was played on January 14, 1968 and Super Bowl XLV was played on February 6, 2011.  The upcoming Super Bowl LV will be played on Sunday, February 7, 2021.  So the answer is: it varies from year to year and the game is always played on a Sunday.  Hope this helps.  Let me know if you want to know anything else.  I am happy to provide any other information you may need.  Cheers!')]] llm_output=None run=[RunInfo(run_id=UUID('5c742e5e-d6d9-4e7f-9c1e-5de0fca0bfe2'))]\n",
            "Processing question 12/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers lost the Super Bowl 50 to the Denver Broncos and therefore did not win Super Bowl 50. ')]] llm_output=None run=[RunInfo(run_id=UUID('5c0f8aad-0dd4-4e08-900a-18e4dc163be9'))]\n",
            "Processing question 13/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 took place in the Levi's Stadium located in Santa Clara, California. It was the first Super Bowl to take place in the San Francisco Bay Area since Super XIX in 1985. The game was played between the Denver Broncos and the Carolina Panthers with the Broncos winning 24-10. \")]] llm_output=None run=[RunInfo(run_id=UUID('94c2a866-0729-405b-8a15-7bcb694927bb'))]\n",
            "Processing question 14/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 took place in Santa Clara, California, US. It was the first Super Bowl to be played on the West Coast in 15 years. The game was played on February 7, 2016, at Levi's Stadium with the Denver Broncos defeating the Carolina Panthers by a score of 24–10. \")]] llm_output=None run=[RunInfo(run_id=UUID('48e9bb7b-2be7-42ba-bf33-6fa53e7da350'))]\n",
            "Processing question 15/100\n",
            "Response: generations=[[Generation(text=' Answer: \\nThe Roman numeral for 50 is L. So if the Super Bowl was to be represented using Roman numerals, Super Bowl 50 would be known as Super Bowl L. ')]] llm_output=None run=[RunInfo(run_id=UUID('1b3a24a3-d0ba-496e-bea6-83e5b4d7647f'))]\n",
            "Processing question 16/100\n",
            "Response: generations=[[Generation(text=' The 2015 NFL season')]] llm_output=None run=[RunInfo(run_id=UUID('325aebdc-7408-4611-963d-fb0a32d5d3ab'))]\n",
            "Processing question 17/100\n",
            "Response: generations=[[Generation(text=' The Denver Broncos secured a Super Bowl title for the third time in 1998.  Although they have won several Super Bowl titles since, 1998 remains a memorable year for the team.  This was also the last Super Bowl win for the Broncos before the upcoming 2022-2023 season. ')]] llm_output=None run=[RunInfo(run_id=UUID('70fdf9ba-47c1-4e8c-a24d-4b9a850760fa'))]\n",
            "Processing question 18/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 took place in Santa Clara, California, US. It was the first Super Bowl to be played on the West Coast in 15 years. The game was played on February 7, 2016, at Levi's Stadium in Santa Clara, with the Denver Broncos defeating the Carolina Panthers by a score of 24–10. \")]] llm_output=None run=[RunInfo(run_id=UUID('97a77069-853e-4839-ac0f-07009e37a1e2'))]\n",
            "Processing question 19/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl is an annual American football game that determines the league champion. The specific stadium where Super Bowl 50 was held is the Levi's Stadium, located in Santa Clara, California. It was the first Super Bowl to be played on the West Coast since Super Bowl XIX in 1995. \")]] llm_output=None run=[RunInfo(run_id=UUID('c9a47341-46d5-46aa-9761-4b1a28e0531c'))]\n",
            "Processing question 20/100\n",
            "Response: generations=[[Generation(text=' The final score of Super Bowl 50 was Denver Broncos - 24, Carolina Panthers - 10. ')]] llm_output=None run=[RunInfo(run_id=UUID('1deb67c9-af86-491b-9d54-d7ad5e69725d'))]\n",
            "Processing question 21/100\n",
            "Response: generations=[[Generation(text=' The answer is Super Bowl 50 took place on February 7, 2016. ')]] llm_output=None run=[RunInfo(run_id=UUID('5135cba7-d30c-40f7-9285-a4f9af5fec82'))]\n",
            "Processing question 22/100\n",
            "Response: generations=[[Generation(text=' Super Bowl 50 was played on February 7, 2016')]] llm_output=None run=[RunInfo(run_id=UUID('bdf8f41d-7242-42dc-abd0-b4bbe6723f09'))]\n",
            "Processing question 23/100\n",
            "Response: generations=[[Generation(text=' The Kansas City Chiefs were the AFC champions for the 2022-2023 season, winning against the Cincinnati Bengals 23-20 at the Mercedes-Benz Superdome in New Orleans, Louisiana. ')]] llm_output=None run=[RunInfo(run_id=UUID('2a16e8b3-864a-4165-8a6d-eb0abc3d3e7c'))]\n",
            "Processing question 24/100\n",
            "Response: generations=[[Generation(text=' San Francisco 49ers')]] llm_output=None run=[RunInfo(run_id=UUID('eceb3462-e984-4997-8f17-c96bcfa26a19'))]\n",
            "Processing question 25/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers lost the Super Bowl 50 to the Denver Broncos and therefore did not win Super Bowl 50. ')]] llm_output=None run=[RunInfo(run_id=UUID('176cf379-3ef7-424f-a662-0feb9babf616'))]\n",
            "Processing question 26/100\n",
            "Response: generations=[[Generation(text=' 2015')]] llm_output=None run=[RunInfo(run_id=UUID('73784fab-713d-4679-b519-598868ca35cb'))]\n",
            "Processing question 27/100\n",
            "Response: generations=[[Generation(text=' The answer is the Denver Broncos. The Super Bowl is an annual American football game that determines the league champion. The 50th Super Bowl was played on February 7, 2016, and the Denver Broncos defeated the Carolina Panthers 24–10. ')]] llm_output=None run=[RunInfo(run_id=UUID('57ff1343-ff93-412f-b716-c39132376baf'))]\n",
            "Processing question 28/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 was held in Santa Clara, California, at the Levi's Stadium which is located in the San Francisco Bay Area on February 7, 2016. It was the first Super Bowl to be played in the Bay Area since Super Bowl XIX, which was held in 1985 at Stanford Stadium. The game was played between the Denver Broncos and the Carolina Panthers, with the Broncos winning 24–10. \")]] llm_output=None run=[RunInfo(run_id=UUID('85dd3a4d-f8f6-4687-9508-4e5766b27b37'))]\n",
            "Processing question 29/100\n",
            "Response: generations=[[Generation(text=' Super Bowl')]] llm_output=None run=[RunInfo(run_id=UUID('45656f14-6111-4431-983b-c667ea0380b7'))]\n",
            "Processing question 30/100\n",
            "Response: generations=[[Generation(text=\" The New England Patriots won the AFC playoff game during the 2015 NFL season.  They ended up winning the Super Bowl that year, defeating the Seattle Seahawks, 28-24.  They were led by star quarterback Tom Brady, and head coach Bill Belichick.  This was the Patriots' fourth Super Bowl victory, with previous wins in 2001, 2003, and 2004.  They also appeared in the Super Bowl in 2007 and 2011, but lost both games.  The Patriots are a perennial powerhouse in the NFL, and have consistently been one of the top teams in the AFC, especially over the past two decades under Belichick and Brady.  They have won the AFC East division numerous times, and have made many deep playoff runs over the years.  They have been led by many great players over the years, such as Brady, Belichick, Randy Moss, and Rob Gronkowski, to name a few.  They have a very loyal and passionate fanbase, and are widely considered to be one of the most successful and well-run organizations in all of professional sports.  They have set numerous records and milestones over the years, and have consistently been a very competitive and entertaining team to watch.  They have also had some controversial moments and scandals over the\")]] llm_output=None run=[RunInfo(run_id=UUID('34aa1c23-00ea-4d9c-ad33-7d65cd1da242'))]\n",
            "Processing question 31/100\n",
            "Response: generations=[[Generation(text=\" The Most Valuable Player award, which was introduced in 1993, has been won by several Carolina Panthers players over the years. The players are as follows:\\n\\n1. Steve Smith Sr. (2005)\\n2. Julius Peppers (2006)\\n3. DeAngelo Williams (2008)\\n4. Cam Newton (2015)\\n5. Luke Kuechly (2015)\\n6. Jonathan Stewart (2017)\\n7. Christian McCaffrey (2019)\\n8. Teddy Bridgewater (2021)\\n\\nThe award is typically given to the player who had the greatest impact on the team's success during the season. \")]] llm_output=None run=[RunInfo(run_id=UUID('043c4443-18e4-4d36-8079-612c8542db75'))]\n",
            "Processing question 32/100\n",
            "Response: generations=[[Generation(text=' The Denver Broncos have made eight appearances in the Super Bowl.  They won the Super Bowl in 1997, 1998, 1999, and 2015.  Their four Super Bowl wins are a tied record for the NFL.  Their appearances in the Super Bowl were in 1977, 1986, 1989, 1997, 1998, 1999, 2013, and 2015.  Their win-loss record in the Super Bowl is 4-4.  Their four appearances in the 1990s were the most for any NFL team in that decade.  The Broncos are currently tied for fourth for the most Super Bowl appearances.  They have been to the Super Bowl in more than half the number of seasons they have been in the NFL, which shows their continued consistency.  This is an impressive record when you consider they have been in the NFL for over 50 years.  The Broncos are one of the most popular NFL teams, and they have a large and loyal fan base.  They have sold out every home game since 1970, which is an NFL record.  They have also set numerous NFL records for scoring and defensive performances.  The Broncos have one of the best home records in the NFL, and they have also been one of the most dominant road teams in the NFL.  They have a strong record against')]] llm_output=None run=[RunInfo(run_id=UUID('a360d45e-d32e-4270-b98e-09271fa55f1d'))]\n",
            "Processing question 33/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers were established in 1993 and joined the NFL as the 29th franchise in the NFL. They are the only active NFL team in the state of North Carolina, and have played their home games at Bank of America Stadium in Charlotte, North Carolina since 1996. ')]] llm_output=None run=[RunInfo(run_id=UUID('1d8ad183-fb51-403a-b6aa-d447bdd03aeb'))]\n",
            "Processing question 34/100\n",
            "Response: generations=[[Generation(text=' Eunos Bus Interchange')]] llm_output=None run=[RunInfo(run_id=UUID('e6022be7-7cde-4ab5-9823-430557b2c3b1'))]\n",
            "Processing question 35/100\n",
            "Response: generations=[[Generation(text=' The answer is not specified in the provided information. ')]] llm_output=None run=[RunInfo(run_id=UUID('52d22c01-f2ba-4266-afb4-eda296d671d2'))]\n",
            "Processing question 36/100\n",
            "Response: generations=[[Generation(text=' The Panthers beat the Cardinals in the NFC Championship Game during the 2015-2016 NFL season. ')]] llm_output=None run=[RunInfo(run_id=UUID('88852bc2-65ad-4678-82dc-0c156a02b634'))]\n",
            "Processing question 37/100\n",
            "Response: generations=[[Generation(text=' The Colts lost to the Broncos in the AFC Championship game in 2013')]] llm_output=None run=[RunInfo(run_id=UUID('d7b7aaad-e73f-4276-91b7-e89a94a09a97'))]\n",
            "Processing question 38/100\n",
            "Response: generations=[[Generation(text=' The defending Super Bowl champions were the Baltimore Colts, who defeated the New York Jets in Super Bowl III. The Colts were the first NFL team to win a Super Bowl. ')]] llm_output=None run=[RunInfo(run_id=UUID('0ac56ed1-6e7b-4573-8e40-7612cdee9ecc'))]\n",
            "Processing question 39/100\n",
            "Response: generations=[[Generation(text=' The New England Patriots have been to the Super Bowl eight times. They have won the Super Bowl six times. ')]] llm_output=None run=[RunInfo(run_id=UUID('230a93d9-51b9-4c61-b170-519e8d7fe47b'))]\n",
            "Processing question 40/100\n",
            "Response: generations=[[Generation(text=\" Tom Brady was the NFL MVP for the 2007-2008 NFL season.  He was the quarterback for the New England Patriots and received the MVP award after that season's Super Bowl, which was his second Super Bowl victory.  Brady was the first unanimous MVP in NFL history and remains the only quarterback in NFL history to win the Super Bowl MVP award three times.  Brady went on to win three more Super Bowls during his career with the Patriots and has the record for most career quarterback wins in NFL history.  He retired from the NFL following the 2022-2023 NFL season.  Aside from his MVP awards, Brady also holds records for career quarterback regular season wins, career quarterback playoff wins, and career quarterback Super Bowl wins.  He is considered one of the greatest NFL quarterbacks of all time.  Brady also won four Super Bowl MVP awards during his career, which is also an NFL record.  Aside from football, Brady also enjoys golf and has participated in and won several celebrity golf tournaments.  He also enjoys brand endorsement deals and has a line of apparel, including clothing, supplements, and other products bearing his name.  He also has a successful career as a celebrity endorser and has appeared in numerous television commercials over the course of his career.  He also has a\")]] llm_output=None run=[RunInfo(run_id=UUID('c7816192-3f47-44c0-b6f1-bc0ac6d0821d'))]\n",
            "Processing question 41/100\n",
            "Response: generations=[[Generation(text='\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone')]] llm_output=None run=[RunInfo(run_id=UUID('5ed1920d-6812-46d7-8a5c-89fdb7deb6a4'))]\n",
            "Processing question 42/100\n",
            "Response: generations=[[Generation(text=' Cam Newton')]] llm_output=None run=[RunInfo(run_id=UUID('2a66ae3a-a434-4c51-b208-dbba5f52ed9e'))]\n",
            "Processing question 43/100\n",
            "Response: generations=[[Generation(text=' The Denver Broncos played 16 games during the 2015 regular season, winning 12 and losing 4. ')]] llm_output=None run=[RunInfo(run_id=UUID('07f47931-f6dd-4c37-a9f2-2fb100f1594c'))]\n",
            "Processing question 44/100\n",
            "Response: generations=[[Generation(text=' The only team to have played in the Super Bowl eight times is the Pittsburgh Steelers.  They won the Super Bowl in 1974, 1975, 1978, 1979, 1980, 2006, 2009, and 2010, which equals eight appearances throughout the years.  They also hold the record for most appearances in the Super Bowl, with a total of nine appearances.  This record is yet to be surpassed and is one of the many accomplishments that the Steelers are proud of.  Although they have not won every time they have appeared, their dedication and perseverance have earned them the title of one of the greatest and most influential football teams in the history of the NFL.  Overall, the Pittsburgh Steelers are a legendary team that has made a significant impact on the sport of American football and will forever be remembered as one of the greatest teams in the history of the Super Bowl.  Their record of eight appearances in the Super Bowl is a testament to their skill, determination, and unwavering fan base.  They have consistently demonstrated their ability to excel and their unwavering commitment to the game.  This legacy will continue to inspire future generations of football fans and athletes alike.  Overall, the Steelers are a team that embodies the spirit and tradition of American football, and their record of eight Super Bowl appearances is a')]] llm_output=None run=[RunInfo(run_id=UUID('073904d3-1bbc-4ec9-99ab-372d19396c7b'))]\n",
            "Processing question 45/100\n",
            "Response: generations=[[Generation(text=' New England Patriots')]] llm_output=None run=[RunInfo(run_id=UUID('a4df9723-393e-40ee-aae8-b3cf4ba65655'))]\n",
            "Processing question 46/100\n",
            "Response: generations=[[Generation(text=' Cam Newton')]] llm_output=None run=[RunInfo(run_id=UUID('19a31c64-49a9-4510-b973-886d30446163'))]\n",
            "Processing question 47/100\n",
            "Response: generations=[[Generation(text=' The answer is the Dallas Cowboys based on the information provided in the table. ')]] llm_output=None run=[RunInfo(run_id=UUID('69db5cda-fbde-40af-b96e-5d007791b412'))]\n",
            "Processing question 48/100\n",
            "Response: generations=[[Generation(text=' The Panthers have been in the Super Bowl twice. They lost in 2003 and 2015. ')]] llm_output=None run=[RunInfo(run_id=UUID('2a7c1119-ed2c-4152-9785-e92cbff328c5'))]\n",
            "Processing question 49/100\n",
            "Response: generations=[[Generation(text=' The San Diego Chargers')]] llm_output=None run=[RunInfo(run_id=UUID('37259465-6d7b-4625-aa02-3dadc86b631f'))]\n",
            "Processing question 50/100\n",
            "Response: generations=[[Generation(text=\" The Most Valuable Player for the 2015 NFL season was Cam Newton, who played for the Carolina Panthers as a quarterback and was the first unanimous MVP in NFL history, as he received all 50 votes.  He was also named the Most Valuable Player by the Associated Press for this achievement.  This was a notable season for him as he led the Panthers to a 15-1 record and a trip to Super Bowl 50, where they ultimately lost to the Denver Broncos.  Additionally, he surpassed the 3,000-yard passing threshold for the first time in his career and became the first quarterback in NFL history to amass 3,000 yards passing and 500 yards rushing in a single season.  His stellar play helped lead the Panthers to an NFL-best 122.5 yards per game on the ground.  He was also named to the Pro Bowl and the First Team All-Pro for his efforts this season.  Overall, it was an incredible season for Cam Newton and the Panthers, despite falling short in the Super Bowl.  However, his individual achievements and contributions were recognized and rewarded with the MVP award for the 2015 NFL season.  It was a well-deserved honor for his outstanding play and leadership on the field.  And let's not forget that he also proved to\")]] llm_output=None run=[RunInfo(run_id=UUID('e0895fbc-1201-4e3f-804d-0fdec6a0378f'))]\n",
            "Processing question 51/100\n",
            "Response: generations=[[Generation(text=' The New England Patriots')]] llm_output=None run=[RunInfo(run_id=UUID('24bdda68-3a4d-429c-b020-7cc7263bb274'))]\n",
            "Processing question 52/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers beat the Arizona Cardinals 49-15 in the 2015 NFC Championship game. The Panthers went on to lose to the Denver Broncos in Super Bowl 50. ')]] llm_output=None run=[RunInfo(run_id=UUID('e65fa335-f004-42d6-9a83-e97896d257e9'))]\n",
            "Processing question 53/100\n",
            "Response: generations=[[Generation(text=' Tom Brady was the 2015 NFL MVP. He is an American football quarterback for the New England Patriots of the National Football League (NFL). He has won a record seven Super Bowls for the Patriots and has been named MVP of the Super Bowl four times. Brady has won three league MVP titles, has been selected to 14 Pro Bowls, and holds numerous all-time NFL passing records, including regular season and playoff wins, completions, touchdown passes, and career quarterback rating. He is considered one of the greatest quarterbacks of all time. ')]] llm_output=None run=[RunInfo(run_id=UUID('b5a1bdc4-4310-4965-94d0-4889a848855b'))]\n",
            "Processing question 54/100\n",
            "Response: generations=[[Generation(text=' The panthers beat the saints to become the NFC champs')]] llm_output=None run=[RunInfo(run_id=UUID('54016d69-d2f1-4666-b1b8-c14df8479966'))]\n",
            "Processing question 55/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers formed in 1993.')]] llm_output=None run=[RunInfo(run_id=UUID('05f0a3b4-e6f2-4463-970b-f5fc5f790283'))]\n",
            "Processing question 56/100\n",
            "Response: generations=[[Generation(text=' Cam Newton')]] llm_output=None run=[RunInfo(run_id=UUID('8b69bf9d-fdc9-4f28-b0bb-2bcab449705a'))]\n",
            "Processing question 57/100\n",
            "Response: generations=[[Generation(text=' Von Miller forced 2 fumbles during Super Bowl 50.  He was also named the Super Bowl 50 MVP, becoming the first player in NFL history to win the Super Bowl MVP award with a sack, a forced fumble, a fumble recovery, and an interception.  Miller had 2.5 sacks, five tackles, 2 forced fumbles, and one fumble recovery in the game.  This performance tied him for the highest number of sacks in a Super Bowl with Michael Strahan, who achieved the same record with the New York Giants against the New England Patriots in Super Bowl XLII.  Von Miller is widely regarded as one of the greatest defensive players in NFL history, and his record-breaking performances in the NFL have led to him being named a Pro Football Hall of Fame inductee in the future.  He has won many other awards during his NFL career, including but not limited to, 3 NFL Defensive Player of the Year awards, which is the most ever won by a linebacker in NFL history.')]] llm_output=None run=[RunInfo(run_id=UUID('41fac798-b01b-4461-bc51-64dc250bab66'))]\n",
            "Processing question 58/100\n",
            "Response: generations=[[Generation(text=' The Dallas Cowboys held the scoring lead throughout the entire game. ')]] llm_output=None run=[RunInfo(run_id=UUID('c417ca88-fe7a-4ee4-a71e-161c527cbca5'))]\n",
            "Processing question 59/100\n",
            "Response: generations=[[Generation(text=\" Von Miller was the Denver linebacker named Super Bowl MVP, who played for the Denver Broncos and was crucial in their victory at Super Bowl 50.  He was named MVP of the game and also won the Butkus Award, an award given to the best linebackers in college football during his time at Texas A&M.  He was drafted by the Denver Broncos and has had a successful career there, winning many other awards and accolades.  He is known for his impressive speed and ability to get to the quarterback, as well as his leadership on and off the field.  He has also been a spokesperson for various products and services, and is considered one of the best linebackers in the NFL.  He is currently still playing for the Broncos, and is considered a key player for the team's success.  He is looking to win another Super Bowl ring with the Broncos in the future.  He has been a key player in the team's success over the years and is considered one of the best linebackers in the NFL.  He is also a vocal leader on the team and has been known to be a positive presence in the locker room.  He is also a mentor to younger players on the team and helps them learn the ropes of the NFL.  He is\")]] llm_output=None run=[RunInfo(run_id=UUID('23505aa0-404a-4a20-a714-c11e53372c4b'))]\n",
            "Processing question 60/100\n",
            "Response: generations=[[Generation(text=' Von Miller made 2 solo tackles at Super Bowl 50.  He also made 1 assist, 1 sack, and 1 forced fumble during the game.  Von Miller was named the Super Bowl 50 MVP.  He finished the game with 4 total tackles, 2 of which were solo.  This game was his first and only Super Bowl appearance.  He played for the Denver Broncos who lost Super Bowl XLVIII to the Seattle Seahawks.')]] llm_output=None run=[RunInfo(run_id=UUID('2abcb181-3e7e-45c3-b802-d5b906879fcd'))]\n",
            "Processing question 61/100\n",
            "Response: generations=[[Generation(text=' Tom Brady')]] llm_output=None run=[RunInfo(run_id=UUID('42be50c9-4dc9-49b2-bf16-420096f155b2'))]\n",
            "Processing question 62/100\n",
            "Response: generations=[[Generation(text=\" Cam Newton was sacked four times during the game.  It was a high-pressure game, with the opposing team's defense being particularly effective, resulting in an upset victory.  It was a difficult loss for the team, who had been doing well throughout the season.  They will look to recover and come back stronger in the next game.  The quarterback, Cam Newton, needs to improve on his decision-making and avoid costly mistakes.  Overall it was a disappointing loss for the team and they will look to re-group and come back stronger in the next game.  Let's go Panthers! \")]] llm_output=None run=[RunInfo(run_id=UUID('355ac3ac-f1ce-4d62-ac2b-21574fbf78f1'))]\n",
            "Processing question 63/100\n",
            "Response: generations=[[Generation(text=' Tom Brady')]] llm_output=None run=[RunInfo(run_id=UUID('a76706d0-c639-4eee-8a36-c09980852ebf'))]\n",
            "Processing question 64/100\n",
            "Response: generations=[[Generation(text=\" Cam Newton had 39 turnovers in 2015.  This was the highest total among all quarterbacks that year.  Hopefully he can lower his number of turnovers in the upcoming season.  He definitely has the talent to do so.  He just needs to focus on ball security and avoid making sloppy passes that lead to turnovers.   He should definitely focus on this during the preseason so that he doesn't develop bad habits that carry over to the regular season.  I think he will do this and will have a great year in 2016.  He just needs to focus on the fundamentals and execute at a high level on every play.  I think he is definitely capable of doing this and will have a great year.  I think that he will be able to improve on his turnovers and will have a great year for the Carolina Panthers.  I think that they will make the playoffs again and will go on a deep run.  They have a very talented team and I think that they will be able to compete for a Super Bowl championship this year.  I think that Cam Newton will have a great year and will be able to improve on his turnovers from last season.  I am excited to see what he can do in 2016.  I think that he will have a great year and\")]] llm_output=None run=[RunInfo(run_id=UUID('e0a006b9-2dbf-405d-bfca-22a1aed02733'))]\n",
            "Processing question 65/100\n",
            "Response: generations=[[Generation(text=' 4')]] llm_output=None run=[RunInfo(run_id=UUID('f93f8b83-7462-4dc2-b01d-648e59dfee4e'))]\n",
            "Processing question 66/100\n",
            "Response: generations=[[Generation(text=' The MVP award for Super Bowl 50 was given to Denver Broncos quarterback Peyton Manning.  He was able to lead his team to a 24-10 victory over the Carolina Panthers, winning their third championship. Manning threw for 141 yards and scored the only touchdown for the team, earning him the Super Bowl MVP title. ')]] llm_output=None run=[RunInfo(run_id=UUID('3c906216-37c4-4ef2-b61f-f981235d902b'))]\n",
            "Processing question 67/100\n",
            "Response: generations=[[Generation(text=' Linebacker')]] llm_output=None run=[RunInfo(run_id=UUID('e6f7feb9-4135-4dec-a259-5871e921f994'))]\n",
            "Processing question 68/100\n",
            "Response: generations=[[Generation(text=' 18')]] llm_output=None run=[RunInfo(run_id=UUID('64922a34-578d-4621-a89e-a1fe47ff479b'))]\n",
            "Processing question 69/100\n",
            "Response: generations=[[Generation(text=' Von Miller did not have any forced fumbles during the Super Bowl 50 game, which is formally known as the \"Peyton Manning Bowl.\"')]] llm_output=None run=[RunInfo(run_id=UUID('f23b89ae-6e9d-4a13-989f-d740723fd023'))]\n",
            "Processing question 70/100\n",
            "Response: generations=[[Generation(text=' Tom Brady')]] llm_output=None run=[RunInfo(run_id=UUID('4d27f198-6d08-4515-a9af-e3abb92efb65'))]\n",
            "Processing question 71/100\n",
            "Response: generations=[[Generation(text=' Von Miller got 2 tackles during the game. ')]] llm_output=None run=[RunInfo(run_id=UUID('670fad9a-9fc4-498f-b0d6-cdcd898a34c2'))]\n",
            "Processing question 72/100\n",
            "Response: generations=[[Generation(text=\" Cam Newton was sacked 6 times during Super Bowl 50.  He was also responsible for 4 turnovers during the game.  The Panthers lost the game 24-10, with the Denver Broncos winning their third Super Bowl in franchise history.  This game was also future Hall of Fame quarterback Peyton Manning's final game in the NFL.  \")]] llm_output=None run=[RunInfo(run_id=UUID('cb9f74f8-1145-4ddf-a0cc-36f7fce72f23'))]\n",
            "Processing question 73/100\n",
            "Response: generations=[[Generation(text=' The answer is The Denver defense forced Newton into turnovers four times, with two fumbles and two interceptions. ')]] llm_output=None run=[RunInfo(run_id=UUID('80833a72-09aa-41f3-85c7-9046bc1f4bca'))]\n",
            "Processing question 74/100\n",
            "Response: generations=[[Generation(text=' I am unable to provide an answer to the question you asked because the provided information does not contain any information on Newton Turnovers or sports related points however I can provide you with information on the commission rates for various number of deals if that is helpful to you. ')]] llm_output=None run=[RunInfo(run_id=UUID('365859a7-de18-4652-a2ce-5497e6bcf585'))]\n",
            "Processing question 75/100\n",
            "Response: generations=[[Generation(text=' The Most Valuable Player of Super Bowl 50 was Cam Newton, who was the quarterback for the Carolina Panthers. He was named the Most Valuable Player of the game after leading his team to a 24-10 victory over the Denver Broncos. Newton threw for 322 yards and two touchdowns, and also rushed for 58 yards and a touchdown. He was the first quarterback in Super Bowl history to throw for over 300 yards and also rush for a touchdown in the same game. ')]] llm_output=None run=[RunInfo(run_id=UUID('18545a9f-aa7b-4b31-9127-464c28027ad7'))]\n",
            "Processing question 76/100\n",
            "Response: generations=[[Generation(text=' Linebacker')]] llm_output=None run=[RunInfo(run_id=UUID('f623ec89-4985-4030-8a58-e131f7cd75fa'))]\n",
            "Processing question 77/100\n",
            "Response: generations=[[Generation(text=' four times')]] llm_output=None run=[RunInfo(run_id=UUID('a0eceec0-beb3-4d89-97ae-e8904d60a262'))]\n",
            "Processing question 78/100\n",
            "Response: generations=[[Generation(text=' The answer is The Broncos caused turnovers four times in the game, as they recovered two fumbles and intercepted two passes. ')]] llm_output=None run=[RunInfo(run_id=UUID('f17cf669-17ce-45d7-922c-7af8d5b249d6'))]\n",
            "Processing question 79/100\n",
            "Response: generations=[[Generation(text=' None')]] llm_output=None run=[RunInfo(run_id=UUID('e984e048-4ade-48d6-9908-cf13edf84d19'))]\n",
            "Processing question 80/100\n",
            "Response: generations=[[Generation(text=' Von Miller achieved 2.0 tackles by himself during the game. ')]] llm_output=None run=[RunInfo(run_id=UUID('1fa6d85e-2934-4386-a7a4-15ae4ac58739'))]\n",
            "Processing question 81/100\n",
            "Response: generations=[[Generation(text=' CBS Sports')]] llm_output=None run=[RunInfo(run_id=UUID('a74b621f-2d0d-4b83-be48-2f4c5a035ec0'))]\n",
            "Processing question 82/100\n",
            "Response: generations=[[Generation(text=' The average cost for a 30 second commercial during Super Bowl 50 was around $50 million. This number is highly variable and depends on many factors, such as the specific network airing the game, the time slot of the commercial, the company advertising, and other deal sweeteners included with the purchase of the ad. For example, in 2023, the average cost of a 30-second ad during Super Bowl LVII was $7.8 million, though this amount does not include additional fees for things like marketing or talent endorsements. ')]] llm_output=None run=[RunInfo(run_id=UUID('63308d50-6bee-4fe5-a0a3-179554f4f340'))]\n",
            "Processing question 83/100\n",
            "Response: generations=[[Generation(text=' The answer is The Weeknd, who was the headline performer at Super Bowl 50 halftime show. ')]] llm_output=None run=[RunInfo(run_id=UUID('c81a999d-1be6-4c1f-86bc-b102c5bf51b5'))]\n",
            "Processing question 84/100\n",
            "Response: generations=[[Generation(text=' Chris Martin, Bruno Mars, and Beyonce')]] llm_output=None run=[RunInfo(run_id=UUID('cdcac65c-3727-46bd-b80b-f484f1e149c1'))]\n",
            "Processing question 85/100\n",
            "Response: generations=[[Generation(text=' Beyonce was the headline performer at the Super Bowl XLVII halftime show in 2013. Her performance was held in the Mercedes-Benz Superdome in New Orleans, Louisiana, and was seen by a record audience of over 110 million viewers. It was the culmination of a series of spectacular halftime shows that she had been performing since 2013. ')]] llm_output=None run=[RunInfo(run_id=UUID('3b9b6ca0-a408-47c1-84d5-868a6e07b2e7'))]\n",
            "Processing question 86/100\n",
            "Response: generations=[[Generation(text=' CBS Sports')]] llm_output=None run=[RunInfo(run_id=UUID('ce500315-68ae-4593-b7d7-45f9253f5186'))]\n",
            "Processing question 87/100\n",
            "Response: generations=[[Generation(text=' None')]] llm_output=None run=[RunInfo(run_id=UUID('00e65eda-1ff0-4f71-83bf-521f4585e9b4'))]\n",
            "Processing question 88/100\n",
            "Response: generations=[[Generation(text=' Beyonce')]] llm_output=None run=[RunInfo(run_id=UUID('4a8af78f-2cd9-45d6-9897-d7cf0aadae28'))]\n",
            "Processing question 89/100\n",
            "Response: generations=[[Generation(text=' Bruno Mars')]] llm_output=None run=[RunInfo(run_id=UUID('9ce471bd-0011-4eb2-a90a-a6db15346bc7'))]\n",
            "Processing question 90/100\n",
            "Response: generations=[[Generation(text=\" There was no mention of a performer at the halftime show in the provided information. The text focuses on a venue that features several entertainment options for adults and children, such as a karaoke pod, gaming pod, playhouse, and kids' playroom. It also lists specifications and features of a building complex called Tembusu Grand.  If you are interested in knowing more about the halftime show performers, please provide the relevant year or event you are interested in. \")]] llm_output=None run=[RunInfo(run_id=UUID('26055fdd-de36-4cf7-9bbf-9dace57da21e'))]\n",
            "Processing question 91/100\n",
            "Response: generations=[[Generation(text=' CBS')]] llm_output=None run=[RunInfo(run_id=UUID('70bde75f-a755-438a-8951-30c1c930c2c5'))]\n",
            "Processing question 92/100\n",
            "Response: generations=[[Generation(text='\\n\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\t')]] llm_output=None run=[RunInfo(run_id=UUID('32ab0190-7358-4f36-b40f-1dc26ac41a6d'))]\n",
            "Processing question 93/100\n",
            "Response: generations=[[Generation(text=' Chris Martin')]] llm_output=None run=[RunInfo(run_id=UUID('9f059ebb-c6e9-46d8-a0fb-1218127d89d1'))]\n",
            "Processing question 94/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 halftime show ranked at number 6 on the list of most watched TV broadcasts.  It recorded around 103.4 million viewers.  The amazing show was held in 2016 and was performed by the band, Coldplay.  It also featured guest performances by several popular artists, including Bruno Mars and Beyonce, who helped to make the show even more spectacular and one to remember.  This ranking just goes to show how popular and highly anticipated the event is, with millions of viewers tuning in each year to watch the performances and see which artists will be making an appearance.  It is definitely one of the most exciting and entertaining TV moments of the year.  The Super Bowl is definitely a time for people to come together and enjoy the entertainment, whether it's the game itself or the performances that take place during the halftime show.  It is definitely a highly anticipated event that people look forward to each year.  The ranking of the Super Bowl 50 halftime show just goes to show how popular and successful it was, with it securing a place on the list of most-watched TV broadcasts of all time.  It was definitely a show that people will remember for a long time and will be hard to beat in terms of entertainment and popularity.  This just goes\")]] llm_output=None run=[RunInfo(run_id=UUID('9a9bb824-7d6b-447e-98a4-13be998ca2cc'))]\n",
            "Processing question 95/100\n",
            "Response: generations=[[Generation(text=' Tanjong Katong MRT Station')]] llm_output=None run=[RunInfo(run_id=UUID('84340b04-809b-424a-9b0c-615a1573766b'))]\n",
            "Processing question 96/100\n",
            "Response: generations=[[Generation(text=' The answer is unfortunately not explicitly provided in the text. ')]] llm_output=None run=[RunInfo(run_id=UUID('9d29b361-49d7-4166-ba9d-27e6730a88be'))]\n",
            "Processing question 97/100\n",
            "Response: generations=[[Generation(text=' Coldplay')]] llm_output=None run=[RunInfo(run_id=UUID('22711182-7a21-462a-998b-0ba487627915'))]\n",
            "Processing question 98/100\n",
            "Response: generations=[[Generation(text=' Dr. Dre and Anderson Paak were the artists that performed with Coldplay during the 2022 Super Bowl half-time show. They were joined by the hip-hop legend, Snoop Dogg. ')]] llm_output=None run=[RunInfo(run_id=UUID('13320bf0-5b91-4849-8e2f-6dba9077cabc'))]\n",
            "Processing question 99/100\n",
            "Response: generations=[[Generation(text=' CBS has traditionally been home to the Super Bowl since the very first one was played back in 1967.')]] llm_output=None run=[RunInfo(run_id=UUID('617959a2-d7a0-4dd6-86b4-d68072d15c89'))]\n",
            "Processing question 100/100\n",
            "Response: generations=[[Generation(text=' The halftime show was headlined by Coldplay, with guest performers including Beyonce, Bruno Mars, and Mark Ronson, and the Youth Orchestra Los Angeles. ')]] llm_output=None run=[RunInfo(run_id=UUID('086f3842-1457-4b1a-abe8-05fd49375022'))]\n",
            "Latency: 325.44 seconds\n",
            "Accuracy: 0.00\n",
            "Precision: 0.00\n",
            "Recall: 0.00\n",
            "ROUGE Scores: {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "Average BLEU Score: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from rouge import Rouge\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import os\n",
        "\n",
        "def format_docs(docs):\n",
        "    # Dummy implementation, replace with actual document formatting logic\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "def evaluate_model_extended(retriever, generate_answer_function, dataset_name='squad', num_samples=100):\n",
        "    # Load the benchmark dataset\n",
        "    print(\"Loading dataset...\")\n",
        "    dataset = load_dataset(dataset_name)\n",
        "\n",
        "    # Extract a subset of the validation data\n",
        "    validation_data = dataset['validation']\n",
        "    sample_data = validation_data.select(range(num_samples))\n",
        "\n",
        "    contexts = [item['context'] for item in sample_data]\n",
        "    questions = [item['question'] for item in sample_data]\n",
        "    true_answers = [item['answers']['text'][0] for item in sample_data]\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, (context, question) in enumerate(zip(contexts, questions), start=1):\n",
        "        print(f\"Processing question {i}/{num_samples}\")\n",
        "        # Retrieve relevant documents for the question\n",
        "        search_results = retriever.invoke(question)\n",
        "        relevant_docs = search_results\n",
        "        formatted_context = format_docs(relevant_docs)\n",
        "\n",
        "        # Generate an answer\n",
        "        result = generate_answer_function(question, formatted_context)\n",
        "        predictions.append(result)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate Latency\n",
        "    latency = end_time - start_time\n",
        "\n",
        "    # Calculate Precision and Recall\n",
        "    def compute_precision_recall(pred, true):\n",
        "        pred_tokens = set(pred.split())\n",
        "        true_tokens = set(true.split())\n",
        "        intersection = pred_tokens.intersection(true_tokens)\n",
        "        precision = len(intersection) / len(pred_tokens) if pred_tokens else 0\n",
        "        recall = len(intersection) / len(true_tokens) if true_tokens else 0\n",
        "        return precision, recall\n",
        "\n",
        "    precisions, recalls = zip(*[compute_precision_recall(pred, true) for pred, true in zip(predictions, true_answers)])\n",
        "    avg_precision = np.mean(precisions)\n",
        "    avg_recall = np.mean(recalls)\n",
        "\n",
        "    # Calculate ROUGE Scores\n",
        "    rouge = Rouge()\n",
        "    rouge_scores = rouge.get_scores(predictions, true_answers, avg=True)\n",
        "\n",
        "    # Calculate BLEU Scores\n",
        "    bleu_scores = [sentence_bleu([true.split()], pred.split()) for pred, true in zip(predictions, true_answers)]\n",
        "    avg_bleu = np.mean(bleu_scores)\n",
        "\n",
        "    # Exact Match\n",
        "    def compute_exact_match(pred, true):\n",
        "        return int(pred.strip().lower() == true.strip().lower())\n",
        "\n",
        "    accuracy = np.mean([compute_exact_match(pred, true) for pred, true in zip(predictions, true_answers)])\n",
        "\n",
        "    print(f\"Latency: {latency:.2f} seconds\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Precision: {avg_precision:.2f}\")\n",
        "    print(f\"Recall: {avg_recall:.2f}\")\n",
        "    print(f\"ROUGE Scores: {rouge_scores}\")\n",
        "    print(f\"Average BLEU Score: {avg_bleu:.2f}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define your `generate_answer` function with context parameter\n",
        "    def generate_answer_with_context(question, context):\n",
        "        cohere_llm = Cohere(model=\"command\", temperature=0.1, cohere_api_key=os.getenv('COHERE_API_KEY'))\n",
        "\n",
        "        prompt_template = f\"\"\"\n",
        "        Context: {context}\n",
        "        Question: {question}\n",
        "        Answer:\"\"\"\n",
        "\n",
        "        response = cohere_llm.generate([prompt_template])\n",
        "        print(\"Response:\", response)\n",
        "\n",
        "        if isinstance(response, list) and len(response) > 0 and 'text' in response[0]:\n",
        "            return response[0]['text'].strip()\n",
        "        else:\n",
        "            return \"No answer generated\"\n",
        "\n",
        "    # Evaluate the model\n",
        "    evaluate_model_extended(retriever, generate_answer_with_context)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLQmLFeM7Ufq",
        "outputId": "095a031f-e7fd-432d-a677-63dfdf729587"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Processing question 1/100\n",
            "Response: generations=[[Generation(text=' The answer is The Denver Broncos represented the AFC at Super Bowl 50')]] llm_output=None run=[RunInfo(run_id=UUID('b5deb7bd-fa2f-4e80-8238-cd19645ed7bd'))]\n",
            "Processing question 2/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers represented the NFC at Super Bowl 50, where they lost to the Denver Broncos by a score of 24–10. ')]] llm_output=None run=[RunInfo(run_id=UUID('a1c33623-a3fe-4902-bc6b-4ef1b1b80c7b'))]\n",
            "Processing question 3/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl is an annual American football game that determines the league champion. The 50th Super Bowl was played in 2016, and was won by the Denver Broncos, who defeated the Carolina Panthers by a score of 24–10. The game was played on February 7, 2016, at Levi's Stadium in Santa Clara, California, and was televised on CBS. \")]] llm_output=None run=[RunInfo(run_id=UUID('dfe07a38-a762-45f6-b863-49d2c8b61955'))]\n",
            "Processing question 4/100\n",
            "Response: generations=[[Generation(text=' The Denver Broncos won Super Bowl 50, defeating the Carolina Panthers by a score of 24-10. This win gave the Broncos their third Super Bowl victory and first since 1998. ')]] llm_output=None run=[RunInfo(run_id=UUID('ea62ab3a-473f-494c-9353-5aea364e02ad'))]\n",
            "Processing question 5/100\n",
            "Response: generations=[[Generation(text=' The color was blue, according to NFL reporter Brian Sexton, although the league didn\\'t disclose the exact shade. The NFL merely promised that it would be \"a new color.\"')]] llm_output=None run=[RunInfo(run_id=UUID('8b5fe723-d6e4-4404-af0c-ca6c51ba9b33'))]\n",
            "Processing question 6/100\n",
            "Response: generations=[[Generation(text=' The theme of Super Bowl 50 was \"Golden Celebration\". It was a reference to the game being the 50th Super Bowl which was played on February 7, 2016, at the Levi\\'s Stadium in Santa Clara, California. The Carolina Panthers played against the Denver Broncos, with the latter being crowned the champion. ')]] llm_output=None run=[RunInfo(run_id=UUID('0da08f4d-90a0-47fd-817b-42573183f2f0'))]\n",
            "Processing question 7/100\n",
            "Response: generations=[[Generation(text=' The game was played on Saturday. The schedule for the week is shown as follows, with the game listed on the weekend:\\n\\n| Sun | Mon | Tues | Wed | Thurs | Fri | Sat |\\n|---|---|---|---|---|---|---|\\n|  |  |  |  |  |  | Game |\\n|  |  |  |  |  | Game |  |\\n|  |  |  |  | Game |  |  |\\n|  |  |  | Game |  |  |  |\\n|  |  | Game |  |  |  |  |\\n|  | Game |  |  |  |  |  |\\n| Game |  |  |  |  |  |  |\\n|  |  |  |  |  |  |  |\\n|  |  |  |  |  |  | Game |\\n\\nTherefore, the game was played on Saturday. ')]] llm_output=None run=[RunInfo(run_id=UUID('bfdd534c-2fcd-4d35-afa7-4648e080f58b'))]\n",
            "Processing question 8/100\n",
            "Response: generations=[[Generation(text=' Tembusu Grand')]] llm_output=None run=[RunInfo(run_id=UUID('daeb3ef0-3598-44f6-8e97-49f2e98a171a'))]\n",
            "Processing question 9/100\n",
            "Response: generations=[[Generation(text=' The theme of Super Bowl 50 was \"Golden Anniversary\" and the Pepsi Halftime Show featured a performance by Coldplay, who opened with a rendition of \"Yellow\" and was accompanied by singer Beyonce. The show also featured spectacular lighting and an array of colorful fireworks. ')]] llm_output=None run=[RunInfo(run_id=UUID('b13b70ae-f2b9-4383-9b53-6665d10882cc'))]\n",
            "Processing question 10/100\n",
            "Response: generations=[[Generation(text=' Air-conditioning system. ')]] llm_output=None run=[RunInfo(run_id=UUID('af37be5f-d402-4fd3-a363-9b20390a60bd'))]\n",
            "Processing question 11/100\n",
            "Response: generations=[[Generation(text=' Sunday')]] llm_output=None run=[RunInfo(run_id=UUID('20dc2a20-7be4-48bc-adc7-2948e3b64382'))]\n",
            "Processing question 12/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers lost the Super Bowl 50 to the Denver Broncos and therefore did not win Super Bowl 50. ')]] llm_output=None run=[RunInfo(run_id=UUID('2ce5354d-7148-46a2-bf2f-8c4650e46315'))]\n",
            "Processing question 13/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 took place in the Levi's Stadium located in Santa Clara, California. It was the first Super Bowl to take place in the San Francisco Bay Area since Super XIX in 1985. The game was played between the Denver Broncos and the Carolina Panthers with the Broncos winning 24-10. \")]] llm_output=None run=[RunInfo(run_id=UUID('ea52af43-c939-4e49-92d2-1eb76466380e'))]\n",
            "Processing question 14/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 took place in Santa Clara, California, US. It was the first Super Bowl to be played on the West Coast in 15 years. The game was played on February 7, 2016, at Levi's Stadium with the Denver Broncos defeating the Carolina Panthers by a score of 24–10. \")]] llm_output=None run=[RunInfo(run_id=UUID('60f36c61-46a6-408e-a8a9-664b20953f28'))]\n",
            "Processing question 15/100\n",
            "Response: generations=[[Generation(text=' Answer: \\nThe Roman numeral for 50 is L. So if we used Roman numerals, Super Bowl 50 would have been called Super Bowl L. ')]] llm_output=None run=[RunInfo(run_id=UUID('fec32b83-a6ee-46e2-ae76-2a351836b4c1'))]\n",
            "Processing question 16/100\n",
            "Response: generations=[[Generation(text=' The 2015 NFL season')]] llm_output=None run=[RunInfo(run_id=UUID('321950f3-d667-41b3-9f96-b7cd7c5b4e6c'))]\n",
            "Processing question 17/100\n",
            "Response: generations=[[Generation(text=' The Denver Broncos secured a Super Bowl title for the third time in 1998.  Although they have won several Super Bowl titles since, 1998 remains a memorable year for the team.  This was also the last Super Bowl win for the Broncos before the upcoming 2022-2023 season. ')]] llm_output=None run=[RunInfo(run_id=UUID('e9580d1a-94a8-4309-8431-2a866629301e'))]\n",
            "Processing question 18/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 took place in Santa Clara, California, US. It was the first Super Bowl to be played on the West Coast in 15 years. The game was played on February 7, 2016, at Levi's Stadium with the Denver Broncos defeating the Carolina Panthers by a score of 24–10. \")]] llm_output=None run=[RunInfo(run_id=UUID('343a5d4a-ac3a-408c-9c60-78e527c60d81'))]\n",
            "Processing question 19/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl is an annual American football game that determines the league champion. The specific stadium where Super Bowl 50 was held is the Levi's Stadium, located in Santa Clara, California. It was the first Super Bowl to be played on the West Coast since Super Bowl XIX in 1985. \")]] llm_output=None run=[RunInfo(run_id=UUID('78e3253b-5b3b-4271-8f3a-8fb47e38618c'))]\n",
            "Processing question 20/100\n",
            "Response: generations=[[Generation(text=' The final score of Super Bowl 50 was Denver Broncos - 24, Carolina Panthers - 10. ')]] llm_output=None run=[RunInfo(run_id=UUID('553859b7-d748-48fa-8e01-1ac9ea1246c8'))]\n",
            "Processing question 21/100\n",
            "Response: generations=[[Generation(text=' The answer is Super Bowl 50 took place on February 7, 2016. ')]] llm_output=None run=[RunInfo(run_id=UUID('987bb90b-15f3-4e2a-89fe-6bf56f80262b'))]\n",
            "Processing question 22/100\n",
            "Response: generations=[[Generation(text=' Super Bowl 50 was played on February 7, 2016')]] llm_output=None run=[RunInfo(run_id=UUID('631f9398-78d2-457a-8085-19cff5d11a19'))]\n",
            "Processing question 23/100\n",
            "Response: generations=[[Generation(text=' New England Patriots')]] llm_output=None run=[RunInfo(run_id=UUID('6f32c271-0f05-4d1c-892a-b1ea17726d73'))]\n",
            "Processing question 24/100\n",
            "Response: generations=[[Generation(text=' Answer: BLK 92')]] llm_output=None run=[RunInfo(run_id=UUID('ef34e49d-741b-4bae-8239-cb5be428f07a'))]\n",
            "Processing question 25/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers lost the Super Bowl 50 to the Denver Broncos and therefore did not win Super Bowl 50. ')]] llm_output=None run=[RunInfo(run_id=UUID('7faf2f34-9827-4183-9b19-b347afe85396'))]\n",
            "Processing question 26/100\n",
            "Response: generations=[[Generation(text=' The 2015 NFL season')]] llm_output=None run=[RunInfo(run_id=UUID('18dbff9a-78a1-4e78-9299-5ce4bcc42fdf'))]\n",
            "Processing question 27/100\n",
            "Response: generations=[[Generation(text=' The answer is the Denver Broncos. The Super Bowl is an annual American football game that determines the league champion. The 50th Super Bowl was played on February 7, 2016, and featured the Denver Broncos against the Carolina Panthers. The Broncos won the game by a score of 24–10, claiming their third Super Bowl championship. ')]] llm_output=None run=[RunInfo(run_id=UUID('8ce0a734-dba9-4961-a466-454ded77d831'))]\n",
            "Processing question 28/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 was held in Santa Clara, California, at the Levi's Stadium which is located in the San Francisco Bay Area on February 7, 2016. It was the first Super Bowl to be played in the Bay Area since Super Bowl XIX, which was held in 1985 at Stanford Stadium. The game was played between the Denver Broncos and the Carolina Panthers, with the Broncos winning 24–10. \")]] llm_output=None run=[RunInfo(run_id=UUID('29ee1368-bc12-44af-8bbd-b89d172908c6'))]\n",
            "Processing question 29/100\n",
            "Response: generations=[[Generation(text=' Super Bowl')]] llm_output=None run=[RunInfo(run_id=UUID('7c6fae59-d556-4b91-8d89-a275d1588749'))]\n",
            "Processing question 30/100\n",
            "Response: generations=[[Generation(text=\" The New England Patriots won the AFC playoff game during the 2015 NFL season.  They ended up winning the Super Bowl that year, defeating the Seattle Seahawks, 28-24.  They were led by star quarterback Tom Brady, and head coach Bill Belichick.  This was the Patriots' fourth Super Bowl victory, with previous wins in 2001, 2003, and 2004.  They also appeared in the Super Bowl in 2007 and 2011, but lost both games.  The Patriots are a perennial powerhouse in the NFL, and have consistently been one of the top teams in the AFC, especially over the past two decades under Belichick and Brady.  They have won the AFC East division numerous times, and have made many deep playoff runs over the years.  They have been led by many great players over the years, such as Brady, Belichick, Randy Moss, and Rob Gronkowski, to name a few.  They have a very loyal and passionate fanbase, and are widely considered to be one of the most successful and well-run organizations in all of professional sports.  They have set numerous records and milestones over the years, and have consistently been a very competitive and entertaining team to watch.  They have also had some controversial moments and scandals over the\")]] llm_output=None run=[RunInfo(run_id=UUID('50dd856c-72fa-466b-b8da-8543810ae12c'))]\n",
            "Processing question 31/100\n",
            "Response: generations=[[Generation(text=\" The Most Valuable Player award, which was introduced in 1993, has been won by several Carolina Panthers players over the years. The players are as follows:\\n\\n1. Steve Smith Sr. (2005)\\n2. Julius Peppers (2006)\\n3. DeAngelo Williams (2008)\\n4. Cam Newton (2015)\\n5. Luke Kuechly (2015)\\n6. Jonathan Stewart (2017)\\n7. Christian McCaffrey (2019)\\n8. Teddy Bridgewater (2021)\\n\\nThe award is typically given to the player who had the greatest impact on the team's success during the season. \")]] llm_output=None run=[RunInfo(run_id=UUID('1ea40027-45c8-415a-99e7-938f888aa973'))]\n",
            "Processing question 32/100\n",
            "Response: generations=[[Generation(text=' The Denver Broncos have made eight appearances in the Super Bowl.  They won the Super Bowl in 1997, 1998, 1999, and 2015.  Their four Super Bowl wins are a tied record for the NFL.  The team has a strong fanbase, and the city has earned the nickname \"Broncos Country\" due to its dedication to the team.  They have appeared in the Super Bowl more than 10 times and have an overall record of 4-4.  The Broncos are currently ranked second in the AFC West division.  They have been ranked in the top 10 teams in the NFL multiple times and have won numerous divisional titles and conference championships.  They are one of the most popular and well-known teams in the NFL.  The Broncos have had a long history of success and have been consistent contenders in the AFC for many years.  They have a talented roster and a strong coaching staff and are always a team to watch out for in the NFL.  They have made the playoffs numerous times and have been a threat to win the Super Bowl every year.  The Broncos are a team that is always a contender and a favorite to win the Super Bowl.  They have a rich history and a dedicated fanbase, and they are a team that is always a')]] llm_output=None run=[RunInfo(run_id=UUID('13440a0c-d324-43b8-95d1-846eb8159900'))]\n",
            "Processing question 33/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers were established in 1993 and joined the NFL as the 29th franchise in the NFL. They are the only active NFL franchise to be based in Charlotte, North Carolina and their current logo, a blue panther face, was adopted in 2012. ')]] llm_output=None run=[RunInfo(run_id=UUID('c754183e-2921-45ce-8169-fd1a7b3e6792'))]\n",
            "Processing question 34/100\n",
            "Response: generations=[[Generation(text=' Eunos Bus Interchange')]] llm_output=None run=[RunInfo(run_id=UUID('941210ec-3bf1-481d-b6b1-a15d93b1584c'))]\n",
            "Processing question 35/100\n",
            "Response: generations=[[Generation(text=' The answer is not in the provided context but the Denver Broncos prevented the New England Patriots from going to the Super Bowl in the 2014–15 NFL season. The Broncos defeated the Patriots in the AFC Championship Game by a score of 26–16, denying them a trip to Super Bowl XLIX and extending their record to 9–0 in games where they have held opponents to fewer than 17 points. ')]] llm_output=None run=[RunInfo(run_id=UUID('8a35a65e-a394-43a0-abb3-292221cf2bf3'))]\n",
            "Processing question 36/100\n",
            "Response: generations=[[Generation(text=' The Panthers beat the Arizona Cardinals in the NFC Championship Game to advance to Super Bowl 50. ')]] llm_output=None run=[RunInfo(run_id=UUID('122901b9-a88a-4782-ac39-59045483ce98'))]\n",
            "Processing question 37/100\n",
            "Response: generations=[[Generation(text=' The Colts lost to the Broncos in the AFC Championship game in 2013')]] llm_output=None run=[RunInfo(run_id=UUID('78df8fbe-45c8-40a5-85aa-e5db43355bed'))]\n",
            "Processing question 38/100\n",
            "Response: generations=[[Generation(text=' The defending Super Bowl champions were the Baltimore Colts, who defeated the New York Jets in Super Bowl III. The Colts were the first NFL team to win a Super Bowl. ')]] llm_output=None run=[RunInfo(run_id=UUID('e4ea69cc-2e7d-4418-848a-2fb12cd20bea'))]\n",
            "Processing question 39/100\n",
            "Response: generations=[[Generation(text=\" The New England Patriots have been to the Super Bowl eight times. They've won the Super Bowl six times. \")]] llm_output=None run=[RunInfo(run_id=UUID('6f8c8946-2bde-4b9b-88db-3a77a1cca70f'))]\n",
            "Processing question 40/100\n",
            "Response: generations=[[Generation(text=\" Tom Brady was the NFL MVP for the 2007-2008 NFL season.  He was also the MVP in the 2001-2002 and the 2004-2005 NFL seasons.  He is a seven-time Super Bowl champion as a quarterback for the New England Patriots, winning Super Bowls XXXVI, XXXVIII, XXXIX, XLIX, LI, LIII, and LV.  He is a five-time Super Bowl MVP, a three-time NFL MVP, and has won the NFL Offensive Player of the Year award four times.  He holds numerous records related to his playing career, as well as records related to his 18-year tenure as the Patriots' starting quarterback.  He is widely considered one of the greatest quarterbacks of all time, and is most well-known for his rivalry with Peyton Manning, as well as his controversial deflategate suspension.  He has won more Super Bowls than any other NFL franchise as well as any other NFL quarterback.  He has won more playoff games than any other NFL franchise as well as any other NFL quarterback.  He is also the oldest quarterback to win a Super Bowl, as well as the first quarterback to win a Super Bowl in three separate decades.  He is also the first quarterback to win a Super\")]] llm_output=None run=[RunInfo(run_id=UUID('6772b728-682e-42dc-92f3-f0d9a55a0bcc'))]\n",
            "Processing question 41/100\n",
            "Response: generations=[[Generation(text=' 3 BHK + Study unit in any one of the following blocks \\nand you sell it before the end of the current quarter you will be eligible for an extra \\n0.005% commission.\\n\\nThe extra commission kicker is for all 3 BHK + Study units in the following blocks and is also subject to the following conditions:\\n\\nAll 3 BHK + Study units must be sold before the end of the current quarter.\\n\\nIf you were to create a question based on this text, what do you think it would be?\\n\\nQuestion: \\nWhat is the percentage for the extra commission kicker for 3 BHK + Study units in blocks 92, 94, 96, and 98?\\n\\nBased on the information provided, what do you think is the answer to this question?\\n\\nAnswer: \\nThe answer is 0.005%. \\n\\nThe relevant sentence in the text that provides this information is: \\n3 BHK + Study unit\\t0.005\\n\\nThe percentage is indicated at the end of the sentence and refers to the commission rate (or \"kick\") for selling these specific types of units in the specified blocks. \\nThe kicker is an extra commission added on top of the regular commission rate for these units')]] llm_output=None run=[RunInfo(run_id=UUID('4b0605bf-a251-4bec-a2c5-4050f8a18e39'))]\n",
            "Processing question 42/100\n",
            "Response: generations=[[Generation(text=' Cam Newton')]] llm_output=None run=[RunInfo(run_id=UUID('df626aee-368e-4d84-937f-e007372f2bdb'))]\n",
            "Processing question 43/100\n",
            "Response: generations=[[Generation(text=' The Denver Broncos played 16 games during the 2015 regular season, winning 13 and losing 3 games. ')]] llm_output=None run=[RunInfo(run_id=UUID('7f3b5a53-ec1e-44f7-a10d-2c219bdfc2ae'))]\n",
            "Processing question 44/100\n",
            "Response: generations=[[Generation(text=' The only team to have played in the Super Bowl eight times is the Pittsburgh Steelers.  They won the Super Bowl in 1974, 1975, 1978, 1979, 1980, 2006, 2009, and 2010, which equals eight appearances throughout the years.  They also hold the record for most Super Bowl victories with six.  Although the Dallas Cowboys have also appeared in the Super Bowl eight times, they have only won it five times, which is still an impressive record.  The Cowboys appeared in the Super Bowl in 1970, 1971, 1973, 1978, 1979, 1981, 1992, and 1995 but fell short of winning all eight times.  Overall, the Steelers have the most Super Bowl appearances and the most Super Bowl victories out of any team that has played in the Super Bowl.  Please let me know if you would like more information on the Pittsburgh Steelers or the Dallas Cowboys! ')]] llm_output=None run=[RunInfo(run_id=UUID('1c3da897-b9df-4be3-a670-6afb4466c792'))]\n",
            "Processing question 45/100\n",
            "Response: generations=[[Generation(text=' New England Patriots')]] llm_output=None run=[RunInfo(run_id=UUID('fbad3e47-0b35-46a7-a245-be0c46f4227c'))]\n",
            "Processing question 46/100\n",
            "Response: generations=[[Generation(text=' Cam Newton')]] llm_output=None run=[RunInfo(run_id=UUID('f309733f-a56a-4499-8027-e1ffdb13e022'))]\n",
            "Processing question 47/100\n",
            "Response: generations=[[Generation(text=' The answer is the Dallas Cowboys based on the information provided in the table. ')]] llm_output=None run=[RunInfo(run_id=UUID('e9c382c6-f0c8-49f8-a22e-f13cf6262b59'))]\n",
            "Processing question 48/100\n",
            "Response: generations=[[Generation(text=' The Panthers have been in the Super Bowl twice. They lost in 2004 and were defeated in 2016, against the New England Patriots and the Denver Broncos, respectively. ')]] llm_output=None run=[RunInfo(run_id=UUID('38fb5bae-d16a-4cca-be78-0ca4313df72b'))]\n",
            "Processing question 49/100\n",
            "Response: generations=[[Generation(text=' The San Diego Chargers')]] llm_output=None run=[RunInfo(run_id=UUID('4c0e506a-497b-461b-b818-e51ccae5a80d'))]\n",
            "Processing question 50/100\n",
            "Response: generations=[[Generation(text=\" The Most Valuable Player for the 2015 NFL season was Cam Newton, who played for the Carolina Panthers as a quarterback and was the first unanimous MVP in NFL history, as he received all 50 votes.  He was also named the Most Valuable Player by the Associated Press for this achievement.  This was a notable season for him as he led the Panthers to a 15–1 record and a trip to Super Bowl 50, where they ultimately lost to the Denver Broncos.  Additionally, he surpassed Peyton Manning's record for most passing yards in a season by a quarterback, with a total of 3,837 yards.  His impressive performance during the 2015 NFL season solidified his place as one of the league's top players.  Let me know if you would like to know more information about the NFL or football in general. \")]] llm_output=None run=[RunInfo(run_id=UUID('700f0062-97b2-4467-9d13-ba46fe2e037b'))]\n",
            "Processing question 51/100\n",
            "Response: generations=[[Generation(text=' New England Patriots')]] llm_output=None run=[RunInfo(run_id=UUID('f35365f0-7cad-4208-9f29-408a99d16db2'))]\n",
            "Processing question 52/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers beat the Arizona Cardinals 49-15 in the 2015 NFC Championship game. The game was played on January 24, 2015 at Bank of America Stadium in Charlotte, North Carolina. ')]] llm_output=None run=[RunInfo(run_id=UUID('fb2c7f09-feec-42b0-92ec-ebb55ce01487'))]\n",
            "Processing question 53/100\n",
            "Response: generations=[[Generation(text=\" The 2015 NFL MVP was Cam Newton, who is a quarterback for the Carolina Panthers.  He helped lead the Panthers to a 15-1 record and a trip to the Super Bowl that year.  He threw for 3,837 yards, 35 touchdowns, and 10 interceptions.  He also rushed for 636 yards and an additional 10 touchdowns.  He was the first quarterback in NFL history to throw for 30+ touchdowns and rush for 10+ touchdowns in a single season.  He was rewarded with the NFL MVP, the AP NFL Offensive Player of the Year, the FedEx Air Player of the Year, and the Pro Football Writers of America Offensive Player of the Year awards.  He also became the first player in NFL history to be named the MVP and Offensive Player of the Year in the same season.  The Panthers eventually lost the Super Bowl to the Denver Broncos, who were led by future Hall of Fame quarterback Peyton Manning.  This was Manning's second and final Super Bowl victory, as he would retire following the Super Bowl and was inducted into the Pro Football Hall of Fame in 2021.  The Panthers have not returned to the Super Bowl since this season.  Let me know if you want to know more information on the 2015 NFL season or the career of Cam Newton.\")]] llm_output=None run=[RunInfo(run_id=UUID('b019241f-0335-4304-922f-3003619bc824'))]\n",
            "Processing question 54/100\n",
            "Response: generations=[[Generation(text=' The panthers beat the saints to become the NFC champs')]] llm_output=None run=[RunInfo(run_id=UUID('2c9a9ab9-2730-469c-b6ca-2c2d75faddb7'))]\n",
            "Processing question 55/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers formed in 1995.')]] llm_output=None run=[RunInfo(run_id=UUID('2c8b12fb-d28e-44dd-b118-9364f78cc5af'))]\n",
            "Processing question 56/100\n",
            "Response: generations=[[Generation(text=' Cam Newton')]] llm_output=None run=[RunInfo(run_id=UUID('97815b83-cdf8-46d1-a370-694e8d48a545'))]\n",
            "Processing question 57/100\n",
            "Response: generations=[[Generation(text=\" Von Miller forced 2 fumbles during Super Bowl 50.  He was also named the Super Bowl 50 MVP, becoming the first player in NFL history to win the Super Bowl MVP award with a sack, a forced fumble, a fumble recovery, and an interception.  Miller had 2.5 sacks, five tackles, 2 forced fumbles, and one fumble recovery in the game.  This performance tied him for the highest number of sacks in a Super Bowl with Michael Strahan, who achieved the same record with the Giants in Super Bowl 46 against the Patriots.  Von Miller is widely regarded as one of the greatest defensive players in NFL history and has been voted to eight Pro Bowls and holds the all-time record for sacks in the Super Bowl with 4.5.  He has won many other accolades such as the Butkus Award, the NFL's Defensive Rookie of the Year, the NFL's Most Valuable Player, and the NFL's Defensive Player of the Year.  He is also a 3-time All-Pro and a 5-time First-team All-Pro, and has appeared in the Pro Bowl eight times.  In Super Bowl 50, Von Miller recorded 2.5 sacks, 5 tackles, 2 forced fumbles, and 1 fumble recovery, and was\")]] llm_output=None run=[RunInfo(run_id=UUID('8057c5c1-a49f-4256-b077-6b6586c4baa3'))]\n",
            "Processing question 58/100\n",
            "Response: generations=[[Generation(text=' The New York Rangers hockey team scored the most points during the entire game and held the lead throughout. ')]] llm_output=None run=[RunInfo(run_id=UUID('b3b50ee6-ec7e-4da1-b86d-c461cb63205c'))]\n",
            "Processing question 59/100\n",
            "Response: generations=[[Generation(text=' Von Miller was the Denver linebacker named Super Bowl MVP, who played for the Denver Broncos and was crucial in their victory at Super Bowl 50.  He was named MVP of the game and also won the Butkus Award, an award given to the best linebackers in college football during his time at Texas A&M.  He was drafted by the Denver Broncos and has had a successful career there, winning many other awards and accolades.  He is known for his impressive speed and ability to get to the quarterback, as well as his leadership on and off the field.  He has been named to the Pro Bowl team multiple times and was also named the NFL Defensive Player of the Year in 2013.  He is considered one of the best linebackers in the NFL and has been a key player for the Denver Broncos for many years.  He is also known for his charitable work and community service, and is considered a positive role model for young people.  He has also been active in the community, working with local charities and organizations to help improve the lives of those in need.  In addition to his successful football career, Von Miller is also a respected and admired public figure who is known for his hard work, dedication, and positive impact on others.  He is a')]] llm_output=None run=[RunInfo(run_id=UUID('a252c06b-5216-44a0-b1bb-f0629515c65e'))]\n",
            "Processing question 60/100\n",
            "Response: generations=[[Generation(text=' Von Miller made 2 solo tackles at Super Bowl 50.  He also made 1 assist, 1 sack, and 1 forced fumble during the game.  Von Miller was named the Super Bowl 50 MVP.  He finished the game with 4 total tackles, 2 of which were solo.  This game was his first and only Super Bowl appearance.  He played for the Denver Broncos who lost Super Bowl XLVIII to the Seattle Seahawks.')]] llm_output=None run=[RunInfo(run_id=UUID('3415b9a9-2410-4c80-8cd3-c3068db7ac89'))]\n",
            "Processing question 61/100\n",
            "Response: generations=[[Generation(text=' Tom Brady')]] llm_output=None run=[RunInfo(run_id=UUID('b289580d-5b3e-41fb-a0e5-8b34debdb4dd'))]\n",
            "Processing question 62/100\n",
            "Response: generations=[[Generation(text=\" Cam Newton was sacked four times during the game.  It was a high-pressure game, with the opposing team's defense being particularly effective, resulting in an upset win and advancing to the next round.  It was a tough loss for Cam and the team, who had been favored to win, and had a disappointing outing in the post-season.  Hopefully, he will learn from this experience and come back stronger next season.  It was a great game for the defense of the opposing team, who played exceptionally well and made the key plays to win the game.  They will now advance to the next round and face a tough opponent.  Let's see if they can pull off another upset!  It was an exciting game, with a lot of back and forth action.  Ultimately, the defense made the difference and secured the win for their team.  It was a great game for the fans, who were treated to an exciting finish.  Let's see if these two teams can meet again in the playoffs next year!  It was a disappointing loss for Cam and the team, but they should be proud of their season and how far they went.  They will learn from this experience and come back stronger next year.  Let's hope for a more\")]] llm_output=None run=[RunInfo(run_id=UUID('6fc7fc58-d00b-452f-b0f1-7c6c48f999b7'))]\n",
            "Processing question 63/100\n",
            "Response: generations=[[Generation(text=' Tom Brady')]] llm_output=None run=[RunInfo(run_id=UUID('46ba9173-5229-4a6b-b953-c05c832d666f'))]\n",
            "Processing question 64/100\n",
            "Response: generations=[[Generation(text=' Cam Newton had 39 turnovers in 2019.  This was the highest total among all quarterbacks that year.  Hopefully he can lower his turnover total this year with his new team, the Carolina Panthers.  Newton had a relatively low interception total of 13, but his fumbles (24) were a notable issue.  This was the main reason why the New England Patriots let him go and why the Panthers signed him.  They hope that Newton can replicate his 2015 MVP season where he threw for 35 touchdowns and only 10 interceptions.  This would also be a major improvement from his injury-plagued 2019 season where he only played in two games.  Let’s see if Newton can stay healthy and improve his turnover total in 2020.  He will need to take better care of the football if he wants to lead the Panthers to the playoffs.  This is especially important given that the Panthers play in the tough NFC South against teams like the New Orleans Saints and Tampa Bay Buccaneers.  This is a tough division even without considering the impact of COVID-19.  The Panthers will need Newton to be at his best in 2020 if they want to have a chance at making the playoffs.  This is also important for Newton’s free agency prospects in the future.')]] llm_output=None run=[RunInfo(run_id=UUID('01608196-ca28-4318-b99f-1380dbd11b51'))]\n",
            "Processing question 65/100\n",
            "Response: generations=[[Generation(text=' 4')]] llm_output=None run=[RunInfo(run_id=UUID('35a10cc8-13dd-44e8-8469-037970fa88a3'))]\n",
            "Processing question 66/100\n",
            "Response: generations=[[Generation(text=' The MVP award for Super Bowl 50 was given to Denver Broncos quarterback Peyton Manning.  He was able to lead his team to a 24-10 victory over the Carolina Panthers, earning the MVP title with his outstanding performance.  Manning threw for 141 yards and scored the only touchdown for the team, which was the key to their victory.  After the game, Manning commented that he felt it was an honor to be named the MVP and that he was grateful for the opportunity to have played in the Super Bowl.  He also stated that he was looking forward to the next season and hoped to be able to lead his team to another victory.  Overall, it was a great moment for Manning and the Denver Broncos, and he was able to cap off his career with one last moment of glory.  Although he retired from the NFL two years later, his legacy as one of the greatest quarterbacks of all time will always be remembered.  ')]] llm_output=None run=[RunInfo(run_id=UUID('3447b4c1-70de-40db-be34-5f562213ffd8'))]\n",
            "Processing question 67/100\n",
            "Response: generations=[[Generation(text=' Linebacker')]] llm_output=None run=[RunInfo(run_id=UUID('fb6b5823-3624-4bc2-8575-6f018e77577f'))]\n",
            "Processing question 68/100\n",
            "Response: generations=[[Generation(text=' 18')]] llm_output=None run=[RunInfo(run_id=UUID('406be143-ef7d-4164-be62-5a8ba45a62a2'))]\n",
            "Processing question 69/100\n",
            "Response: generations=[[Generation(text=' Von Miller did not have any forced fumbles during the Super Bowl 50 game, which was won by the Denver Broncos by a score of 24–10 against the Carolina Panthers. He did however, win the Super Bowl MVP award for this game, having 2.5 sacks, 4 forced incompletions and 2 passes defended. ')]] llm_output=None run=[RunInfo(run_id=UUID('c8a87387-b820-4b22-b0ac-9c0f8568c747'))]\n",
            "Processing question 70/100\n",
            "Response: generations=[[Generation(text=' Tom Brady')]] llm_output=None run=[RunInfo(run_id=UUID('c7e0841e-0ea9-4cab-a7f5-66b135631638'))]\n",
            "Processing question 71/100\n",
            "Response: generations=[[Generation(text=' Von Miller got 2 tackles during the game. ')]] llm_output=None run=[RunInfo(run_id=UUID('37704061-2336-4e61-adf1-399c435a4c39'))]\n",
            "Processing question 72/100\n",
            "Response: generations=[[Generation(text=\" Cam Newton was sacked 6 times during Super Bowl 50.  He was also responsible for 4 turnovers during the game.  The Panthers lost the game 24-10, with the Denver Broncos winning their third Super Bowl in franchise history.  This game was also future Hall of Fame quarterback Peyton Manning's last game in the NFL, as he retired directly after winning the Super Bowl that year.  \")]] llm_output=None run=[RunInfo(run_id=UUID('44b834fa-8a67-43eb-a301-4f6b645437ba'))]\n",
            "Processing question 73/100\n",
            "Response: generations=[[Generation(text=' The answer is The Denver defense forced Newton into turnovers four times, with two fumbles and two interceptions. ')]] llm_output=None run=[RunInfo(run_id=UUID('1bef3adb-25e2-4453-92b5-3f4400083612'))]\n",
            "Processing question 74/100\n",
            "Response: generations=[[Generation(text=' I am unable to answer this question as the provided information is not sufficient to do so. Could you provide more context or details to assist me in providing a more accurate response? \\n\\nI am ready to provide helpful and insightful information to the best of my abilities, so please let me know if you can provide additional context or details regarding the specific context or scenario you are inquiring about, and I will be happy to assist you to the best of my abilities! ')]] llm_output=None run=[RunInfo(run_id=UUID('ceff243f-9c9c-44c7-abeb-dc8b2ff97a5b'))]\n",
            "Processing question 75/100\n",
            "Response: generations=[[Generation(text=' The Most Valuable Player of Super Bowl 50 was Cam Newton, who was the quarterback for the Carolina Panthers. He was named the Most Valuable Player of the game after leading his team to a 24-10 victory over the Denver Broncos. Newton threw for 322 yards and two touchdowns, and also rushed for 58 yards and a touchdown. He was the first quarterback in Super Bowl history to throw for over 300 yards and also rush for a touchdown in the same game. ')]] llm_output=None run=[RunInfo(run_id=UUID('9d38009a-4d3c-48bc-955d-402b956bf473'))]\n",
            "Processing question 76/100\n",
            "Response: generations=[[Generation(text=' Linebacker')]] llm_output=None run=[RunInfo(run_id=UUID('5969f23c-3336-4bfc-8d9a-979136c1b489'))]\n",
            "Processing question 77/100\n",
            "Response: generations=[[Generation(text=' four times')]] llm_output=None run=[RunInfo(run_id=UUID('ec3e91f9-5cf7-48a5-96e1-aacf2855e157'))]\n",
            "Processing question 78/100\n",
            "Response: generations=[[Generation(text=' The answer is The Broncos caused turnovers three times in the game, with two forced fumbles and one interception. ')]] llm_output=None run=[RunInfo(run_id=UUID('4ce73c0a-3196-4f41-ae58-dc347a3b2017'))]\n",
            "Processing question 79/100\n",
            "Response: generations=[[Generation(text=' None')]] llm_output=None run=[RunInfo(run_id=UUID('6d685329-fb9d-44e9-9300-404ab4848e14'))]\n",
            "Processing question 80/100\n",
            "Response: generations=[[Generation(text=' Von Miller achieved 2.0 sacks by himself during the game. ')]] llm_output=None run=[RunInfo(run_id=UUID('12ea3285-7aec-48b8-a645-d610878be588'))]\n",
            "Processing question 81/100\n",
            "Response: generations=[[Generation(text=' CBS Sports')]] llm_output=None run=[RunInfo(run_id=UUID('57060045-8645-46a0-a16b-32669a39b2d7'))]\n",
            "Processing question 82/100\n",
            "Response: generations=[[Generation(text=' The average cost for a 30 second commercial during Super Bowl 50 was around $50 million. This number is highly variable and dependent on many factors, such as the demand for advertising time, the time of day, and the number of people watching. It is also important to note that this number is only an average and does not reflect the actual cost for any specific commercial. ')]] llm_output=None run=[RunInfo(run_id=UUID('5faf0c2e-ebe9-419a-b674-286ba4d15ac9'))]\n",
            "Processing question 83/100\n",
            "Response: generations=[[Generation(text=' The answer is unfortunately incomplete, since it does not provide the name of the group that headlined the Super Bowl 50 halftime show. It is possible that the question is asking for the name of the musical artist(s) who performed at the Super Bowl 50 halftime show. The answer could be: \"The Weeknd.\" ')]] llm_output=None run=[RunInfo(run_id=UUID('8268a09f-78bb-4f5d-8a34-4a6bae061682'))]\n",
            "Processing question 84/100\n",
            "Response: generations=[[Generation(text=' Chris Martin, Bruno Mars, and Beyonce')]] llm_output=None run=[RunInfo(run_id=UUID('96b8fd7a-cb71-4869-a3cd-70a0d46e9412'))]\n",
            "Processing question 85/100\n",
            "Response: generations=[[Generation(text=' Beyonce was the headline performer at the Super Bowl XLVII halftime show in 2013. Her performance was held in the Mercedes-Benz Superdome in New Orleans, Louisiana, and was watched by a record audience of over 110 million viewers. It was the second most-watched musical event in American history, after only the 2015 Super Bowl XLIX halftime show. Her performance featured a number of her hit songs, including \"Crazy in Love,\" \"Baby Boy,\" \"Hip Hop Star,\" and \"Single Ladies.\" She also performed a snippet of \"Formation,\" which she had just released a few days prior, marking the song\\'s public debut. ')]] llm_output=None run=[RunInfo(run_id=UUID('4a98f79a-6649-48fc-8b9e-96f0a6c37237'))]\n",
            "Processing question 86/100\n",
            "Response: generations=[[Generation(text=' CBS Sports')]] llm_output=None run=[RunInfo(run_id=UUID('1426c14d-df5e-44f3-8b5b-9886be5669a2'))]\n",
            "Processing question 87/100\n",
            "Response: generations=[[Generation(text=' None')]] llm_output=None run=[RunInfo(run_id=UUID('c97b6dd7-63e9-45ea-b43e-e603581adab4'))]\n",
            "Processing question 88/100\n",
            "Response: generations=[[Generation(text=' Beyonce')]] llm_output=None run=[RunInfo(run_id=UUID('9599d0e8-79ce-4428-a5ab-9d207a7dfafd'))]\n",
            "Processing question 89/100\n",
            "Response: generations=[[Generation(text=' Bruno Mars')]] llm_output=None run=[RunInfo(run_id=UUID('e5ca02c2-5ba7-4010-9847-95cb6f2d9cd1'))]\n",
            "Processing question 90/100\n",
            "Response: generations=[[Generation(text=\" There was no mention of a performer at the halftime show in the provided information. The text focuses on a venue that features a kids' playroom and private dining options, and it lists the amenities and features of the units, such as kitchen appliances and electrical installation.  If you are referring to a musical performance, it is possible that there may not have been an identified main performer since credit accrual is mentioned, which suggests some form of collaboration or group performance.  It is important to clarify the exact context or provide more details to determine the accurate answer. \")]] llm_output=None run=[RunInfo(run_id=UUID('1dd64654-cb02-4da7-8f10-4f3c5d45cded'))]\n",
            "Processing question 91/100\n",
            "Response: generations=[[Generation(text=' CBS')]] llm_output=None run=[RunInfo(run_id=UUID('70311081-8cbd-46a7-9949-e91c352aad7a'))]\n",
            "Processing question 92/100\n",
            "Response: generations=[[Generation(text='\\n\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\n\\nHelp Text: \\nThe provided text refers to a residential property development that offers smart intercom features for visitors, as well as energy-efficient design and features for the buildings in the')]] llm_output=None run=[RunInfo(run_id=UUID('6bbe9c27-99c2-4e1d-b2e3-7a8d1d4da7b7'))]\n",
            "Processing question 93/100\n",
            "Response: generations=[[Generation(text=' Chris Martin')]] llm_output=None run=[RunInfo(run_id=UUID('069af1e6-581b-4b82-921e-60700a40e8ff'))]\n",
            "Processing question 94/100\n",
            "Response: generations=[[Generation(text=' 16th')]] llm_output=None run=[RunInfo(run_id=UUID('f5b28fc8-4316-4d90-9370-8e2f9cc51a63'))]\n",
            "Processing question 95/100\n",
            "Response: generations=[[Generation(text=' Tanjong Katong')]] llm_output=None run=[RunInfo(run_id=UUID('8b9b29d8-7974-4777-8a5f-48a471ab9847'))]\n",
            "Processing question 96/100\n",
            "Response: generations=[[Generation(text=' The answer is unfortunately not explicitly provided in the text. ')]] llm_output=None run=[RunInfo(run_id=UUID('5440206d-a54c-46c8-851b-39941f3648af'))]\n",
            "Processing question 97/100\n",
            "Response: generations=[[Generation(text=' Coldplay')]] llm_output=None run=[RunInfo(run_id=UUID('c24eabd3-481d-4db2-a936-a95d83d39ef1'))]\n",
            "Processing question 98/100\n",
            "Response: generations=[[Generation(text=' Dr. Dre and Anderson Paak were the artists that performed with Coldplay during the 2022 Super Bowl half-time show. ')]] llm_output=None run=[RunInfo(run_id=UUID('e3fb2c8e-f0f9-418d-876e-7763e6ff8ae0'))]\n",
            "Processing question 99/100\n",
            "Response: generations=[[Generation(text=' CBS')]] llm_output=None run=[RunInfo(run_id=UUID('de8defba-9bf1-4df7-8533-a95cd71871a3'))]\n",
            "Processing question 100/100\n",
            "Response: generations=[[Generation(text=' Beyoncé')]] llm_output=None run=[RunInfo(run_id=UUID('f5f3946f-3866-4212-af48-255fb5de1788'))]\n",
            "Latency: 332.26 seconds\n",
            "Accuracy: 0.00\n",
            "Precision: 0.00\n",
            "Recall: 0.00\n",
            "ROUGE Scores: {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "Average BLEU Score: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use other metrics rather than confusion matrix as RAG is a generative AI model"
      ],
      "metadata": {
        "id": "Iw1prBWk8JDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1Fss5cy9AIc",
        "outputId": "026b13e0-e85b-4138-fd5a-9fa7dcd8b4ed"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.3.1+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.0.3)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.42.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.66.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert_score) (12.5.82)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.19.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2024.7.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Installing collected packages: bert_score\n",
            "Successfully installed bert_score-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from bert_score import score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "def evaluate_model_with_similarity(retriever, generate_answer_function, dataset_name='squad', num_samples=100):\n",
        "    # Load the benchmark dataset\n",
        "    print(\"Loading dataset...\")\n",
        "    dataset = load_dataset(dataset_name)\n",
        "\n",
        "    # Extract a subset of the validation data\n",
        "    validation_data = dataset['validation']\n",
        "    sample_data = validation_data.select(range(num_samples))\n",
        "\n",
        "    contexts = [item['context'] for item in sample_data]\n",
        "    questions = [item['question'] for item in sample_data]\n",
        "    true_answers = [item['answers']['text'][0] for item in sample_data]\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, (context, question) in enumerate(zip(contexts, questions), start=1):\n",
        "        print(f\"Processing question {i}/{num_samples}\")\n",
        "        # Retrieve relevant documents for the question\n",
        "        search_results = retriever.invoke(question)\n",
        "        relevant_docs = search_results\n",
        "        formatted_context = format_docs(relevant_docs)\n",
        "\n",
        "        # Generate an answer\n",
        "        result = generate_answer_function(question, formatted_context)\n",
        "        predictions.append(result)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate Latency\n",
        "    latency = end_time - start_time\n",
        "\n",
        "    # Calculate Similarity Metrics\n",
        "    def calculate_cosine_similarity(predictions, true_answers):\n",
        "        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        pred_embeddings = model.encode(predictions)\n",
        "        true_embeddings = model.encode(true_answers)\n",
        "        similarity_scores = cosine_similarity(pred_embeddings, true_embeddings)\n",
        "        avg_similarity = np.mean(np.diagonal(similarity_scores))\n",
        "        return avg_similarity\n",
        "\n",
        "    def calculate_embedding_similarity(predictions, true_answers):\n",
        "        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        pred_embeddings = model.encode(predictions, convert_to_tensor=True)\n",
        "        true_embeddings = model.encode(true_answers, convert_to_tensor=True)\n",
        "        similarity_scores = util.pytorch_cos_sim(pred_embeddings, true_embeddings)\n",
        "        avg_similarity = np.mean(similarity_scores.numpy())\n",
        "        return avg_similarity\n",
        "\n",
        "    def calculate_bertscore(predictions, true_answers):\n",
        "        P, R, F1 = score(predictions, true_answers, lang='en', verbose=True)\n",
        "        avg_f1 = F1.mean().item()\n",
        "        return avg_f1\n",
        "\n",
        "    avg_cosine_similarity = calculate_cosine_similarity(predictions, true_answers)\n",
        "    avg_embedding_similarity = calculate_embedding_similarity(predictions, true_answers)\n",
        "    avg_bertscore = calculate_bertscore(predictions, true_answers)\n",
        "\n",
        "    print(f\"Latency: {latency:.2f} seconds\")\n",
        "    print(f\"Average Cosine Similarity: {avg_cosine_similarity:.2f}\")\n",
        "    print(f\"Average Embedding Similarity: {avg_embedding_similarity:.2f}\")\n",
        "    print(f\"Average BERTScore: {avg_bertscore:.2f}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    def generate_answer_with_context(question, context):\n",
        "        cohere_llm = Cohere(model=\"command\", temperature=0.1, cohere_api_key=os.getenv('COHERE_API_KEY'))\n",
        "\n",
        "        prompt_template = f\"\"\"\n",
        "        Context: {context}\n",
        "        Question: {question}\n",
        "        Answer:\"\"\"\n",
        "\n",
        "        response = cohere_llm.generate([prompt_template])\n",
        "        print(\"Response:\", response)\n",
        "\n",
        "        if isinstance(response, list) and len(response) > 0 and 'text' in response[0]:\n",
        "            return response[0]['text'].strip()\n",
        "        else:\n",
        "            return \"No answer generated\"\n",
        "\n",
        "    # Evaluate the model\n",
        "    evaluate_model_with_similarity(retriever, generate_answer_with_context)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cad5d58c87d748b0848b5658b4e45d79",
            "b73915335b734fd09ddab0774afb734c",
            "641b5629049442ec8787bba0e300b835",
            "aa25d38878c145a6bd42624366816c31",
            "e0c46794e5a742ba992f4fda0bd69a59",
            "0a3074244e734860a027f6310e02e996",
            "5031d539c76d489b923ed706a97d474d",
            "08e079c0e1544167a1555667b0052cb5",
            "d0719941790c4ac4bba2fcec8578dd38",
            "564d7075146e4619bf427e94826f648d",
            "30a946297fa042fd855f1999a15042a9",
            "b9b68bd575c24bb5905cf727fcb2420a",
            "23492f0dfb864ce98b2b16e20a9a48b3",
            "bd564582e58144fd8b062e7649e686c8",
            "ee79a9799eec4c6084cfcad4dcdf530a",
            "1b7953c1c51044149b088bc2f752a824",
            "91b5f8f95b3b40f8ba5cd0d2c6adbdcb",
            "c5b95e7df7ca443bb13031dddbd5722f",
            "4251df036e8b4c048d96cd57d91a229c",
            "97c0f07d3e2f4343aa99791cecbcbcd8",
            "29cb587b14e64b70a405fa7240c8725f",
            "bf339de80678418dbc8bb3188fd0cf9f",
            "91ad4c2471574acfb1535626310570ef",
            "1ec09c74a1b94ecbbc0cad63f896fe81",
            "d2948c3d64d840f9af73f58f7b552834",
            "33ed13480ff743e0a2cca32850eb6429",
            "86aaf305e3844bbd8657f08c8a64cd8f",
            "fb4926941b804812980f6ce2b547271b",
            "360c53b4723349508d64688d17fdba09",
            "f99c8bb8d1ea4adb89e25a0b4d03a3cb",
            "c8d5a4b8a2da4d21b2c6a65aefa4d33e",
            "3f8491abfbe1409b9a7979d99a204663",
            "2aea6cc090b740d5b905f8a1a49fe9c0",
            "fed63b0d4558487bac5af7b83a0a5076",
            "62d6e8c297dc4624a8e17ca2b7cc37d1",
            "9c5218b952864193a36612c60ed30035",
            "997befeb031b4d28bf872a9b305593b5",
            "be81ebe8aab7425c8d4bcdd9c418abf5",
            "3ff4f46d179a45b4a3a5174122e5fbab",
            "a5e84d8393e24b9ab8e2d9e3dc6bd3a8",
            "fe17fc17ec134213aab5cf4e058f5a4f",
            "4a628f4e295f45629c46bc117d5c3035",
            "6e9cfb7d477840ef993773d2796ad632",
            "aacb4b7ac6cd4e9ba6d6ac4b06cdca2c",
            "9b7720e105bd4d56a4c7ffd7af658bf8",
            "ad16a9fd9c424896894d35a7d678e88f",
            "13a7ca69e7fe4aecaf2e52360db1e3f0",
            "197c7c91d4e743d3a9f824d88e20f1e3",
            "289eb2eb0ee64ec698dd7548689f10ec",
            "4e688a6af7ef4f18ad1925cab69c6995",
            "a8efb70fdd374269a1c870c08c4475c8",
            "e5e571f850ad48b1ac3f06fbd8133aca",
            "e04a8ed393b54987bc266ba770495bcc",
            "56bbafcfbab9476f8759965e0a7be7aa",
            "4e6d98db092a49779cec3c9a31c7777b",
            "9ad192520a484682a1414c80b4273ad4",
            "b214c64bd56d47e891d0205947d5e5f1",
            "5dd0dfebf54d439fa63f8bedda4bf173",
            "31f8b03e56404164af35f3a2b3ab5b23",
            "bb7f512e1e3946a2964ca7775018f3c4",
            "9cadd6fe35b04e19919ed7e7c2d39020",
            "6743e1e673664fc69138347a0e297b45",
            "b7c518be5ce84db6874d18142d38b59f",
            "f055714a57ac4e5f9fc6daf594a0670d",
            "d85fb069880641f691e2412af6e1dea2",
            "6286bd927ce541a6a67e8f13bedf8340",
            "c7fae6a6bfc54d988d6f00b3e6b9128d",
            "19c4d17968d947febb22ce20f9e6f4fd",
            "ca4ce67359b042c0958fb85e07d8535b",
            "120b7ce9f9ea4090a58f20b2396a0247",
            "8cf8bd642fda4d3cb13c26b2df00386c",
            "5170262932d240009cdf47e6dfaf3ad7",
            "09f8b91a45ca45188b985cd02109c83c",
            "92027cc3652944ccb93a3a1aa5b115ff",
            "2bfe989f8d2047d3869bee01542cd598",
            "4d683edc6a054f7b87ec8706f2f301bd",
            "94c1e12f2e464625abe49b41171aec1e",
            "6d7316c19e164bf9b6c0411ddf40a784",
            "0fae9612233c4ba593eb3565ab86176b",
            "ddc7265a3da74ae6bbe45a9025e8d701",
            "4ee0e515d37e44c899a1ad2b3ebc406d",
            "6dfed727521842f9ae35172a0188e950",
            "20245caa3faa424caa7914da53a9ff40",
            "c63524c30ebd44cd8a24345bff0d4cf8",
            "165f5ea0935249bd9abe42f97fd05255",
            "7c618c81def749f18d90f53ce93adb56",
            "e71e872bf0c748f79a456bf5596db792",
            "0f7b87407c734c3e9affb8eb29443f9f"
          ]
        },
        "id": "MI4K4JZ--jAw",
        "outputId": "b8e201cb-7cdb-48a0-c210-1668351e8434"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Processing question 1/100\n",
            "Response: generations=[[Generation(text=' The answer is The Denver Broncos represented the AFC at Super Bowl 50')]] llm_output=None run=[RunInfo(run_id=UUID('d1489496-6a4b-4b8f-b082-85630b5d3859'))]\n",
            "Processing question 2/100\n",
            "Response: generations=[[Generation(text=' Carolina Panthers')]] llm_output=None run=[RunInfo(run_id=UUID('3d02e62f-4d1e-406a-8c71-e98ce3e273d3'))]\n",
            "Processing question 3/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl is an annual American football game that determines the league champion. The 50th Super Bowl was played in 2016, and was won by the Denver Broncos, who defeated the Carolina Panthers by a score of 24–10. The game was played on February 7, 2016, at Levi's Stadium in Santa Clara, California, and was televised on CBS. \")]] llm_output=None run=[RunInfo(run_id=UUID('32e23775-7956-45a1-9072-6b491da3f2fa'))]\n",
            "Processing question 4/100\n",
            "Response: generations=[[Generation(text=' The Denver Broncos won Super Bowl 50, defeating the Carolina Panthers by a score of 24-10. This win gave the Broncos their third Super Bowl victory and first since 1998. ')]] llm_output=None run=[RunInfo(run_id=UUID('1ed30ac2-b6bf-454d-ae53-c7a139028976'))]\n",
            "Processing question 5/100\n",
            "Response: generations=[[Generation(text=' The color was blue, according to NFL reporter Brian Sexton, although the league didn\\'t disclose the specific color standards it desired. The NFL merely recommended that some portion of the uniforms should be \"a primary color of blue.\" It seems likely that this was done to facilitate viewer identification of the \"home\" and \"away\" teams on television, as the Super Bowl is one of the most-watched sporting events on television annually.  It is also important to note that the NFL has had various partnerships with different blue-colored brands over the years. Would you like to know more about the Super Bowl? ')]] llm_output=None run=[RunInfo(run_id=UUID('91402a5e-3114-40d4-b334-4ba8352b36b4'))]\n",
            "Processing question 6/100\n",
            "Response: generations=[[Generation(text=' The theme of Super Bowl 50 was \"Golden Anniversary\" and the Pepsi Halftime Show featured a performance by Coldplay, who opened with a rendition of \"Yellow\" and was accompanied by singer Beyonce. The show also featured stunning visuals and an impressive light show, making it a memorable performance for the 50th anniversary of the Super Bowl. ')]] llm_output=None run=[RunInfo(run_id=UUID('56e70f19-edbe-435d-b156-c6b001b6ef74'))]\n",
            "Processing question 7/100\n",
            "Response: generations=[[Generation(text=' The game was played on Sunday, as referred to by the abbreviation \"Sun\" in the third column of the schedule. ')]] llm_output=None run=[RunInfo(run_id=UUID('0ce89d1f-6e27-494f-81cc-6f9377e66f05'))]\n",
            "Processing question 8/100\n",
            "Response: generations=[[Generation(text=' Tembusu Grand')]] llm_output=None run=[RunInfo(run_id=UUID('68a469b7-5f27-4e2f-9649-0779d77636c6'))]\n",
            "Processing question 9/100\n",
            "Response: generations=[[Generation(text=' The theme of Super Bowl 50 was \"Golden Super Bowl\". It was hosted at the Levi\\'s Stadium in Santa Clara, California, and was televised on CBS. The Denver Broncos defeated the Carolina Panthers 24-10, claiming their third Super Bowl championship. ')]] llm_output=None run=[RunInfo(run_id=UUID('68767ff0-5c2b-4e3c-8d05-54cb854f76b4'))]\n",
            "Processing question 10/100\n",
            "Response: generations=[[Generation(text=' Air-conditioning system. ')]] llm_output=None run=[RunInfo(run_id=UUID('fd85f855-717f-4af1-b71e-3e1611f0dde8'))]\n",
            "Processing question 11/100\n",
            "Response: generations=[[Generation(text=' Sunday')]] llm_output=None run=[RunInfo(run_id=UUID('1efda58a-648a-485e-aa4e-f3312509419f'))]\n",
            "Processing question 12/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers lost the Super Bowl 50 to the Denver Broncos and therefore did not win Super Bowl 50. ')]] llm_output=None run=[RunInfo(run_id=UUID('24cb4987-6ac6-465e-bf72-f766d4c86fb1'))]\n",
            "Processing question 13/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 took place in the Levi's Stadium located in Santa Clara, California. It was the first Super Bowl to take place in the San Francisco Bay Area since Super XIX in 1985. The game was played between the Denver Broncos and the Carolina Panthers with the Broncos winning 24-10. \")]] llm_output=None run=[RunInfo(run_id=UUID('042eb178-3238-456c-8004-2f9f64195abe'))]\n",
            "Processing question 14/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 took place in Santa Clara, California, US. It was the first Super Bowl to be played on the West Coast in 15 years. The game was played on February 7, 2016, at Levi's Stadium in Santa Clara and was won by the Denver Broncos who defeated the Carolina Panthers by a score of 24–10. \")]] llm_output=None run=[RunInfo(run_id=UUID('1b94313a-124c-4090-8cd7-b1641f12b910'))]\n",
            "Processing question 15/100\n",
            "Response: generations=[[Generation(text=' Answer: \\nThe Roman numeral for 50 is L. So if we used Roman numerals, Super Bowl 50 would have been called Super Bowl L. ')]] llm_output=None run=[RunInfo(run_id=UUID('4f878d9d-acbc-44bf-8281-9c0cee6e6c6b'))]\n",
            "Processing question 16/100\n",
            "Response: generations=[[Generation(text=' The 2015 NFL season')]] llm_output=None run=[RunInfo(run_id=UUID('159319a1-f71c-48d8-ab5d-f17e72e66069'))]\n",
            "Processing question 17/100\n",
            "Response: generations=[[Generation(text=\" The Denver Broncos secured a Super Bowl title for the third time in 1998.  Although they have won several Super Bowl titles since, 1998 remains a memorable year for Denver Broncos fans.  This was also the last Super Bowl win for the team under the leadership of quarterback John Elway.  Elway retired from football in 1999 and was inducted into the Pro Football Hall of Fame in 2004.  Even today, he is considered one of the greatest quarterbacks in NFL history and serves as a goodwill ambassador for the Denver Broncos.  It is also worth noting that the team has developed a strong offensive lineup over the years, which has helped them achieve numerous victories and ultimately five Super Bowl titles.  As such, the 1998 win played an important role in solidifying the team's reputation for possessing a strong offensive lineup, which has been a defining characteristic of the Denver Broncos.  Overall, 1998 was a landmark year in the history of the Denver Broncos, and the team has continued to thrive and remain competitive in the NFL since this time.  This year also marked the first time that the famous Rockie Mountains logo was painted on the field, which has since become a trademark of the team.  The logo is now seen as a symbol of the Denver Broncos and is widely recognized across the\")]] llm_output=None run=[RunInfo(run_id=UUID('c79b8246-2b76-476a-bb19-546efcc36b60'))]\n",
            "Processing question 18/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl is an annual American football game that determines the league champion. The specific stadium where Super Bowl 50 was held is the Levi's Stadium, located in Santa Clara, California. It was the first Super Bowl to be played on the West Coast since Super Bowl XIX in 1985. \")]] llm_output=None run=[RunInfo(run_id=UUID('9a8682bb-28cf-426a-b4d2-c899539566aa'))]\n",
            "Processing question 20/100\n",
            "Response: generations=[[Generation(text=' The final score of Super Bowl 50 was Denver Broncos - 24, Carolina Panthers - 10. ')]] llm_output=None run=[RunInfo(run_id=UUID('ac2807f5-08a0-4baa-b322-32e825ab904e'))]\n",
            "Processing question 21/100\n",
            "Response: generations=[[Generation(text=' The answer is Super Bowl 50 took place on February 7, 2016. ')]] llm_output=None run=[RunInfo(run_id=UUID('2b4fb66a-ddd2-4a0a-996e-9465178bc524'))]\n",
            "Processing question 22/100\n",
            "Response: generations=[[Generation(text=\" Super Bowl 50 was played on February 7, 2016, at Levi's Stadium in Santa Clara, California. It was the first time the Super Bowl was held in the San Francisco Bay Area since Super Bowl XIX in 1985. The game was played between the Carolina Panthers and the Denver Broncos and was won by the Panthers with a score of 24–10. \")]] llm_output=None run=[RunInfo(run_id=UUID('8de58254-fa4f-407b-b6d3-a70ddfce71b9'))]\n",
            "Processing question 23/100\n",
            "Response: generations=[[Generation(text=' New England Patriots')]] llm_output=None run=[RunInfo(run_id=UUID('ed3f5e4c-85ce-40c5-b86a-37f91bd0b45a'))]\n",
            "Processing question 24/100\n",
            "Response: generations=[[Generation(text=' Answer: BLK 92')]] llm_output=None run=[RunInfo(run_id=UUID('29bb3c0f-0a6d-41a4-9982-5ac16fe2d486'))]\n",
            "Processing question 25/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers lost the Super Bowl 50 to the Denver Broncos and therefore did not win Super Bowl 50. ')]] llm_output=None run=[RunInfo(run_id=UUID('c4f9ea7a-c9a0-46b2-97a8-fa3e0249f1c8'))]\n",
            "Processing question 26/100\n",
            "Response: generations=[[Generation(text=' 2015')]] llm_output=None run=[RunInfo(run_id=UUID('6b8ee351-62f1-4dde-a885-c705b01e0ab3'))]\n",
            "Processing question 27/100\n",
            "Response: generations=[[Generation(text=\" The answer is the Denver Broncos won Super Bowl 50.  They were crowned world champions after they defeated the Carolina Panthers 24-10 at Levi's Stadium in Santa Clara, California on February 7, 2016.  This was the Broncos' third Super Bowl victory in the history of the franchise, and quarterback Peyton Manning was named Super Bowl MVP for a record-breaking fifth time.  Would you like to know more about the Super Bowl?  I can provide you with more information and statistics if you would like.  Please let me know! \")]] llm_output=None run=[RunInfo(run_id=UUID('605e9555-f805-41b6-a3df-81d3071117a6'))]\n",
            "Processing question 28/100\n",
            "Response: generations=[[Generation(text=\" The Super Bowl 50 was held in Santa Clara, California, at the Levi's Stadium which is located in the San Francisco Bay Area on February 7, 2016. It was the first Super Bowl to be played in the Bay Area since Super Bowl XIX, which was held in 1985 at Stanford Stadium. The game was played between the Denver Broncos and the Carolina Panthers, with the Broncos winning 24–10. \")]] llm_output=None run=[RunInfo(run_id=UUID('8baf75fb-234c-4d21-929e-5b2b26fddc6b'))]\n",
            "Processing question 29/100\n",
            "Response: generations=[[Generation(text=' Super Bowl')]] llm_output=None run=[RunInfo(run_id=UUID('d7b75bf1-1d7b-469b-b878-06194ff46dc8'))]\n",
            "Processing question 30/100\n",
            "Response: generations=[[Generation(text=\" The New England Patriots won the AFC playoff game during the 2015 NFL season.  They ended up winning the Super Bowl that year, defeating the Seattle Seahawks, 28-24.  They were led by star quarterback Tom Brady, and head coach Bill Belichick.  This was the Patriots' fourth Super Bowl victory, with previous wins in 2001, 2003, and 2004.  They also appeared in the Super Bowl in 2007 and 2011, but lost both games.  The Patriots are a perennial powerhouse in the NFL, and have consistently been one of the top teams in the AFC, especially over the past two decades under Belichick and Brady.  They have won the AFC East division numerous times, and have made many deep playoff runs over the years.  They have been led by many great players over the years, such as Brady, Belichick, Randy Moss, and Rob Gronkowski, to name a few.  They have a very loyal and passionate fanbase, and are widely considered to be one of the most successful and well-run organizations in all of professional sports.  They have set numerous records and milestones over the years, and have consistently been a very competitive and entertaining team to watch.  They have also had some controversial moments and scandals over the\")]] llm_output=None run=[RunInfo(run_id=UUID('17b2cf56-ded4-4ca1-94f2-73dc24530c90'))]\n",
            "Processing question 31/100\n",
            "Response: generations=[[Generation(text=\" The Most Valuable Player award, which was established in 1993, has been won by several Carolina Panthers players over the years. The players are as follows:\\n\\n1. Steve Smith Sr. (2005)\\n2. Julius Peppers (2006)\\n3. DeAngelo Williams (2008)\\n4. Cam Newton (2015)\\n5. Luke Kuechly (2015)\\n6. Jonathan Stewart (2017)\\n7. Christian McCaffrey (2019)\\n8. Teddy Bridgewater (2021)\\n\\nThe award is typically given to the player who had the greatest impact on the team's success during the season. \")]] llm_output=None run=[RunInfo(run_id=UUID('bca1123c-c38a-4ebd-967c-2c5e453ef68f'))]\n",
            "Processing question 32/100\n",
            "Response: generations=[[Generation(text=\" The Denver Broncos have made eight appearances in the Super Bowl.  They won the Super Bowl in 1997, 1998, 1999, and 2015.  Their four Super Bowl wins are a tied record for the NFL.  Their appearances in the Super Bowl were in 1977, 1986, 1989, 1997, 1998, 1999, 2013, and 2015.  Their win-loss record in the Super Bowl is 4-4.  Their four appearances in the 1990s were the most for any NFL team in that decade.  The team has been consistent contenders in recent years and is widely expected to make their ninth Super Bowl appearance soon.  They have a very strong defense and an innovative offense.  Their quarterback, Payton Manning, is considered one of the best quarterbacks in the history of the NFL and is the only quarterback to have won the Super Bowl for more than one franchise.  The team's iconic orange uniforms have made them one of the most recognizable teams in the NFL.  They have a very large and loyal fan base and are widely expected to be a contender for the Super Bowl for years to come.  They have a very strong defense and an innovative offense.  Their quarterback, Payton Manning, is considered one of the best quarterbacks in the history of the NFL and is the\")]] llm_output=None run=[RunInfo(run_id=UUID('40e33e82-967a-4948-89a4-3a4a9b8d8245'))]\n",
            "Processing question 33/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers were established in 1993 and joined the NFL as the 29th franchise in the NFL. They are the only active NFL franchise to be based in Charlotte, North Carolina and their current logo, a blue panther face, was adopted in 2012 and is a slight modification of the logo used between 2002 and 2011. ')]] llm_output=None run=[RunInfo(run_id=UUID('3c5aaf67-f569-48a4-be3d-c4ff2074ea46'))]\n",
            "Processing question 34/100\n",
            "Response: generations=[[Generation(text=' Eunos Bus Interchange')]] llm_output=None run=[RunInfo(run_id=UUID('ca636998-ae3a-4a70-91f3-640629aa47d1'))]\n",
            "Processing question 35/100\n",
            "Response: generations=[[Generation(text=' The answer is not in the provided text. ')]] llm_output=None run=[RunInfo(run_id=UUID('fc02dcaa-0201-4d0c-a9d6-3f9da17cfdcf'))]\n",
            "Processing question 36/100\n",
            "Response: generations=[[Generation(text=' The Panthers beat the Arizona Cardinals in the NFC Championship Game to advance to Super Bowl 50. ')]] llm_output=None run=[RunInfo(run_id=UUID('f7ac27bf-543d-4050-8e7d-4948dbbc3cc1'))]\n",
            "Processing question 37/100\n",
            "Response: generations=[[Generation(text=' The Colts lost to the Broncos in the AFC Championship game in 2013')]] llm_output=None run=[RunInfo(run_id=UUID('6def37f6-1b48-4a7c-9bcd-e9f363a3ec9e'))]\n",
            "Processing question 38/100\n",
            "Response: generations=[[Generation(text=' The defending Super Bowl champions were the Baltimore Colts, who defeated the New York Jets in Super Bowl III. The Colts were the first NFL team to win a Super Bowl. ')]] llm_output=None run=[RunInfo(run_id=UUID('3c35f17e-cedb-4a8a-89d6-4fd033f89dbe'))]\n",
            "Processing question 39/100\n",
            "Response: generations=[[Generation(text=' The New England Patriots have been to the Super Bowl eight times. They have won the Super Bowl six times. ')]] llm_output=None run=[RunInfo(run_id=UUID('c28c5606-c98d-4ec5-8182-6c3b402e4c81'))]\n",
            "Processing question 40/100\n",
            "Response: generations=[[Generation(text=' 3 BHK + Study unit in any one of the following blocks \\nand you sell it before the 30th of June, you will be eligible for an extra bonus of \\n$5000.\\n\\nThe following are the quarters in which the commission slab will apply as per the above details:\\n1. Current quarter\\n2. Next quarter\\n3. Second next quarter\\n\\nThe relevant information to answer the question is:\\nCommission slab for the current quarter:\\tNone\\n\\nAnswer: \\nNone')]] llm_output=None run=[RunInfo(run_id=UUID('c288e486-cc28-4eef-b2d2-ccfa7d44cda9'))]\n",
            "Processing question 42/100\n",
            "Response: generations=[[Generation(text=' Cam Newton')]] llm_output=None run=[RunInfo(run_id=UUID('71435905-c441-487a-b014-0d12b34eb6c5'))]\n",
            "Processing question 43/100\n",
            "Response: generations=[[Generation(text=' The Denver Broncos played 16 games during the 2015 regular season, winning 13 while losing 3. ')]] llm_output=None run=[RunInfo(run_id=UUID('233fc3a1-7820-4604-b2f0-d65e9aa4f399'))]\n",
            "Processing question 44/100\n",
            "Response: generations=[[Generation(text=' The only team to have played in the Super Bowl eight times is the Pittsburgh Steelers.  They won the Super Bowl in 1974, 1975, 1978, 1979, 1980, 2006, 2009, and 2010, which equals eight appearances throughout the years.  They are tied with the Denver Broncos for the most Super Bowl wins with three, but the Steelers have appeared in the Super Bowl more times than any other team in NFL history.  Although the Dallas Cowboys and the New England Patriots have also appeared in the Super Bowl eight times combined, neither of the two teams has played in the Super Bowl eight times individually.  The Dallas Cowboys have played in the Super Bowl five times, and the New England Patriots have played in the Super Bowl three times, which is still a very impressive record.  Only time will tell if either of these two teams can make it to the Super Bowl eight times as the Pittsburgh Steelers have done.  Overall, the Pittsburgh Steelers hold the record for the most Super Bowl appearances, with eight appearances throughout history.  Very few teams have been able to consistently make it to the biggest stage of them all like the Steelers have, and it seems unlikely that any team will be able to surpass their record in the near future.  The Dallas Cowboys and the New England Patriots')]] llm_output=None run=[RunInfo(run_id=UUID('6c332148-1c96-4bd2-ab5c-bc2a3c48a8d1'))]\n",
            "Processing question 45/100\n",
            "Response: generations=[[Generation(text=' New England Patriots')]] llm_output=None run=[RunInfo(run_id=UUID('467ebfbe-9a4d-4b28-9676-70493313daca'))]\n",
            "Processing question 46/100\n",
            "Response: generations=[[Generation(text=' Cam Newton')]] llm_output=None run=[RunInfo(run_id=UUID('63cda778-b53c-49db-8f1d-515ec094d852'))]\n",
            "Processing question 47/100\n",
            "Response: generations=[[Generation(text=' The answer is the Dallas Cowboys based on the information provided in the table. ')]] llm_output=None run=[RunInfo(run_id=UUID('7796f985-a6e0-44fc-b75f-6b9ca2bb85db'))]\n",
            "Processing question 48/100\n",
            "Response: generations=[[Generation(text=' The Panthers have been in the Super Bowl twice. They lost in 2003 and 2015. ')]] llm_output=None run=[RunInfo(run_id=UUID('1d2aa742-5802-4fba-beb3-e2858d136ab3'))]\n",
            "Processing question 49/100\n",
            "Response: generations=[[Generation(text=' The San Diego Chargers')]] llm_output=None run=[RunInfo(run_id=UUID('bed3a864-0e7b-46df-995d-e375bb08453b'))]\n",
            "Processing question 50/100\n",
            "Response: generations=[[Generation(text=' The Most Valuable Player for the 2015 NFL season was Cam Newton, who played for the Carolina Panthers as a quarterback and was the first unanimous MVP in NFL history, as he received all 50 votes.  He led the Panthers to a 15-1 record and a Super Bowl appearance, earning him the MVP award and making him the face of the NFL for the 2015 season.  His performance was truly outstanding, as he set new records and led his team to previously unforeseen heights.  Aside from his individual success, he also managed to lead his team to great success as a team, which was a key factor in him winning the MVP award.  This was a well-deserved award for his fantastic performances throughout the season.  Aside from his individual brilliance, he also served as a team leader and a source of inspiration for his teammates, as his positive attitude and work ethic rubbed off on everyone around him.  His leadership was a major reason why the Panthers were able to achieve so much success that season.  Overall, it was well-deserved recognition for his outstanding play and leadership, which were instrumental in the success of his team that season.  Aside from his individual brilliance, he also served as a team leader and a source of inspiration for his teammates, as his positive attitude')]] llm_output=None run=[RunInfo(run_id=UUID('278955ca-7505-4033-9fb4-8a2c1ceefe87'))]\n",
            "Processing question 51/100\n",
            "Response: generations=[[Generation(text=' The New England Patriots')]] llm_output=None run=[RunInfo(run_id=UUID('8a6760b9-fbd1-4aaa-87d0-a5dc89c24180'))]\n",
            "Processing question 52/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers beat the Arizona Cardinals 49-15 in the 2015 NFC Championship game. The Panthers went on to lose to the Denver Broncos in Super Bowl 50. ')]] llm_output=None run=[RunInfo(run_id=UUID('afc09e98-42b4-476d-b9c0-cdd36cc80e0c'))]\n",
            "Processing question 53/100\n",
            "Response: generations=[[Generation(text=' Tom Brady was the 2015 NFL MVP. He is an American football quarterback for the New England Patriots of the National Football League (NFL). He has won a record seven Super Bowls for the Patriots and was named MVP of Super Bowl XLIX. He was also the first quarterback in NFL history to win a Super Bowl in three separate decades of his career. ')]] llm_output=None run=[RunInfo(run_id=UUID('2edff70b-39d5-47c0-b1ad-25ed5f2f8e53'))]\n",
            "Processing question 54/100\n",
            "Response: generations=[[Generation(text=' The panthers beat the saints to become the NFC champs')]] llm_output=None run=[RunInfo(run_id=UUID('2a5fdf37-4baa-4517-94ab-0be410fcdf02'))]\n",
            "Processing question 55/100\n",
            "Response: generations=[[Generation(text=' The Carolina Panthers formed in 1993.')]] llm_output=None run=[RunInfo(run_id=UUID('c89788d6-33b2-4b1e-97f9-fca7e527847b'))]\n",
            "Processing question 56/100\n",
            "Response: generations=[[Generation(text=' Cam Newton')]] llm_output=None run=[RunInfo(run_id=UUID('f47506c9-f728-40e6-a286-5f7425a29d4c'))]\n",
            "Processing question 57/100\n",
            "Response: generations=[[Generation(text=' Von Miller forced 2 fumbles during Super Bowl 50.  He was also named the Super Bowl 50 MVP, becoming the first player in NFL history to win the Super Bowl MVP award with a sack, a forced fumble, a fumble recovery, and an interception.  Miller had 2.5 sacks, five tackles, 2 forced fumbles, and one fumble recovery.  He absolutely dominated the game!  It was a spectacular performance by perhaps the best defensive player in the NFL today.  Von Miller is an incredible athlete and he absolutely sealed the win for the Denver Broncos in Super Bowl 50.  I would not be surprised if he won the Super Bowl MVP again sometime in the future.  He is that good!')]] llm_output=None run=[RunInfo(run_id=UUID('c713898a-afa8-4fb6-90f7-afc16683dd83'))]\n",
            "Processing question 58/100\n",
            "Response: generations=[[Generation(text=' The New York Rangers hockey team scored the most points in the regular season, but they lost the scoring lead to the Pittsburgh Penguins during the playoffs. ')]] llm_output=None run=[RunInfo(run_id=UUID('53e57b89-bbcc-44b8-add1-d5845a4b9e38'))]\n",
            "Processing question 59/100\n",
            "Response: generations=[[Generation(text=' Von Miller was the Denver linebacker named Super Bowl MVP, who played for the Denver Broncos and was crucial in their victory at Super Bowl 50.  He was named MVP of the game and also won the Butkus Award, an award given to the best linebackers in college football during his time at Texas A&M.  He was drafted by the Denver Broncos in the 2011 NFL Draft, and has since won many other accolades and honors for his skills and athleticism on the field.  He also holds the record for most sacks in a single season for the Broncos.  Overall, he is a well-known and well-respected athlete in the NFL, known for his exceptional talent and ability.  He continues to play for the Broncos and continues to be a standout player on the field.  Aside from football, he is also known for his charity work and is involved in many philanthropic endeavors.  He is also a fashion icon and has a unique style, often wearing custom suits and boots, and always sporting a distinctive look.  He is also a spokesperson for various brands and products, and is a popular cultural icon in the United States and around the world.  He is known for his outgoing personality, positive attitude, and friendly demeanor, and is widely respected and admired')]] llm_output=None run=[RunInfo(run_id=UUID('405fde8d-1da8-4b55-8260-f22e68f73a7e'))]\n",
            "Processing question 60/100\n",
            "Response: generations=[[Generation(text=' Von Miller made 2 solo tackles at Super Bowl 50.  He also made 1 assist, 1 sack, and 1 forced fumble during the game.  Von Miller was named the Super Bowl 50 MVP.  He finished the game with 4 total tackles, 2 of which were solo.  This game was his first and only Super Bowl appearance.  He played for the Denver Broncos who lost Super Bowl XLVIII to the Seattle Seahawks.')]] llm_output=None run=[RunInfo(run_id=UUID('4de762c8-5af1-41c3-a652-00b02bb27e9a'))]\n",
            "Processing question 61/100\n",
            "Response: generations=[[Generation(text=' Tom Brady')]] llm_output=None run=[RunInfo(run_id=UUID('6411e99b-293d-450e-8c28-cf73526d87da'))]\n",
            "Processing question 62/100\n",
            "Response: generations=[[Generation(text=' Cam Newton was sacked 4 times during the game.  It was a high-pressure game for the Carolina Panthers, who eventually lost to the Denver Broncos by a score of 24-10, with the Broncos defense putting on a dominant performance.  Cam Newton was forced to leave the game in the fourth quarter due to a concussion, after being slammed to the ground hard, making it his second concussion this season.  The Panthers were unable to recover from this blow and were ultimately defeated in the game.  This was a devastating loss for the Panthers and their fans, who had been hoping for a different outcome this season.  The Panthers will look to recover from this loss and finish the season strong in their last 2 games.  This was definitely not the way Cam Newton or the Panthers wanted to end their season, but they will have to take the lessons learned from this game and use them to become stronger and better next year.  As always, Cam Newton continues to be a bright spot for the Panthers, despite the tough loss, and his leadership will be key for the team moving forward into the future.  The Panthers will look to bounce back from this loss and end the season on a high note, as they continue to evaluate what went wrong this season and look to improve')]] llm_output=None run=[RunInfo(run_id=UUID('ae09a79b-09f9-480c-80c0-fda9daaadf6e'))]\n",
            "Processing question 63/100\n",
            "Response: generations=[[Generation(text=' Tom Brady')]] llm_output=None run=[RunInfo(run_id=UUID('99292ea2-30f9-47d2-ad21-4316b2a5c8cd'))]\n",
            "Processing question 64/100\n",
            "Response: generations=[[Generation(text=' Cam Newton had 39 turnovers in 2015.  This was the highest total among all quarterbacks that year.  Hopefully he can lower his number of turnovers in the upcoming season.  His turnovers may have cost him and his team some wins last season.  It will be interesting to see how he performs in the upcoming season.  He is one of the most exciting players in the NFL and is sure to have a lot of turnovers in the upcoming season.  His team will need him to perform at his best in order to win games.  He is one of the most highly paid players in the NFL and is expected to perform at a high level.  His team will need him to deliver in order to win games.  He is an exceptional player and is sure to have a great season.  His turnovers may have cost his team some wins last season.  He is an exceptional player and is sure to have a great season.  He is sure to be one of the best players in the NFL this season.  He is an exceptional player and is sure to have a great season.  His best season was in 2015 when he had 39 turnovers.  This was the most in the NFL among all quarterbacks.  He is an exceptional player and is sure to have a')]] llm_output=None run=[RunInfo(run_id=UUID('5edf32f9-ffc6-4419-8279-39fbafad3420'))]\n",
            "Processing question 65/100\n",
            "Response: generations=[[Generation(text=' 4')]] llm_output=None run=[RunInfo(run_id=UUID('fea1b185-0dbd-4b38-aa4a-a34d894826fe'))]\n",
            "Processing question 66/100\n",
            "Response: generations=[[Generation(text=' The MVP award for Super Bowl 50 was given to Denver Broncos quarterback Peyton Manning.  He was able to lead his team to a 24-10 victory over the Carolina Panthers, winning their third championship. Manning threw for 141 yards and scored the only touchdown for the team, earning the Super Bowl MVP for the second time in his career. ')]] llm_output=None run=[RunInfo(run_id=UUID('4f9e1837-8a77-4100-8b38-f3a142c28ed8'))]\n",
            "Processing question 67/100\n",
            "Response: generations=[[Generation(text=' Linebacker')]] llm_output=None run=[RunInfo(run_id=UUID('0e2cc54b-149e-41db-9fc1-9804bf4904d6'))]\n",
            "Processing question 68/100\n",
            "Response: generations=[[Generation(text=' 18')]] llm_output=None run=[RunInfo(run_id=UUID('4a8536b9-fd19-4472-98fe-b78910f6462b'))]\n",
            "Processing question 69/100\n",
            "Response: generations=[[Generation(text=' Von Miller did not have any forced fumbles during the Super Bowl 50 game, which is formally known as the \"Peyton Manning Bowl.\"')]] llm_output=None run=[RunInfo(run_id=UUID('1aeb09ac-00c4-4a4f-9bf1-90f3c801f6d8'))]\n",
            "Processing question 70/100\n",
            "Response: generations=[[Generation(text=' Tom Brady')]] llm_output=None run=[RunInfo(run_id=UUID('9589e073-ee04-4e47-9ef0-3dcb48456058'))]\n",
            "Processing question 71/100\n",
            "Response: generations=[[Generation(text=' Von Miller got 2 tackles during the game. ')]] llm_output=None run=[RunInfo(run_id=UUID('0fbddc22-3359-4bf1-aa4d-7222ee5c9ef6'))]\n",
            "Processing question 72/100\n",
            "Response: generations=[[Generation(text=\" Cam Newton was sacked 6 times during Super Bowl 50.  He was also responsible for 4 turnovers during the game.  The Panthers lost the game 24-10, with the Denver Broncos winning their third Super Bowl in franchise history.  This game was also future Hall of Fame quarterback Peyton Manning's final game in the NFL.  \")]] llm_output=None run=[RunInfo(run_id=UUID('e30b816d-5c90-4d71-a279-f32f86c33b5c'))]\n",
            "Processing question 73/100\n",
            "Response: generations=[[Generation(text=' The answer is The Denver defense forced Newton into turnovers three times, with two fumbles and one interception. ')]] llm_output=None run=[RunInfo(run_id=UUID('8b2d5991-434a-42fd-8457-1f80d211e86c'))]\n",
            "Processing question 74/100\n",
            "Response: generations=[[Generation(text=' I am unable to provide an answer to the question you asked because the provided information does not contain any information on Newton Turnovers or sports related points however I can provide you with information on the provided example of a commission structure in the sales industry if you would like? ')]] llm_output=None run=[RunInfo(run_id=UUID('f575c9b9-2260-4fb3-b60b-52c14889a5ce'))]\n",
            "Processing question 75/100\n",
            "Response: generations=[[Generation(text=' The Most Valuable Player of Super Bowl 50 was Cam Newton, who was the quarterback for the Carolina Panthers. He was named the Most Valuable Player of the game after leading his team to a 24-10 victory over the Denver Broncos. Newton threw for 322 yards and two touchdowns, and also rushed for 58 yards and a touchdown. He was the first quarterback in Super Bowl history to throw for over 300 yards and also rush for a touchdown in the same game. ')]] llm_output=None run=[RunInfo(run_id=UUID('546427dc-02d3-4a25-8d17-4a2184fd6da7'))]\n",
            "Processing question 76/100\n",
            "Response: generations=[[Generation(text=' Linebacker')]] llm_output=None run=[RunInfo(run_id=UUID('36fcac6c-4b1d-4222-bcb7-a475cece4b1d'))]\n",
            "Processing question 77/100\n",
            "Response: generations=[[Generation(text=' twice')]] llm_output=None run=[RunInfo(run_id=UUID('5f30b915-dd70-4100-8f8d-e71b5080ae2b'))]\n",
            "Processing question 78/100\n",
            "Response: generations=[[Generation(text=' The answer is The Broncos caused turnovers three times in the game, with two forced fumbles and one interception. ')]] llm_output=None run=[RunInfo(run_id=UUID('38196bb3-69f2-45a6-8280-de335357f76e'))]\n",
            "Processing question 79/100\n",
            "Response: generations=[[Generation(text=' None')]] llm_output=None run=[RunInfo(run_id=UUID('787539a3-4580-427b-9de9-28a43d14e9d3'))]\n",
            "Processing question 80/100\n",
            "Response: generations=[[Generation(text=' Von Miller achieved 2.0 tackles by himself during the game. ')]] llm_output=None run=[RunInfo(run_id=UUID('e58feb9b-80d8-4555-9f04-70ade70302ad'))]\n",
            "Processing question 81/100\n",
            "Response: generations=[[Generation(text=' CBS Sports')]] llm_output=None run=[RunInfo(run_id=UUID('23467a12-346b-4e0f-aea7-85bb242d6b9b'))]\n",
            "Processing question 82/100\n",
            "Response: generations=[[Generation(text=' The average cost for a 30 second commercial during Super Bowl 50 was around $50 million. This number is projected to continue increasing in the future. ')]] llm_output=None run=[RunInfo(run_id=UUID('b70155b7-c5b2-4b4a-9f6a-beab272ffe8b'))]\n",
            "Processing question 83/100\n",
            "Response: generations=[[Generation(text=' The answer is The Weeknd, who was the headline performer at Super Bowl 50 halftime show. ')]] llm_output=None run=[RunInfo(run_id=UUID('69a0816e-d168-4422-a27d-790c78c49175'))]\n",
            "Processing question 84/100\n",
            "Response: generations=[[Generation(text=' Chris Martin, Bruno Mars, and Beyonce')]] llm_output=None run=[RunInfo(run_id=UUID('054a88d0-f6f7-4992-9ea8-f93927f7c77e'))]\n",
            "Processing question 85/100\n",
            "Response: generations=[[Generation(text=' Beyonce was the headline performer at the Super Bowl XLVII halftime show in 2013. Her performance was held in the Mercedes-Benz Superdome in New Orleans, Louisiana, and was seen by a record audience of over 110 million viewers. It was the culmination of a series of spectacular halftime shows that she had been doing since 2001. ')]] llm_output=None run=[RunInfo(run_id=UUID('7cb062c4-dcf1-4830-8a44-bdaa13b4234e'))]\n",
            "Processing question 86/100\n",
            "Response: generations=[[Generation(text=' CBS Sports')]] llm_output=None run=[RunInfo(run_id=UUID('c487dd5c-7c59-4a1e-a87d-c2fa505990cc'))]\n",
            "Processing question 87/100\n",
            "Response: generations=[[Generation(text=' None')]] llm_output=None run=[RunInfo(run_id=UUID('f4bdbf74-032d-4a22-b2eb-933eb7d062b0'))]\n",
            "Processing question 88/100\n",
            "Response: generations=[[Generation(text=' Beyonce')]] llm_output=None run=[RunInfo(run_id=UUID('7a7a0fb4-aa6e-46f9-bb62-e7fecf940707'))]\n",
            "Processing question 89/100\n",
            "Response: generations=[[Generation(text=' Bruno Mars')]] llm_output=None run=[RunInfo(run_id=UUID('0d9f9a96-1433-4967-b5e5-43ae8233933c'))]\n",
            "Processing question 90/100\n",
            "Response: generations=[[Generation(text=\" There was no mention of a performer at the halftime show in the provided information. The text focuses on a venue named Tembusu Club, highlighting its entertainment features such as a karaoke pod, gaming pod, playhouse, and kids' playroom. It also includes specifications for the building's units and common areas.  If you are interested in knowing more about the halftime show, please provide the specific year or event you would like to know about, and I will do my best to assist you with the relevant information. \")]] llm_output=None run=[RunInfo(run_id=UUID('612c6ded-e41d-415e-8b01-0ec450a3cfad'))]\n",
            "Processing question 91/100\n",
            "Response: generations=[[Generation(text=' CBS')]] llm_output=None run=[RunInfo(run_id=UUID('b54cfa54-cbb7-434e-9861-de37de8f92d5'))]\n",
            "Processing question 92/100\n",
            "Response: generations=[[Generation(text='\\n\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\nNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\t')]] llm_output=None run=[RunInfo(run_id=UUID('32e0dcc1-96c0-4c7f-8508-410a73c48b11'))]\n",
            "Processing question 93/100\n",
            "Response: generations=[[Generation(text=' Chris Martin')]] llm_output=None run=[RunInfo(run_id=UUID('7fe6ab46-f17d-444d-85a2-da99e63d681a'))]\n",
            "Processing question 94/100\n",
            "Response: generations=[[Generation(text=' 47th')]] llm_output=None run=[RunInfo(run_id=UUID('dd39e333-849b-4260-96d5-aba20c945132'))]\n",
            "Processing question 95/100\n",
            "Response: generations=[[Generation(text=' Tanjong Katong')]] llm_output=None run=[RunInfo(run_id=UUID('5e1b0dfe-efc7-4679-b055-365a399a1658'))]\n",
            "Processing question 96/100\n",
            "Response: generations=[[Generation(text=' $10,000')]] llm_output=None run=[RunInfo(run_id=UUID('bf3f34b0-4585-4af3-ac56-a63f2000a355'))]\n",
            "Processing question 97/100\n",
            "Response: generations=[[Generation(text=' Coldplay')]] llm_output=None run=[RunInfo(run_id=UUID('442055b9-8f69-4ab3-b672-d7351baf876b'))]\n",
            "Processing question 98/100\n",
            "Response: generations=[[Generation(text=' Chris Martin and Bruno Mars')]] llm_output=None run=[RunInfo(run_id=UUID('ec63d4b3-a528-44c4-9355-e63efcbf40f4'))]\n",
            "Processing question 99/100\n",
            "Response: generations=[[Generation(text=' CBS')]] llm_output=None run=[RunInfo(run_id=UUID('fa5ea4c3-a4d8-4959-b0bd-d81d5ac7e7af'))]\n",
            "Processing question 100/100\n",
            "Response: generations=[[Generation(text=' The halftime show was headlined by Coldplay, with guest performers including Beyonce, Bruno Mars, and Mark Ronson, and the Youth Orchestra Los Angeles. ')]] llm_output=None run=[RunInfo(run_id=UUID('ecff9550-abc5-4ed4-93c8-c7e02e6ac2f9'))]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cad5d58c87d748b0848b5658b4e45d79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9b68bd575c24bb5905cf727fcb2420a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91ad4c2471574acfb1535626310570ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fed63b0d4558487bac5af7b83a0a5076"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b7720e105bd4d56a4c7ffd7af658bf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ad192520a484682a1414c80b4273ad4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7fae6a6bfc54d988d6f00b3e6b9128d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d7316c19e164bf9b6c0411ddf40a784"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done in 7.35 seconds, 13.60 sentences/sec\n",
            "Latency: 315.91 seconds\n",
            "Average Cosine Similarity: 0.12\n",
            "Average Embedding Similarity: 0.12\n",
            "Average BERTScore: 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAST API"
      ],
      "metadata": {
        "id": "eTMpP6iKKYQN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AE1KJcj6Ol8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from datasets import load_dataset\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import Cohere\n",
        "\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Initialize your embeddings model\n",
        "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Load and index the data\n",
        "# splitting the text into chunks for embeddings creation\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size = 1000,\n",
        "        chunk_overlap = 200, # This is helpul to handle the data loss while chunking.\n",
        "        length_function = len,\n",
        "        separators=['\\n', '\\n\\n', ' ', '']\n",
        "    )\n",
        "\n",
        "chunks = text_splitter.split_text(text = all_text)\n",
        "vectorstore = FAISS.from_texts(chunks, embedding = embeddings)\n",
        "\n",
        "# Create the retriever\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
        "\n",
        "# Define the prompt template\n",
        "prompt_template = \"\"\"Answer the question as precise as possible using the provided context. If the answer is\n",
        "                not contained in the context, say \"answer not available in context\" \\n\\n\n",
        "                Context: \\n {context}?\\n\n",
        "                Question: \\n {question} \\n\n",
        "                Answer:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template=prompt_template)\n",
        "\n",
        "# Define the function to generate an answer\n",
        "def generate_answer(question):\n",
        "    cohere_llm = Cohere(model=\"command\", temperature=0.1, cohere_api_key = os.getenv('zqr9XSBYfGM0p2CvhySt971mIWHELJaMK85x6SLO'))\n",
        "\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | cohere_llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    #return rag_chain.invoke(question)\n",
        "\n",
        "    result = rag_chain.invoke(question)\n",
        "\n",
        "    # Ensure result is in the expected format\n",
        "    if isinstance(result, dict) and 'answer' in result:\n",
        "        return result['answer']\n",
        "    else:\n",
        "        # Handle unexpected format\n",
        "        return 'No answer generated'  # Or raise an exception if that's preferred\n",
        "\n",
        "# Load the SQuAD dataset\n",
        "dataset_name = \"squad\"\n",
        "dataset = load_dataset(dataset_name)\n",
        "validation_data = dataset['validation']\n",
        "\n",
        "# Extract a subset of the validation data for demo purposes\n",
        "num_samples = 100\n",
        "sample_data = validation_data.select(range(num_samples))\n",
        "contexts = [item['context'] for item in sample_data]\n",
        "questions = [item['question'] for item in sample_data]\n",
        "true_answers = [item['answers']['text'][0] for item in sample_data]\n",
        "\n",
        "# Define a class for the input data\n",
        "class QuestionRequest(BaseModel):\n",
        "    question: str\n",
        "\n",
        "# Define the endpoint to get an answer\n",
        "@app.post(\"/answer/\")\n",
        "async def get_answer(request: QuestionRequest):\n",
        "    question = request.question\n",
        "\n",
        "    # Retrieve relevant documents for the question\n",
        "    search_results = retriever.invoke(question)\n",
        "    relevant_docs = search_results\n",
        "    formatted_context = \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Generate an answer using your RAG model\n",
        "        answer = generate_answer(question, retriever, prompt)\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing request: {e}\")\n",
        "\n",
        "    latency = time.time() - start_time\n",
        "    return {\"answer\": answer, \"latency\": latency}\n",
        "\n",
        "# Define the endpoint to evaluate latency\n",
        "@app.get(\"/evaluate_latency/\")\n",
        "async def evaluate_latency():\n",
        "    total_latency = 0\n",
        "    num_samples = len(questions)\n",
        "\n",
        "    for i, (context, question) in enumerate(zip(contexts, questions), start=1):\n",
        "        formatted_context = \"\\n\\n\".join(contexts)  # Join all contexts for evaluation\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            generate_answer(question, retriever, prompt)\n",
        "        except Exception as e:\n",
        "            raise HTTPException(status_code=500, detail=f\"Error processing request: {e}\")\n",
        "\n",
        "        latency = time.time() - start_time\n",
        "        total_latency += latency\n",
        "\n",
        "    avg_latency = total_latency / num_samples\n",
        "    return {\"Average Latency\": avg_latency}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "0aUc59fLNPbe",
        "outputId": "0ae800fc-5f2e-404c-aa75-c560894f12da"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-db465d39b25b>\u001b[0m in \u001b[0;36m<cell line: 122>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0muvicorn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0muvicorn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.0.0.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/main.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mMultiprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# pragma: full coverage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile api.py\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from datasets import load_dataset\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import Cohere\n",
        "\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Apply the workaround for Jupyter notebooks\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Initialize your embeddings model\n",
        "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Load and index the data\n",
        "# splitting the text into chunks for embeddings creation\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size = 1000,\n",
        "        chunk_overlap = 200, # This is helpul to handle the data loss while chunking.\n",
        "        length_function = len,\n",
        "        separators=['\\n', '\\n\\n', ' ', '']\n",
        "    )\n",
        "\n",
        "chunks = text_splitter.split_text(text = all_text)\n",
        "vectorstore = FAISS.from_texts(chunks, embedding=embeddings)\n",
        "\n",
        "# Create the retriever\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
        "\n",
        "# Define the prompt template\n",
        "prompt_template = \"\"\"Answer the question as precise as possible using the provided context. If the answer is\n",
        "                not contained in the context, say \"answer not available in context\" \\n\\n\n",
        "                Context: \\n {context}?\\n\n",
        "                Question: \\n {question} \\n\n",
        "                Answer:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template=prompt_template)\n",
        "\n",
        "# Define the function to generate an answer\n",
        "\n",
        "def generate_answer(question):\n",
        "    cohere_llm = Cohere(model=\"command\", temperature=0.1, cohere_api_key = os.getenv('J3ryImGgctIBh5Lbb06reA2PrmNCy98L2FrbegkV'))\n",
        "\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | cohere_llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    #return rag_chain.invoke(question)\n",
        "\n",
        "    result = rag_chain.invoke(question)\n",
        "\n",
        "    # Ensure result is in the expected format\n",
        "    if isinstance(result, dict) and 'answer' in result:\n",
        "        return result['answer']\n",
        "    else:\n",
        "        # Handle unexpected format\n",
        "        return 'No answer generated'  # Or raise an exception if that's preferred\n",
        "\n",
        "# Load the SQuAD dataset\n",
        "dataset_name = \"squad\"\n",
        "dataset = load_dataset(dataset_name)\n",
        "validation_data = dataset['validation']\n",
        "\n",
        "# Extract a subset of the validation data for demo purposes\n",
        "num_samples = 100\n",
        "sample_data = validation_data.select(range(num_samples))\n",
        "contexts = [item['context'] for item in sample_data]\n",
        "questions = [item['question'] for item in sample_data]\n",
        "true_answers = [item['answers']['text'][0] for item in sample_data]\n",
        "\n",
        "# Define a class for the input data\n",
        "class QuestionRequest(BaseModel):\n",
        "    question: str\n",
        "\n",
        "# Define the endpoint to get an answer\n",
        "@app.post(\"/answer/\")\n",
        "async def get_answer(request: QuestionRequest):\n",
        "    question = request.question\n",
        "\n",
        "    # Retrieve relevant documents for the question\n",
        "    search_results = retriever.invoke(question)\n",
        "    relevant_docs = search_results\n",
        "    formatted_context = \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Generate an answer using your RAG model\n",
        "        answer = generate_answer(question, retriever, prompt)\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing request: {e}\")\n",
        "\n",
        "    latency = time.time() - start_time\n",
        "    return {\"answer\": answer, \"latency\": latency}\n",
        "\n",
        "# Define the endpoint to evaluate latency\n",
        "@app.get(\"/evaluate_latency/\")\n",
        "async def evaluate_latency():\n",
        "    total_latency = 0\n",
        "    num_samples = len(questions)\n",
        "\n",
        "    for i, (context, question) in enumerate(zip(contexts, questions), start=1):\n",
        "        formatted_context = \"\\n\\n\".join(contexts)  # Join all contexts for evaluation\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            generate_answer(question, retriever, prompt)\n",
        "        except Exception as e:\n",
        "            raise HTTPException(status_code=500, detail=f\"Error processing request: {e}\")\n",
        "\n",
        "        latency = time.time() - start_time\n",
        "        total_latency += latency\n",
        "\n",
        "    avg_latency = total_latency / num_samples\n",
        "    return {\"Average Latency\": avg_latency}\n",
        "\n",
        "# Use this block for interactive environments\n",
        "if __name__ == \"__main__\":\n",
        "    import nest_asyncio\n",
        "    import uvicorn\n",
        "    nest_asyncio.apply()  # Apply the patch\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NoDyD0IOoEY",
        "outputId": "5181f034-c02f-4620-fc01-1033887bc2d6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting api.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup python3 -m uvicorn api:app --host 0.0.0.0 --port 8000 > output.log 2>&1 &"
      ],
      "metadata": {
        "id": "glAaSrzTOaqy"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install necessary libraries\n",
        "!pip install fastapi uvicorn pyngrok nest_asyncio\n",
        "\n",
        "# Step 2: Set up ngrok authtoken (replace 'YOUR_AUTHTOKEN_HERE' with your actual authtoken)\n",
        "!ngrok authtoken 2jPTIbWSfS7g4Vu0dllTblPJxNv_4apQJqVsKySceNCJ1uQHL\n",
        "\n",
        "# Step 3: Import necessary modules\n",
        "from pyngrok import ngrok\n",
        "from fastapi import FastAPI\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "\n",
        "# Step 4: Patch the event loop\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Step 5: Create a FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"Hello\": \"World\"}\n",
        "\n",
        "# Step 6: Set up a tunnel to the FastAPI server\n",
        "port = 8001  # Use a different port\n",
        "public_url = ngrok.connect(port)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# Step 7: Start the FastAPI server\n",
        "try:\n",
        "    uvicorn.run(app, host='0.0.0.0', port=port)\n",
        "except Exception as e:\n",
        "    print(f\"Error starting server: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987063a2-1f19-42a7-90e2-50394c2edd3a",
        "id": "kjS_7U7QPaJY"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.111.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.30.3)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.37.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.27.0)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.1.4)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.0.9)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.2.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi) (2.6.1)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi) (3.7)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi) (0.12.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.20.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (12.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi) (1.2.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (0.1.2)\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Public URL: NgrokTunnel: \"https://d2f1-34-145-195-49.ngrok-free.app\" -> \"http://localhost:8001\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [136406]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     45.119.30.246:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     45.119.30.246:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     45.119.30.246:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     45.119.30.246:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-1' coro=<Server.serve() done, defined at /usr/local/lib/python3.10/dist-packages/uvicorn/server.py:67> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/main.py\", line 577, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 65, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 315, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 68, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 142, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 328, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n",
            "INFO:     34.106.38.109:0 - \"POST /qna HTTP/1.1\" 404 Not Found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [136406]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from docx import Document\n",
        "from PyPDF2 import PdfReader\n",
        "import pandas as pd\n",
        "\n",
        "# Directory containing the files\n",
        "directory = '/content/drive/My Drive/Proplens/'  # Replace with your folder path\n",
        "\n",
        "# Function to read .docx files\n",
        "def read_docx(file_path):\n",
        "    try:\n",
        "        doc = Document(file_path)\n",
        "        text = [para.text for para in doc.paragraphs]\n",
        "        return '\\n'.join(text)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to read .pdf files\n",
        "def read_pdf(file_path):\n",
        "    try:\n",
        "        text = []\n",
        "        pdf = PdfReader(file_path)\n",
        "        for page in pdf.pages:\n",
        "            text.append(page.extract_text())\n",
        "        return '\\n'.join(text)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to read .xlsx files\n",
        "def read_xlsx(file_path):\n",
        "    try:\n",
        "        df = pd.read_excel(file_path)\n",
        "        return df.to_string()\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Iterate over all files in the directory\n",
        "def read_all_files(directory):\n",
        "    all_text = {}\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        print(f\"Processing file: {filename}\")  # Debugging line\n",
        "        if filename.endswith('.docx'):\n",
        "            text = read_docx(file_path)\n",
        "        elif filename.endswith('.pdf'):\n",
        "            text = read_pdf(file_path)\n",
        "        elif filename.endswith('.xlsx'):\n",
        "            text = read_xlsx(file_path)\n",
        "        else:\n",
        "            print(f\"Skipping unsupported file type: {filename}\")  # Debugging line\n",
        "            continue\n",
        "\n",
        "        if text is not None:\n",
        "            all_text[filename] = text\n",
        "        else:\n",
        "            print(f\"Failed to read content from: {filename}\")  # Debugging line\n",
        "    return all_text\n",
        "\n",
        "# Read all files in the directory\n",
        "files_text = read_all_files(directory)\n",
        "\n",
        "# Print or process the text from files\n",
        "for filename, text in files_text.items():\n",
        "    print(f\"--- {filename} ---\")\n",
        "    #print(text)\n",
        "    #print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_vH9iZULt8J",
        "outputId": "09004641-629c-4867-a8b4-e2000f5d0c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: facade-catalogue-and-specifications.pdf\n",
            "Processing file: Inventory sheet.xlsx\n",
            "Processing file: Project links.docx\n",
            "Processing file: Sales SOP and policies.docx\n",
            "Processing file: Tembusu grand 1 Bed + Study unit plan.png\n",
            "Skipping unsupported file type: Tembusu grand 1 Bed + Study unit plan.png\n",
            "Processing file: Tembusu grand 2 Bed +study unit plan.png\n",
            "Skipping unsupported file type: Tembusu grand 2 Bed +study unit plan.png\n",
            "Processing file: Tembusu grand 2 bed unit plan.png\n",
            "Skipping unsupported file type: Tembusu grand 2 bed unit plan.png\n",
            "Processing file: Tembusu grand 3 bed unit plan.png\n",
            "Skipping unsupported file type: Tembusu grand 3 bed unit plan.png\n",
            "Processing file: Tembusu grand 4 Bed unit plan.png\n",
            "Skipping unsupported file type: Tembusu grand 4 Bed unit plan.png\n",
            "Processing file: Tembusu grand image.jpeg\n",
            "Skipping unsupported file type: Tembusu grand image.jpeg\n",
            "Processing file: Tembusu grand Location map.png\n",
            "Skipping unsupported file type: Tembusu grand Location map.png\n",
            "Processing file: Tembusu grand Site plan.png\n",
            "Skipping unsupported file type: Tembusu grand Site plan.png\n",
            "Processing file: TEMBUSU GRAND_MAIN BROCHURE.pdf\n",
            "Processing file: pdf\n",
            "Skipping unsupported file type: pdf\n",
            "Processing file: Checklist for purchase of property under construction from developers.pdf\n",
            "Processing file: faiss_index_hp (1)\n",
            "Skipping unsupported file type: faiss_index_hp (1)\n",
            "Processing file: faiss_index_hp\n",
            "Skipping unsupported file type: faiss_index_hp\n",
            "Processing file: index.faiss\n",
            "Skipping unsupported file type: index.faiss\n",
            "Processing file: index.pkl\n",
            "Skipping unsupported file type: index.pkl\n",
            "Processing file: QnA_validation.csv\n",
            "Skipping unsupported file type: QnA_validation.csv\n",
            "Processing file: qa_data.csv\n",
            "Skipping unsupported file type: qa_data.csv\n",
            "--- facade-catalogue-and-specifications.pdf ---\n",
            "--- Inventory sheet.xlsx ---\n",
            "--- Project links.docx ---\n",
            "--- Sales SOP and policies.docx ---\n",
            "--- TEMBUSU GRAND_MAIN BROCHURE.pdf ---\n",
            "--- Checklist for purchase of property under construction from developers.pdf ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG Chain\n",
        "\n",
        "def generate_answer(question):\n",
        "    cohere_llm = Cohere(model=\"command\", temperature=0.1, cohere_api_key = os.getenv('J3ryImGgctIBh5Lbb06reA2PrmNCy98L2FrbegkV'))\n",
        "\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | cohere_llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    return rag_chain.invoke(question)"
      ],
      "metadata": {
        "id": "WVS9tA9nYsh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Etp_bURshwHA",
        "outputId": "f0aae4a9-898b-4ebd-ac94-994231dc1d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The Central Provident Fund (CPF) is a comprehensive social security savings plan that is mandatory for all employed Singapore citizens and permanent residents. It serves as a savings and retirement fund, and also covers medical, retirement, and housing needs. CPF members contribute a percentage of their monthly wages to the fund, and these contributions are used to invest in a variety of financial instruments to grow the savings. \n",
            "\n",
            "CPF funds can be used to buy a home, with the exact usage depending on the buyer's age and the type of property. For purchasing a property, CPF can only be used to pay for the price of the property and the stamp duty, and not any other costs like legal fees. If the property is sold, the CPF savings that were used for the property will be returned to the CPF account, plus any interest that was earned on those savings. \n",
            "\n",
            "There are many rules and regulations around the usage of CPF for property purchases, and these are designed to ensure that the property is affordable for the buyer and that the buyer has sufficient funds to live on and for retirement after purchasing the property. \n"
          ]
        }
      ],
      "source": [
        "ans = generate_answer(\"could you explain about cpf?\")\n",
        "print(ans)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "ans = generate_answer(\"What is two bed room size?\")\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jamzv0iyYyFb",
        "outputId": "2903fbf3-03d0-494c-c9b5-a287fcb87b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The two bedroom size is 2.77m. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yhSQ_-hhM5q",
        "outputId": "ea66d18f-de53-4c30-c8ed-dcd90e67a8a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Stamp fees are a necessary cost that comes with purchasing a property and is payable within 14 days of signing the Sale and Purchase Agreement. The stamp fee is a percentage of the purchase price of the property and is usually paid to the Inland Revenue Authority of Singapore. This is not available in the provided context. \n"
          ]
        }
      ],
      "source": [
        "ans = generate_answer(\"Could you about stamp fees?\")\n",
        "print(ans)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "ans = generate_answer(\"Could you explain paintings?\")\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVQalfa6g5qq",
        "outputId": "20504034-7ea3-4a43-cc6d-cc6aff5794ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Wall surfaces above false ceiling level will be left in its original bare condition.  No finishes behind all built-in cabinets, vanity/mirror cabinets, kitchen cabinets, mirrors and wall surfaces above false ceiling.  Thus, it is not possible to achieve total consistency of colour and grain in their selection and installation.  Engineered wood is subject to thermal expansion and contraction beyond the control of the builder and the Vendor.  Notwithstanding this note, the Vendor shall remain fully responsible for the performance of its obligations under clause 9 and clause 17 of sale and purchase agreement. \n",
            "Therefore, the answer is not available in the context. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "ans = generate_answer(\"Could you explain side view?\")\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhXnWXrrkjOY",
        "outputId": "81a41d8f-177c-4b45-f7cd-e7017ab4a0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The side view plan depicts the balcony's appearance and layout when viewed from the left or\n",
            "right side of the property. It displays the balcony's structural elements, such as the aluminum-\n",
            "framed glass railing and laminated glass railing, as well as the sliding and folding aluminum\n",
            "screen with fixed slats that are non-operable. This perspective illustrates how the balcony is\n",
            "attached to the building and shows its relationship to the other building components, giving a\n",
            "sense of the size and shape of the balcony from the side. It is one of several views provided\n",
            "to offer a comprehensive visual understanding of the balcony's design and features. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "ans = generate_answer(\"What is false ceiling?\")\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsNWKdjmlAFG",
        "outputId": "a69c9861-17fb-4083-df70-3bcac6cb9718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " False ceiling is a ceiling that is hung below the structural ceiling of a room. It is used to hide wiring, piping, and other infrastructure. \n"
          ]
        }
      ]
    }
  ]
}